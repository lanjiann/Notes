#+TITLE: Seven Concurrency Models in Seven Weeks
#+SUBTITLE: When Threads Unravel
#+VERSION: 2014
#+AUTHOR: Paul Butcher
#+STARTUP: entitiespretty

* Table of Contents                                      :TOC_4_org:noexport:
- [[Foreword - vii][Foreword - vii]]
- [[Acknowledgments - ix][Acknowledgments - ix]]
- [[Preface - xi][Preface - xi]]
- [[1. Introduction - 1][1. Introduction - 1]]
  - [[Concurrent or Parallel? - 1][Concurrent or Parallel? - 1]]
  - [[Parallel Architecture - 3][Parallel Architecture - 3]]
  - [[Concurrency: Beyond Multiple Cores - 4][Concurrency: Beyond Multiple Cores - 4]]
  - [[The Seven Models - 7][The Seven Models - 7]]
- [[2. Threads and Locks - 9][2. Threads and Locks - 9]]
  - [[The Simplest Thing That Could Possibly Work - 9][The Simplest Thing That Could Possibly Work - 9]]
  - [[Day 1: Mutual Exclusion and Memory Models - 10][Day 1: Mutual Exclusion and Memory Models - 10]]
  - [[Day 2: Beyond Intrinsic Locks - 21][Day 2: Beyond Intrinsic Locks - 21]]
  - [[Day 3: On the Shoulders of Giants - 32][Day 3: On the Shoulders of Giants - 32]]
  - [[Wrap-Up - 44][Wrap-Up - 44]]
- [[3. Functional Programming - 49][3. Functional Programming - 49]]
  - [[If It Hurts, Stop Doing It - 49][If It Hurts, Stop Doing It - 49]]
  - [[Day 1: Programming Without Mutable State - 50][Day 1: Programming Without Mutable State - 50]]
  - [[Day 2: Functional Parallelism - 61][Day 2: Functional Parallelism - 61]]
  - [[Day 3: Functional Concurrency - 71][Day 3: Functional Concurrency - 71]]
  - [[Wrap-Up - 82][Wrap-Up - 82]]
- [[4. The Clojure Way—Separating Identity from State - 85][4. The Clojure Way—Separating Identity from State - 85]]
  - [[The Best of Both Worlds - 85][The Best of Both Worlds - 85]]
  - [[Day 1: Atoms and Persistent Data Structures - 85][Day 1: Atoms and Persistent Data Structures - 85]]
  - [[Day 2: Agents and Software Transactional Memory - 97][Day 2: Agents and Software Transactional Memory - 97]]
  - [[Day 3: In Depth - 106][Day 3: In Depth - 106]]
  - [[Wrap-Up - 113][Wrap-Up - 113]]
- [[5. Actors - 115][5. Actors - 115]]
  - [[More Object-Oriented than Objects - 115][More Object-Oriented than Objects - 115]]
  - [[Day 1: Messages and Mailboxes - 116 - =TODO - Wrap-Up=][Day 1: Messages and Mailboxes - 116 - =TODO - Wrap-Up=]]
    - [[Our First Actor - 116][Our First Actor - 116]]
    - [[Mailboxes Are Queues - 117][Mailboxes Are Queues - 117]]
    - [[Receiving Messages - 118][Receiving Messages - 118]]
    - [[Linking Processes - 119][Linking Processes - 119]]
    - [[Stateful Actors - 120][Stateful Actors - 120]]
    - [[Hiding Messages Behind an API - 121][Hiding Messages Behind an API - 121]]
    - [[Bidirectional Communication - 122][Bidirectional Communication - 122]]
    - [[Naming Processes - 123][Naming Processes - 123]]
    - [[Interlude—First-Class Functions - 124][Interlude—First-Class Functions - 124]]
    - [[Parallel Map - 125][Parallel Map - 125]]
    - [[Day 1 Wrap-Up - 126][Day 1 Wrap-Up - 126]]
      - [[What We Learned in Day 1 - 126][What We Learned in Day 1 - 126]]
      - [[Day 1 Self-Study - 126][Day 1 Self-Study - 126]]
  - [[Day 2: Error Handling and Resilience - 127][Day 2: Error Handling and Resilience - 127]]
    - [[A Caching Actor - 127][A Caching Actor - 127]]
    - [[Fault Detection - 130][Fault Detection - 130]]
      - [[Links Propagate Abnormal Termination - 130][Links Propagate Abnormal Termination - 130]]
      - [[Links Are Bidirectional - 131][Links Are Bidirectional - 131]]
      - [[Normal Termination - 131][Normal Termination - 131]]
      - [[System Processes - 132][System Processes - 132]]
    - [[Supervising a Process - 132][Supervising a Process - 132]]
    - [[Timeouts - 133][Timeouts - 133]]
    - [[The Error-Kernel Pattern - 134][The Error-Kernel Pattern - 134]]
    - [[Let It Crash! - 135][Let It Crash! - 135]]
    - [[Day 2 Wrap-Up - 137][Day 2 Wrap-Up - 137]]
      - [[What We Learned in Day 2 - 137][What We Learned in Day 2 - 137]]
      - [[Day 2 Self-Study - 137][Day 2 Self-Study - 137]]
  - [[Day 3: Distribution - 137][Day 3: Distribution - 137]]
    - [[OTP - 138][OTP - 138]]
      - [[Functions and Pattern Matching - 138][Functions and Pattern Matching - 138]]
      - [[Reimplementing Cache with GenServer - 139][Reimplementing Cache with GenServer - 139]]
      - [[An OTP Supervisor - 141][An OTP Supervisor - 141]]
    - [[Nodes - 141][Nodes - 141]]
      - [[Connecting Nodes - 142][Connecting Nodes - 142]]
      - [[Remote Execution - 143][Remote Execution - 143]]
      - [[Remote Messaging - 143][Remote Messaging - 143]]
    - [[Distributed Word Count - 145][Distributed Word Count - 145]]
      - [[Counting Words - 145][Counting Words - 145]]
      - [[Keeping Track of Totals - 147][Keeping Track of Totals - 147]]
      - [[Parsing and Fault Tolerance - 147][Parsing and Fault Tolerance - 147]]
      - [[The Big Win - 149][The Big Win - 149]]
    - [[Day 3 Wrap-Up - 150][Day 3 Wrap-Up - 150]]
      - [[What We Learned in Day 3 - 150][What We Learned in Day 3 - 150]]
      - [[Day 3 Self-Study - 150][Day 3 Self-Study - 150]]
  - [[Wrap-Up - 150][Wrap-Up - 150]]
    - [[Strengths - 151][Strengths - 151]]
      - [[Messaging and Encapsulation - 151][Messaging and Encapsulation - 151]]
      - [[Fault Tolerance - 151][Fault Tolerance - 151]]
      - [[Distributed Programming - 151][Distributed Programming - 151]]
    - [[Weaknesses - 152 - =RE-READ=][Weaknesses - 152 - =RE-READ=]]
    - [[Other Languages - 152][Other Languages - 152]]
    - [[Final Thoughts - 152][Final Thoughts - 152]]
- [[6. Communicating Sequential Processes - 153][6. Communicating Sequential Processes - 153]]
  - [[Communication Is Everything - 153][Communication Is Everything - 153]]
  - [[Day 1: Channels and Go Blocks - 154][Day 1: Channels and Go Blocks - 154]]
  - [[Day 2: Multiple Channels and IO - 166][Day 2: Multiple Channels and IO - 166]]
  - [[Day 3: Client-Side CSP - 177][Day 3: Client-Side CSP - 177]]
  - [[Wrap-Up - 185][Wrap-Up - 185]]
- [[7. Data Parallelism - 189][7. Data Parallelism - 189]]
  - [[The Supercomputer Hidden in Your Laptop - 189][The Supercomputer Hidden in Your Laptop - 189]]
  - [[Day 1: GPGPU Programming - 190][Day 1: GPGPU Programming - 190]]
  - [[Day 2: Multiple Dimensions and Work-Groups - 201][Day 2: Multiple Dimensions and Work-Groups - 201]]
  - [[Day 3: OpenCL and OpenGL—Keeping It on the GPU - 212][Day 3: OpenCL and OpenGL—Keeping It on the GPU - 212]]
  - [[Wrap-Up - 220][Wrap-Up - 220]]
- [[8. The Lambda Architecture - 223][8. The Lambda Architecture - 223]]
  - [[Parallelism Enables Big Data - 223][Parallelism Enables Big Data - 223]]
  - [[Day 1: MapReduce - 224][Day 1: MapReduce - 224]]
  - [[Day 2: The Batch Layer - 237][Day 2: The Batch Layer - 237]]
  - [[Day 3: The Speed Layer - 249][Day 3: The Speed Layer - 249]]
  - [[Wrap-Up - 261][Wrap-Up - 261]]
- [[9. Wrapping Up - 263][9. Wrapping Up - 263]]
  - [[Where Are We Going? - 263][Where Are We Going? - 263]]
  - [[Roads Not Taken - 265][Roads Not Taken - 265]]
  - [[Over to You - 267][Over to You - 267]]
- [[Bibliography - 269][Bibliography - 269]]
- [[Index - 271][Index - 271]]

* Foreword - vii
* Acknowledgments - ix
* Preface - xi
* 1. Introduction - 1
** Concurrent or Parallel? - 1
** Parallel Architecture - 3
** Concurrency: Beyond Multiple Cores - 4
** The Seven Models - 7

* 2. Threads and Locks - 9
** The Simplest Thing That Could Possibly Work - 9
** Day 1: Mutual Exclusion and Memory Models - 10
** Day 2: Beyond Intrinsic Locks - 21
** Day 3: On the Shoulders of Giants - 32
** Wrap-Up - 44

* 3. Functional Programming - 49
** If It Hurts, Stop Doing It - 49
** Day 1: Programming Without Mutable State - 50
** Day 2: Functional Parallelism - 61
** Day 3: Functional Concurrency - 71
** Wrap-Up - 82

* 4. The Clojure Way—Separating Identity from State - 85
** The Best of Both Worlds - 85
** Day 1: Atoms and Persistent Data Structures - 85
** Day 2: Agents and Software Transactional Memory - 97
** Day 3: In Depth - 106
** Wrap-Up - 113

* TODO 5. Actors - 115
** TODO More Object-Oriented than Objects - 115
   - Functional programming AVOIDS the problems associated with *shared mutable state*,
     by *avoiding* /mutable state/

     /Actor model/ AVOIDS *share*, but retains *mutable state*.

   - Many concepts in /actor modle/ is similar to the ones in the _popular OO
     program_, but they have some significant differences:
     + /actors/ run concurrently with each other

     + /actors/ _REALLY_ communicate by passing messages.

       However, the message passing of _popular OO program_ is mostly limited to
       calling /methods/.

   - Use Elixir code as an illustration!

   - In day 1
     The basics of the actor model -- creating actors and sending and receiving
     messages.

     In day 2
     How failure detection, coupled with the "let it crash" philosophy, allows
     actor programs to be fault-tolerant.

     In day 3
     How actors' support for distributed programming allows us to both scale
     beyond a single machine and recover from failure of one or more of those
     machines.

** DONE Day 1: Messages and Mailboxes - 116 - =TODO - Wrap-Up=
   CLOSED: [2018-09-23 Sun 00:15]
   - *Joe asks: Actor or Process?*
     =TODO=

*** DONE Our First Actor - 116
    CLOSED: [2018-09-22 Sat 14:20]
    #+BEGIN_SRC elixir
      # Actors/hello_actors/hello_actors.exs
      defmodule Talker do
        def loop do
          receive do
            {:greet,     name     } -> IO.puts {"Hello #{name}"}
            {:praise,    name     } -> IO.puts {"#{name}, you're amazing"}
            {:celebrate, name, age} -> IO.puts {"Here's to another #{age} years, #{name}"}
          end
          loop
        end
      end

      pid = spawn(&Talker.loop/0)  ## Create an actor, and use `pid` to refer it.
      send(pid, {:greet, "Huey"})
      send(pid, {:praise, "Dewey"})
      send(pid, {:celebrate, "Louie", 16})
      sleep(1000)  ## NOT a good way, learn a better way later!

      # Hello Huey
      # Dewey, you're amazing
      # Here's to another 16 years, Louie
    #+END_SRC

    See what's going on under the hood.

*** DONE Mailboxes Are Queues - 117
    CLOSED: [2018-09-22 Sat 14:28]
    - One of the most important features of /actor/ programming is that
      _messages are sent /asynchronously/_ -- to each /mailbox/ of the receiver
      /actors/.

    - This means that actors are *decoupled* --
      /actors/ run at their own speed and do _NOT block_ when sending messages.

    - An /actor/ *runs* /concurrently/ with other /actors/
      but *handles messages* /sequentially/, in the order they were added to the
      mailbox, moving on to the next message only when it's finished processing
      the current message.

      =TODO= =IMPORTANT=
      We only have to worry about concurrency when sending messages.

*** DONE Receiving Messages - 118
    CLOSED: [2018-09-22 Sat 14:34]
    - An /actor/ typically sits in an _infinite loop_, waiting for a message to
      arrive with receive and then processing it.

      Our ~loop~ function (in ~Talker~ module) implements an _infinite loop_ by
      calling itself recursively

    - *Joe asks: Won’t Infinite Recursion Blow Up the Stack?*
     Exilir implements /tail-call elimination/
    1
*** DONE Linking Processes - 119
    CLOSED: [2018-09-22 Sat 15:50]
    - We need two things to be able to shut down cleanly.
      1. we need a way to tell our /actor/ to stop when it's finished processing
         all the messages in its queue.

         + solution: add a new kind of message and its handler:
           ~{:shutdown} -> exit(:normal)~

      2. we need some way to know that it has done so.

         + solution:
           Use
           #+BEGIN_SRC elixir
             Process.flag(:trap_exit, true)
             pid = spawn_link(&Talker.loop/0)
           #+END_SRC

           and then, after sending ~{:shutdown}~,

           #+BEGIN_SRC elixir
             receive do
               {:EXIT, ^pid, reason} -> IO.puts("Talker has exited (#{reason})")
             end
           #+END_SRC

    - Solution:
      #+BEGIN_SRC elixir
        defmodule Talker do
          def loop do
            receive do
              {:greet,     name}      -> IO.puts("Hello #{name}")
              {:praise,    name}      -> IO.puts("#{name}, you're amazing")
              {:celebrate, name, age} -> IO.puts("Here's to another #{age} years, #{name}")
              {:shutdown}             -> exit(:normal)
            end
            loop
          end
        end

        Process.flag(:trap_exit, true)
        pid = spawn_link(&Talker.loop/0)
        send(pid, {:greet, "Huey"})
        send(pid, {:praise, "Dewey"})
        send(pid, {:celebrate, "Louie", 16})
        send(pid, {:shutdown})

        receive do
          {:EXIT, ^pid, reason} -> IO.puts("Talker has exited (#{reason})")
        end

        # Hello Huey
        # Dewey, you're amazing
        # Here's to another 16 years, Louie
        # Talker has exited (normal)
      #+END_SRC

    - 

*** DONE Stateful Actors - 120
    CLOSED: [2018-09-22 Sat 16:02]
    They are actually recursions.
    #+BEGIN_SRC elixir
      ## Actors/counter/counter.ex
      defmodule Counter do
        def loop(count) do
          receive do
            {:next} ->
              IO.puts("Current count: #{count}")
              loop(count + 1)
          end
        end
      end

      counter = spawn(Counter, :loop, [1])
      send(counter, {:next})  # Current count: 1
      send(counter, {:next})  # Current count: 2
      send(counter, {:next})  # Current count: 3
    #+END_SRC

    This is the actor, which can safely access the states withough any
    concurrency bugs -- messages are *handled sequentially*.

*** DONE Hiding Messages Behind an API - 121
    CLOSED: [2018-09-22 Sat 16:47]
    #+BEGIN_SRC elixir
      defmodule Counter do
        def start(count) do
          spawn(__MODULE__, :loop, [count])
        end

        def next(counter) do
          send(counter, {:next})
        end

        def loop(count) do
          receive do
            {:next} ->
              IO.puts("Current count: #{count}")
              loop(count + 1)
          end
        end
      end

      counter = Counter.start(42)  ## #PID<0.44.0>
      Counter.next(counter)  ## Current count: 42 # {:next}
      Counter.next(counter)  ## Current count: 43 # {:next}
    #+END_SRC

    Next, let's make bidirectional communication, and then we can do something
    more interesting than just print out states.

*** DONE Bidirectional Communication - 122
    CLOSED: [2018-09-22 Sat 22:31]
    The /actor model/ does *NOT* provide direct support for replies,

    but it's something we can _build for ourselves very easily_ *by including
    the identifier of the sending process in the message*, which allows the
    recipient to send a reply:
    #+BEGIN_SRC elixir
      defmodule Counter do
        def start(count) do
          spawn(__MODULE__, :loop, [count])
        end

        def next(counter) do
          ref = make_ref()
          send(counter, {:next, self(), ref})
          receive do
            {:ok, ^ref, count} -> count
          end
        end

        def loop(count) do
          receive do
            {:next, sender, ref} ->
              send(sender, {:ok, ref, count})
              loop(count + 1)
          end
        end
      end

      counter = Counter.start(42)  ## #PID<0.47.0>
      Counter.next(counter)        ## 42
      Counter.next(counter)        ## 43
    #+END_SRC
    
    - *Joe asks: Why Reply with a Tuple?*
      Certainly, you can simply reply the _count_, like ~send(sender, count)~,
      rather than a tuple contains it.

      However, *idiomatic Elixir* typically uses _tuples as messages_, where
      + the first element indicates success or failure.

      In this instance, we also include a unique reference generated by the
      client, which ensures that the reply will be correctly identified in the
      event that there are multiple messages waiting in the client's mailbox.

    - NEXT: =TODO=
      We'll make one further improvement to ~Counter~ before we move on --
      _giving it a name to make it discoverable_.

*** DONE Naming Processes - 123
    CLOSED: [2018-09-22 Sat 22:31]
    - Unitl now, we only sent messages to /actors/ we created. Then,
      + Q :: How to send messages to /actors/ that are NOT created by us???

      + A :: There are several ways!
             The most convenient is to _register a name_ for the /process (actor
             in Elixir)/.

    - Example:
      #+BEGIN_SRC elixir
        pid = Counter.start(42)              # #PID<0.47.0>
        Process.register(pid, :counter)      # true
        counter = Process.whereis(:counter)  # #PID<0.47.0>
        Counter.next(counter)                # 42
      #+END_SRC

      + Run ~Process.registered~ to see all registered /actors (or processes,
        another name of actor in Elixir)/.

        As you can see, the virtual machine _automatically_ registers a number
        of standard processes at startup.

      + The ~send~ function can take a /process name/ instead of a /process identifier/.
        #+BEGIN_SRC elixir
          send(:counter, {:next, self(), make_ref()})  # {:next, #PID<0.45.0>, #Reference<0.0.0.107>}
          receive do msg -> msg end                    # {:ok, #Reference<0.0.0.107>, 43}
        #+END_SRC

    - Modified code that use /process name/ rather than /process identifier/:
      #+BEGIN_SRC elixir
        def start(count) do
          pid = spawn(__MODULE__, :loop, [count])
          Process.register(pid, :counter)
          pid
        end

        def next do
          ref = make_ref()
          send(:counter, {:next, self(), ref})
          receive do
            {:ok, ^ref, count} -> count
          end
        end

        Counter.start(42)  # #PID<0.47.0>
        Counter.next       # 42
        Counter.next       # 43
      #+END_SRC

    - Next:
      Parallel Map,
      First, its prelude

*** DONE Interlude—First-Class Functions - 124
    CLOSED: [2018-09-22 Sat 22:37]
    #+BEGIN_SRC elixir
      Enum.map([1, 2, 3, 4], fn(x) -> x * 2 end)
      # Shorthand syntax
      Enum.map([1, 2, 3, 4], &(&1 * 2))

      double = &(&1 * 2)    # #Function<erl_eval.6.80484245>
      double.(3)            # 6

      twice = fn(fun) -> fn(x) -> fun.(fun.(x)) end end  # #Function<erl_eval.680484245>
      twice.(double).(3)                                 # 12
    #+END_SRC

*** DONE Parallel Map - 125
    CLOSED: [2018-09-23 Sun 00:06]
    Here this "map" is the operation, not the same name data structure.

    #+BEGIN_SRC elixir
      defmodule Parallel do
        def map(collection, fun) do
          parent = self()

          processes = Enum.map(collection, fn(e) ->
            spawn_link(
              fn() ->
                send(parent, {self(), fun.(e)})
              end)
            end)

          Enum.map(processes,
            fn(pid) ->
              receive do
                {^pid, result} -> result
              end
            end)
        end
      end
    #+END_SRC

    + =from Jian=
      It seems the cost of creating /processes (actor)/ in sequential does NOT
      have much overhead.

    + Test:
      #+BEGIN_SRC elixir
        slow_double = fn(x) -> :timer.sleep(1000); x * 2 end            # #Function<6.80484245 in :erl_eval.expr/5>
        :timer.tc(fn() -> Enum.map([1, 2, 3, 4], slow_double) end)      # {4003414, [2, 4, 6, 8]}
        :timer.tc(fn() -> Parallel.map([1, 2, 3, 4], slow_double) end)  # {1001131, [2, 4, 6, 8]}
      #+END_SRC

*** TODO Day 1 Wrap-Up - 126
    End day 1!

    In day 2, learn how the actor model helps with _error handling_ and
    _resilience_.

**** What We Learned in Day 1 - 126
     - Actors (processes)
       + run concurrently
       + do not share state
       + communicate by asynchronously sending messages to mailboxes.

     - We covered how to do the following:
       + *Create* a new /process/ with ~spawn()~

       + *Send* a /message/ to a /process/ with ~send()~

       + Use /pattern matching/ to *handle* /messages/

       + *Create* a _link between two processes_ and _receive notification when
         one terminates_

       + *Implement* _bidirectional_, _synchronous messaging_ ON TOP OF the _standard
         asynchronous messaging_

       + *Register* a name for a /process/

**** Day 1 Self-Study - 126
***** Find
      - =TODO=
        The video of Erik Meijer and Clemens Szyperski talking to Carl Hewitt
        about the actor model at Lang.NEXT 2012

***** TODO Do
      - =TODO=
        Measure the cost of creating a process on the BEAM.
        How does it compare with the cost of creating a thread on the JVM?

      - =TODO=
        Measure the cost of the parallel map function we created compared to a
        sequential map. When would it make sense to use a parallel map, and when
        a sequential map?

      - =TODO=
        Write a parallel reduce function along the lines of the parallel map
        function we just created.

** TODO Day 2: Error Handling and Resilience - 127
   One of the key benefits of /concurrency/ is that it enables us to write
   /fault-tolerant/ code -- ech concurrency modle has their own way. We will show
   how the /actor modle/ do this.

   Create a more complicated and realistic example as a basis for today's
   discussion.

*** TODO A Caching Actor - 127
    - We'll use the map data structure.
      #+BEGIN_SRC elixir
        d = Map.new                            ### %{}
        d1 = Map.put(d, :a, "A value for a")   ### %{a: "A value for a"}
        d2 = Map.put(d1, :b, "A value for b")  ### %{a: "A value for a", b: "A value for b"}
        d1                                     ### %{a: "A value for a"}
        d2[:a]                                 ### "A value for a"
      #+END_SRC

    - Then,
      #+BEGIN_SRC elixir
        defmodule Cache do
          def loop(pages, size) do
            receive do
              {:put, url, page} ->
                new_pages = Map.put(pages, url, page)
                new_size = size + byte_size(page)
                loop(new_pages, new_size)

              {:get, sender, ref, url} ->
                send(sender, {:ok, ref, pages[url]})
                loop(pages, size)

              {:size, sender, ref} ->
                send(sender, {:ok, ref, size})
                loop(pages, size)

              {:terminate} -> # Terminate request - don't recurse
            end
          end
        end
      #+END_SRC

      To provide a better API, we add these functions to ~Cache~:
      #+BEGIN_SRC elixir
        def put(url, page) do
          send(:cache, {:put, url, page})
        end

        def get(url) do
          ref = make_ref()
          send(:cache, {:get, self(), ref, url})
          receive do
            {:ok, ^ref, page} -> page
          end
        end

        def size do
          ref = make_ref()
          send(:cache, {:size, self(), ref})
          receive do
            {:ok, ^ref, s} -> s
          end
        end

        def terminate do
          send(:cache, {:terminate})
        end
      #+END_SRC

    - For this program, if you try to put a ~nil~ as page into it, the ~byte_size~
      function invocation will crash.

      We will see how does the /actor model/ deal with it.
      (Use /supervisor process/).

*** TODO Fault Detection - 130
    - In Linking Processes, on page 119,

      we used ~spawn_link()~ to *create a link between two processes*
      so that we could *detect when one of them terminated*.

    - /Links/ are one of the *most important concepts* in Elixir programming.

**** DONE Links Propagate Abnormal Termination - 130
     CLOSED: [2018-09-23 Sun 14:33]
     - We can establish a /link/ between two /processes/ at _any time_ with
       ~Process.link()~.
       #+BEGIN_SRC elixir
         defmodule LinkTest do
           def loop do
             receive do
               {:exit_because, reason} -> exit(reason)
               {:link_to, pid}         -> Process.link(pid)
               {:EXIT, pid, reason}    -> IO.puts("#{inspect(pid)} exited because #{reason}")
             end
             loop
           end
         end
       #+END_SRC

     - Create a couple of instances of THIS /actor/, _link them_, and
       see what happens when one of them fails:
       #+BEGIN_SRC elixir
         pid1 = spawn(&LinkTest.loop/0)                    # #PID<0.47.0>
         pid2 = spawn(&LinkTest.loop/0)                    # #PID<0.49.0>
         send(pid1, {:link_to, pid2})                      # {:link_to, #PID<0.49.0>}
         send(pid2, {:exit_because, :bad_thing_happened})  # {:exit_because, :bad_thing_happened}

         Process.info(pid2, :status)  # nil
         Process.info(pid1, :status)  # nil
       #+END_SRC

     - Though when we check the status of ~pid1~ and ~pid2~, we found they both exit,
       we may also want to say something when we send the exit message to ~pid2~.
       This need set ~:trap_exit~.

**** TODO Links Are Bidirectional - 131
**** TODO Normal Termination - 131
**** TODO System Processes - 132

*** TODO Supervising a Process - 132


*** TODO Timeouts - 133
    - xx

*** TODO The Error-Kernel Pattern - 134
    - xx

*** TODO Let It Crash! - 135
    - xx

*** TODO Day 2 Wrap-Up - 137
**** What We Learned in Day 2 - 137
**** Day 2 Self-Study - 137
***** Find
***** Do

** TODO Day 3: Distribution - 137
*** OTP - 138
    - *Joe asks: What Does OTP Stand For?*
**** Functions and Pattern Matching - 138
**** Reimplementing Cache with GenServer - 139
**** An OTP Supervisor - 141
     - *Joe asks: What Is a Restart Strategy?*

*** Nodes - 141
    - *Joe asks: What Else Does OTP Do?*

**** Connecting Nodes - 142
     - *Joe asks: What If I Only Have One Computer?*

**** Remote Execution - 143
**** Remote Messaging - 143
     - *Joe asks: How Do I Manage My Cluster?*

*** Distributed Word Count - 145
**** Counting Words - 145
**** Keeping Track of Totals - 147
**** Parsing and Fault Tolerance - 147
**** The Big Win - 149

*** Day 3 Wrap-Up - 150
**** What We Learned in Day 3 - 150
**** Day 3 Self-Study - 150
***** Find
***** Do

** TODO Wrap-Up - 150
   #+BEGIN_QUOTE
   I’m sorry that I long ago coined the term “objects” for this topic because it
   gets many people to focus on the lesser idea.

   The big idea is “messaging” ... The Japanese have a small word—ma—for “that
   which is in-between”—perhaps the nearest English equivalent is
   “interstitial.” The key in making great and growable systems is much more to
   design how its modules communicate rather than what their internal properties
   and behaviors should be.     -- by Alan Kay (http://c2.com/cgi/wiki?AlanKayOnMessaging)
   #+END_QUOTE

*** Strengths - 151
**** Messaging and Encapsulation - 151
**** Fault Tolerance - 151
**** Distributed Programming - 151

*** DONE Weaknesses - 152 - =RE-READ=
    CLOSED: [2018-09-22 Sat 14:18]
    - actors are still susceptible to problems
      like deadlock plus a few failure modes unique to actors (such as overflowing
      an actor’s mailbox).
      Although a program constructed with /actors/ is easier to debug than one
      constructed with threads and locks,

    - As with /threads/ and /locks/, /actors/ provide *no direct support for
      parallelism*.
      Parallel solutions need to be built from concurrent building blocks,
      raising the specter of nondeterminism. =TODO= =???=

      And because /actors/ do _NOT share state_ and can ONLY communicate through
      message passing, /actors/ are *not a suitable choice if you need fine-grained
      parallelism*.

*** DONE Other Languages - 152
    CLOSED: [2018-09-22 Sat 14:14]
    - The /actor model/ is first described in the 1970s, most notably by Carl Hewitt.

    - The most popular one: Erlang

    - Now, many languages have actor model library:
      Akka for Scala and Java (theoretically and more generally, JVM-based languages).

*** Final Thoughts - 152

* 6. Communicating Sequential Processes - 153
** Communication Is Everything - 153
** Day 1: Channels and Go Blocks - 154
** Day 2: Multiple Channels and IO - 166
** Day 3: Client-Side CSP - 177
** Wrap-Up - 185

* 7. Data Parallelism - 189
** The Supercomputer Hidden in Your Laptop - 189
** Day 1: GPGPU Programming - 190
** Day 2: Multiple Dimensions and Work-Groups - 201
** Day 3: OpenCL and OpenGL—Keeping It on the GPU - 212
** Wrap-Up - 220

* 8. The Lambda Architecture - 223
** Parallelism Enables Big Data - 223
** Day 1: MapReduce - 224
** Day 2: The Batch Layer - 237
** Day 3: The Speed Layer - 249
** Wrap-Up - 261

* 9. Wrapping Up - 263
** Where Are We Going? - 263
** Roads Not Taken - 265
** Over to You - 267

* Bibliography - 269
* Index - 271
