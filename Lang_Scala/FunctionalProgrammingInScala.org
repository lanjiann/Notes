#+TITLE: Functional Programming in Scala
#+VERSION: 2015
#+AUTHOR: Paul Chiusano, RÃºnar Bjarnason
#+STARTUP: entitiespretty

* Table of Contents                                      :TOC_4_org:noexport:
- [[foreword][foreword]]
- [[preface][preface]]
- [[acknowledgments][acknowledgments]]
- [[about this book][about this book]]
  - [[How this book is structured =IMPORTANT=][How this book is structured =IMPORTANT=]]
  - [[Audience][Audience]]
  - [[How to read this book][How to read this book]]
  - [[Code conventions and downloads][Code conventions and downloads]]
  - [[Setting expectations][Setting expectations]]
  - [[Author Online][Author Online]]
- [[Part 1 Introduction to functional programming - 1][Part 1 Introduction to functional programming - 1]]
  - [[1 What is functional programming? - 3][1 What is functional programming? - 3]]
    - [[1.1 The benefits of FP: a simple example - 4][1.1 The benefits of FP: a simple example - 4]]
      - [[1.1.1 A program with side effects - 4][1.1.1 A program with side effects - 4]]
      - [[1.1.2 A functional solution: removing the side effects - 6][1.1.2 A functional solution: removing the side effects - 6]]
    - [[1.2 Exactly what is a (pure) function? - 9][1.2 Exactly what is a (pure) function? - 9]]
    - [[1.3 Referential transparency, purity, and the substitution model - 10][1.3 Referential transparency, purity, and the substitution model - 10]]
    - [[1.4 Summary - 13][1.4 Summary - 13]]
  - [[2 Getting started with functional programming in Scala - 14][2 Getting started with functional programming in Scala - 14]]
    - [[2.1 Introducing Scala the language: an example - 15][2.1 Introducing Scala the language: an example - 15]]
    - [[2.2 Running our program - 17][2.2 Running our program - 17]]
    - [[2.3 Modules, objects, and namespaces - 18][2.3 Modules, objects, and namespaces - 18]]
    - [[2.4 Higher-order functions: passing functions to functions - 19][2.4 Higher-order functions: passing functions to functions - 19]]
      - [[2.4.1 A short detour: writing loops functionally - 20][2.4.1 A short detour: writing loops functionally - 20]]
      - [[2.4.2 Writing our first higher-order function - 21][2.4.2 Writing our first higher-order function - 21]]
    - [[2.5 Polymorphic functions: abstracting over types - 22][2.5 Polymorphic functions: abstracting over types - 22]]
      - [[2.5.1 An example of a polymorphic function - 23][2.5.1 An example of a polymorphic function - 23]]
      - [[2.5.2 Calling HOFs with anonymous functions - 24][2.5.2 Calling HOFs with anonymous functions - 24]]
    - [[2.6 Following types to implementations - 25][2.6 Following types to implementations - 25]]
    - [[2.7 Summary - 28][2.7 Summary - 28]]
  - [[3 Functional data structures - 29][3 Functional data structures - 29]]
    - [[3.1 Defining functional data structures - 29][3.1 Defining functional data structures - 29]]
    - [[3.2 Pattern matching - 32][3.2 Pattern matching - 32]]
    - [[3.3 Data sharing in functional data structures - 35][3.3 Data sharing in functional data structures - 35]]
      - [[3.3.1 The efficiency of data sharing - 36][3.3.1 The efficiency of data sharing - 36]]
      - [[3.3.2 Improving type inference for higher-order functions - 37][3.3.2 Improving type inference for higher-order functions - 37]]
    - [[3.4 Recursion over lists and generalizing to higher-order functions - 38][3.4 Recursion over lists and generalizing to higher-order functions - 38]]
      - [[3.4.1 More functions for working with lists - 41][3.4.1 More functions for working with lists - 41]]
      - [[3.4.2 Loss of efficiency when assembling list functions from simpler components - 44][3.4.2 Loss of efficiency when assembling list functions from simpler components - 44]]
    - [[3.5 Trees - 44][3.5 Trees - 44]]
    - [[3.6 Summary - 47][3.6 Summary - 47]]
  - [[4 Handling errors without exceptions - 48 =ing...=][4 Handling errors without exceptions - 48 =ing...=]]
    - [[4.1 The good and bad aspects of exceptions - 48][4.1 The good and bad aspects of exceptions - 48]]
    - [[4.2 Possible alternatives to exceptions - 50][4.2 Possible alternatives to exceptions - 50]]
    - [[4.3 The ~Option~ data type - 52][4.3 The ~Option~ data type - 52]]
      - [[4.3.1 Usage patterns for ~Option~ - 53][4.3.1 Usage patterns for ~Option~ - 53]]
      - [[4.3.2 ~Option~ composition, lifting, and wrapping exception-oriented APIs - 56][4.3.2 ~Option~ composition, lifting, and wrapping exception-oriented APIs - 56]]
    - [[4.4 The ~Either~ data type - 60][4.4 The ~Either~ data type - 60]]
    - [[4.5 Summary - 63][4.5 Summary - 63]]
  - [[5 Strictness and laziness - 64][5 Strictness and laziness - 64]]
    - [[5.1 Strict and non-strict functions - 65][5.1 Strict and non-strict functions - 65]]
    - [[5.2 An extended example: lazy lists - 68][5.2 An extended example: lazy lists - 68]]
      - [[5.2.1 Memoizing streams and avoiding recomputation - 69][5.2.1 Memoizing streams and avoiding recomputation - 69]]
      - [[5.2.2 Helper functions for inspecting streams - 69][5.2.2 Helper functions for inspecting streams - 69]]
    - [[5.3 Separating program description from evaluation - 70][5.3 Separating program description from evaluation - 70]]
    - [[5.4 Infinite streams and corecursion - 73][5.4 Infinite streams and corecursion - 73]]
    - [[5.5 Summary - 77][5.5 Summary - 77]]
  - [[6 Purely functional state - 78][6 Purely functional state - 78]]
    - [[6.1 Generating random numbers using side effects - 78][6.1 Generating random numbers using side effects - 78]]
    - [[6.2 Purely functional random number generation - 80][6.2 Purely functional random number generation - 80]]
    - [[6.3 Making stateful APIs pure - 81][6.3 Making stateful APIs pure - 81]]
    - [[6.4 A better API for state actions - 84][6.4 A better API for state actions - 84]]
      - [[6.4.1 Combining state actions - 85  ======= EXERCISE 6.7 =TODO=][6.4.1 Combining state actions - 85  ======= EXERCISE 6.7 =TODO=]]
      - [[6.4.2 Nesting state actions - 86][6.4.2 Nesting state actions - 86]]
    - [[6.5 A general state action data type - 87][6.5 A general state action data type - 87]]
    - [[6.6 Purely functional imperative programming - 88][6.6 Purely functional imperative programming - 88]]
    - [[6.7 Summary - 91][6.7 Summary - 91]]
- [[PART 2 FUNCTIONAL DESIGN AND COMBINATOR LIBRARIES - 93][PART 2 FUNCTIONAL DESIGN AND COMBINATOR LIBRARIES - 93]]
  - [[7 Purely functional parallelism - 95][7 Purely functional parallelism - 95]]
    - [[7.1 Choosing data types and functions - 96][7.1 Choosing data types and functions - 96]]
      - [[7.1.1 A data type for parallel computations - 97][7.1.1 A data type for parallel computations - 97]]
      - [[7.1.2 Combining parallel computations - 100][7.1.2 Combining parallel computations - 100]]
      - [[7.1.3 Explicit forking - 102][7.1.3 Explicit forking - 102]]
    - [[7.2 Picking a representation - 104][7.2 Picking a representation - 104]]
    - [[7.3 Refining the API - 105][7.3 Refining the API - 105]]
    - [[7.4 The algebra of an API - 110][7.4 The algebra of an API - 110]]
      - [[7.4.1 The law of mapping - 110][7.4.1 The law of mapping - 110]]
      - [[7.4.2 The law of forking - 112][7.4.2 The law of forking - 112]]
      - [[7.4.3 Breaking the law: a subtle bug - 113][7.4.3 Breaking the law: a subtle bug - 113]]
      - [[7.4.4 A fully non-blocking Par implementation using actors - 115][7.4.4 A fully non-blocking Par implementation using actors - 115]]
    - [[7.5 Refining combinators to their most general form - 120][7.5 Refining combinators to their most general form - 120]]
    - [[7.6 Summary - 123][7.6 Summary - 123]]
  - [[8 Property-based testing - 124][8 Property-based testing - 124]]
    - [[8.1 A brief tour of property-based testing - 124][8.1 A brief tour of property-based testing - 124]]
    - [[8.2 Choosing data types and functions - 127][8.2 Choosing data types and functions - 127]]
      - [[8.2.1 Initial snippets of an API - 127][8.2.1 Initial snippets of an API - 127]]
      - [[8.2.2 The meaning and API of properties - 128][8.2.2 The meaning and API of properties - 128]]
      - [[8.2.3 The meaning and API of generators - 130][8.2.3 The meaning and API of generators - 130]]
      - [[8.2.4 Generators that depend on generated values - 131][8.2.4 Generators that depend on generated values - 131]]
      - [[8.2.5 Refining the Prop data type - 132][8.2.5 Refining the Prop data type - 132]]
    - [[8.3 Test case minimization - 134][8.3 Test case minimization - 134]]
    - [[8.4 Using the library and improving its usability - 136][8.4 Using the library and improving its usability - 136]]
      - [[8.4.1 Some simple examples - 137][8.4.1 Some simple examples - 137]]
      - [[8.4.2 Writing a test suite for parallel computations - 138][8.4.2 Writing a test suite for parallel computations - 138]]
    - [[8.5 Testing higher-order functions and future directions - 142][8.5 Testing higher-order functions and future directions - 142]]
    - [[8.6 The laws of generators - 144][8.6 The laws of generators - 144]]
    - [[8.7 Summary - 144][8.7 Summary - 144]]
  - [[9 Parser combinators - 146][9 Parser combinators - 146]]
    - [[9.1 Designing an algebra, first - 147][9.1 Designing an algebra, first - 147]]
    - [[9.2 A possible algebra - 152][9.2 A possible algebra - 152]]
      - [[9.2.1 Slicing and nonempty repetition - 154][9.2.1 Slicing and nonempty repetition - 154]]
    - [[9.3 Handling context sensitivity - 156][9.3 Handling context sensitivity - 156]]
    - [[9.4 Writing a JSON parser - 158][9.4 Writing a JSON parser - 158]]
      - [[9.4.1 The JSON format - 158][9.4.1 The JSON format - 158]]
      - [[9.4.2 A JSON parser - 159][9.4.2 A JSON parser - 159]]
    - [[9.5 Error reporting - 160][9.5 Error reporting - 160]]
      - [[9.5.1 A possible design - 161][9.5.1 A possible design - 161]]
      - [[9.5.2 Error nesting - 162][9.5.2 Error nesting - 162]]
      - [[9.5.3 Controlling branching and backtracking - 163][9.5.3 Controlling branching and backtracking - 163]]
    - [[9.6 Implementing the algebra - 165][9.6 Implementing the algebra - 165]]
      - [[9.6.1 One possible implementation - 166][9.6.1 One possible implementation - 166]]
      - [[9.6.2 Sequencing parsers - 166][9.6.2 Sequencing parsers - 166]]
      - [[9.6.3 Labeling parsers - 167][9.6.3 Labeling parsers - 167]]
      - [[9.6.4 Failover and backtracking - 168][9.6.4 Failover and backtracking - 168]]
      - [[9.6.5 Context-sensitive parsing - 169][9.6.5 Context-sensitive parsing - 169]]
    - [[9.7 Summary - 171][9.7 Summary - 171]]
- [[PART 3 COMMON STRUCTURES IN FUNCTIONAL DESIGN - 173][PART 3 COMMON STRUCTURES IN FUNCTIONAL DESIGN - 173]]
  - [[10  Monoids - 175][10  Monoids - 175]]
    - [[10.1 What is a monoid? - 175][10.1 What is a monoid? - 175]]
    - [[10.2 Folding lists with monoids - 178][10.2 Folding lists with monoids - 178]]
    - [[10.3 Associativity and parallelism - 179][10.3 Associativity and parallelism - 179]]
    - [[10.4 Example: Parallel parsing - 181][10.4 Example: Parallel parsing - 181]]
    - [[10.5 Foldable data structures - 183][10.5 Foldable data structures - 183]]
    - [[10.6 Composing monoids - 184][10.6 Composing monoids - 184]]
      - [[10.6.1 Assembling more complex monoids - 185][10.6.1 Assembling more complex monoids - 185]]
      - [[10.6.2 Using composed monoids to fuse traversals - 186][10.6.2 Using composed monoids to fuse traversals - 186]]
    - [[10.7 Summary - 186][10.7 Summary - 186]]
  - [[11  Monads - 187][11  Monads - 187]]
    - [[11.1 Functors: generalizing the map function - 187][11.1 Functors: generalizing the map function - 187]]
      - [[11.1.1 Functor laws - 189][11.1.1 Functor laws - 189]]
    - [[11.2 Monads: generalizing the flatMap and unit functions - 190][11.2 Monads: generalizing the flatMap and unit functions - 190]]
      - [[11.2.1 The Monad trait - 191][11.2.1 The Monad trait - 191]]
    - [[11.3 Monadic combinators - 193][11.3 Monadic combinators - 193]]
    - [[11.4 Monad laws - 194][11.4 Monad laws - 194]]
      - [[11.4.1 The associative law - 194][11.4.1 The associative law - 194]]
      - [[11.4.2 Proving the associative law for a specific monad - 196][11.4.2 Proving the associative law for a specific monad - 196]]
      - [[11.4.3 The identity laws - 197][11.4.3 The identity laws - 197]]
    - [[11.5 Just what is a monad? - 198][11.5 Just what is a monad? - 198]]
      - [[11.5.1 The identity monad - 199][11.5.1 The identity monad - 199]]
      - [[11.5.2 The State monad and partial type application - 200][11.5.2 The State monad and partial type application - 200]]
    - [[11.6 Summary - 204][11.6 Summary - 204]]
  - [[12  Applicative and traversable functors - 205][12  Applicative and traversable functors - 205]]
    - [[12.1 Generalizing monads - 205][12.1 Generalizing monads - 205]]
    - [[12.2 The Applicative trait - 206][12.2 The Applicative trait - 206]]
    - [[12.3 The difference between monads and applicative functors - 208][12.3 The difference between monads and applicative functors - 208]]
      - [[12.3.1 The Option applicative versus the Option monad - 209][12.3.1 The Option applicative versus the Option monad - 209]]
      - [[12.3.2 The Parser applicative versus the Parser monad - 210][12.3.2 The Parser applicative versus the Parser monad - 210]]
    - [[12.4 The advantages of applicative functors - 211][12.4 The advantages of applicative functors - 211]]
      - [[12.4.1 Not all applicative functors are monads - 211][12.4.1 Not all applicative functors are monads - 211]]
    - [[12.5 The applicative laws - 214][12.5 The applicative laws - 214]]
      - [[12.5.1 Left and right identity - 214][12.5.1 Left and right identity - 214]]
      - [[12.5.2 Associativity - 215][12.5.2 Associativity - 215]]
      - [[12.5.3 Naturality of product - 216][12.5.3 Naturality of product - 216]]
    - [[12.6 Traversable functors - 218][12.6 Traversable functors - 218]]
    - [[12.7 Uses of Traverse - 219][12.7 Uses of Traverse - 219]]
      - [[12.7.1 From monoids to applicative functors - 220][12.7.1 From monoids to applicative functors - 220]]
      - [[12.7.2 Traversals with State - 221][12.7.2 Traversals with State - 221]]
      - [[12.7.3 Combining traversable structures - 223][12.7.3 Combining traversable structures - 223]]
      - [[12.7.4 Traversal fusion - 224][12.7.4 Traversal fusion - 224]]
      - [[12.7.5 Nested traversals - 224][12.7.5 Nested traversals - 224]]
      - [[12.7.6 Monad composition - 225][12.7.6 Monad composition - 225]]
    - [[12.8 Summary - 226][12.8 Summary - 226]]
- [[PART 4 EFFECTS AND I/O - 227][PART 4 EFFECTS AND I/O - 227]]
  - [[13 External effects and I/O - 229][13 External effects and I/O - 229]]
    - [[13.1 Factoring effects - 229][13.1 Factoring effects - 229]]
    - [[13.2 A simple IO type - 231][13.2 A simple IO type - 231]]
      - [[13.2.1 Handling input effects - 232][13.2.1 Handling input effects - 232]]
      - [[13.2.2 Benefits and drawbacks of the simple IO type - 235][13.2.2 Benefits and drawbacks of the simple IO type - 235]]
    - [[13.3 Avoiding the ~StackOverflowError~ - 237][13.3 Avoiding the ~StackOverflowError~ - 237]]
      - [[13.3.1 Reifying control flow as data constructors - 237][13.3.1 Reifying control flow as data constructors - 237]]
      - [[13.3.2 Trampolining: a general solution to stack overflow - 239][13.3.2 Trampolining: a general solution to stack overflow - 239]]
    - [[13.4 A more nuanced IO type - 241][13.4 A more nuanced IO type - 241]]
      - [[13.4.1 Reasonably priced monads - 242][13.4.1 Reasonably priced monads - 242]]
      - [[13.4.2 A monad that supports only console I/O - 243][13.4.2 A monad that supports only console I/O - 243]]
      - [[13.4.3 Pure interpreters - 246][13.4.3 Pure interpreters - 246]]
    - [[13.5 Non-blocking and asynchronous I/O - 247][13.5 Non-blocking and asynchronous I/O - 247]]
    - [[13.6 A general-purpose IO type - 250][13.6 A general-purpose IO type - 250]]
      - [[13.6.1 The main program at the end of the universe - 250][13.6.1 The main program at the end of the universe - 250]]
    - [[13.7 Why the IO type is insufficient for streaming I/O - 251][13.7 Why the IO type is insufficient for streaming I/O - 251]]
    - [[13.8 Summary - 253][13.8 Summary - 253]]
  - [[14 Local effects and mutable state - 254][14 Local effects and mutable state - 254]]
    - [[14.1 Purely functional mutable state - 254][14.1 Purely functional mutable state - 254]]
    - [[14.2 A data type to enforce scoping of side effects - 256][14.2 A data type to enforce scoping of side effects - 256]]
      - [[14.2.1 A little language for scoped mutation - 256][14.2.1 A little language for scoped mutation - 256]]
      - [[14.2.2 An algebra of mutable references - 258][14.2.2 An algebra of mutable references - 258]]
      - [[14.2.3 Running mutable state actions - 259][14.2.3 Running mutable state actions - 259]]
      - [[14.2.4 Mutable arrays - 262][14.2.4 Mutable arrays - 262]]
      - [[14.2.5 A purely functional in-place quicksort - 263][14.2.5 A purely functional in-place quicksort - 263]]
    - [[14.3 Purity is contextual - 264][14.3 Purity is contextual - 264]]
      - [[14.3.1 What counts as a side effect? - 266][14.3.1 What counts as a side effect? - 266]]
    - [[14.4 Summary - 267][14.4 Summary - 267]]
  - [[15 Stream processing and incremental I/O - 268][15 Stream processing and incremental I/O - 268]]
    - [[15.1 Problems with imperative I/O: an example - 268][15.1 Problems with imperative I/O: an example - 268]]
    - [[15.2 Simple stream transducers - 271][15.2 Simple stream transducers - 271]]
      - [[15.2.1 Creating processes - 272][15.2.1 Creating processes - 272]]
      - [[15.2.2 Composing and appending processes - 275][15.2.2 Composing and appending processes - 275]]
      - [[15.2.3 Processing files - 278][15.2.3 Processing files - 278]]
    - [[15.3 An extensible process type - 278][15.3 An extensible process type - 278]]
      - [[15.3.1 Sources - 281][15.3.1 Sources - 281]]
      - [[15.3.2 Ensuring resource safety - 283][15.3.2 Ensuring resource safety - 283]]
      - [[15.3.3 Single-input processes - 285][15.3.3 Single-input processes - 285]]
      - [[15.3.4 Multiple input streams - 287][15.3.4 Multiple input streams - 287]]
      - [[15.3.5 Sinks - 290][15.3.5 Sinks - 290]]
      - [[15.3.6 Effectful channels - 291][15.3.6 Effectful channels - 291]]
      - [[15.3.7 Dynamic resource allocation - 201][15.3.7 Dynamic resource allocation - 201]]
    - [[15.4 Applications - 292][15.4 Applications - 292]]
    - [[15.5 Summary - 293][15.5 Summary - 293]]
- [[Tips][Tips]]

* foreword
  - _It would be nice_ if we could distinguish pure and impure functions in
    Scala,
    (but) I believe we _have not yet found_ a way to do so that is lightweight
    and flexible enough to be added to Scala without hesitation.

* preface
* acknowledgments
* DONE about this book
  CLOSED: [2017-03-18 Sat 04:51]

** How this book is structured =IMPORTANT=
   - wiki: https://github.com/fpinscala/fpinscala/wiki
** Audience
   - We WON'T spend a lot of time and space discussing Scala's syntax and
     language features.

   - References:
     + Book: http://scala-lang.org/documentation/books.html
     + Doc: http://scala-lang.org/documentation/

** How to read this book
   - A _filled-in square_ next to an exercise means the exercise is _CRITICAL_.
   - An _open square_ means the exercise is _OPTIONAL_.
** Code conventions and downloads
** Setting expectations
   - Take your questions to
     + the Google Group: https://groups.google.com/forum/#!topic/scala-functional/ or
     + the IRC channel (=#fp-in-scala= on =irc.freenode.net=).

** Author Online

_EN_:
intriguing title
haphazardly
a patchwork of
mourn
Coalesce

* TODO Part 1 Introduction to functional programming - 1
  - We BEGIN this book with a _radical premise_:
    that we will *restrict* ourselves to constructing programs *using only pure
    functions* with no side effects such as reading from files or mutating memory.

    This idea, of /functional programming/, leads to a very different way of
    writing programs than you may be used to.
      We therefore start from the very beginning, *relearning* how to write the
    simplest of programs *in a functional way*.

  - Outlines for the Chapter 1 ~ 6:
    + Chapter 1 explains exactly
      * *WHAT* functional programming means
        AND
      * give you some idea of its *benefits*.

    + The rest of the chapters in part 1 introduce the _basic techniques_ for
      /functional programming/ in Scala.
      * Chapter 2 introduces Scala the language and covers fundamentals LIKE
        - how to write loops functionally

        - manipulate functions as ordinary values.

      * Chapter 3 deals with /in-memory data structures/ that may change over time.

      * Chapter 4 talks about _handling errors in pure functions_, and

      * Chapter 5 introduces the *notion* of /non-strictness/, which can be used
        to improve the /efficiency/ and /modularity/ of functional code.

      * Chapter 6 introduces _modeling STATEFUL programs using pure functions_.

  - The intent of this first part of the book is
    * to get you thinking about programs purely in terms of functions from inputs
      to outputs,
      and
    * to teach you the techniques you'll need in part 2, when we start writing
      some practical code.

** DONE 1 What is functional programming? - 3
   CLOSED: [2017-03-15 Wed 21:01]
   - A function has a /side effect/ if it does something
     /other than simply return a result/, for example:
     + Modifying a variable
     + Modifying a data structure in place
     + Setting a field on an object
     + Throwing an exception or halting with an error =TODO=
     + Printing to the console or reading user input
     + Reading from or writing to a file
     + Drawing on the screen

   - Q: Then how is it even possible to write useful programs at all?
     A: functional programming
     + is _a restriction on_ _HOW_ we write programs,
     + but _not_ on _WHAT_ programs we can express.

   - Over the course of this book, we'll learn how to express all of our
     programs without side effects, and that includes programs that perform I/O,
     handle errors, and modify data.

   - _tremendously beneficial_ of FP: the increase in /modularity/

   - Because the increased /modularity/, pure functions are easier to
     + test
     + reuse
     + parallelize
     + generalize
     + reason about

   - /referential transparency/

   - /the substitution model/

*** 1.1 The benefits of FP: a simple example - 4
**** 1.1.1 A program with side effects - 4
**** 1.1.2 A functional solution: removing the side effects - 6
     - FP is a truly radical shift in _how programs are organized_
       at every level -- _from_ the simplest of loops _to_ high-level program
       architecture_.
*** 1.2 Exactly what is a (pure) function? - 9
    - ~A => B~ is pronounced as "A to B" or "A arrow B".

    - A function has _NO observable effect_ on the execution of the program
      _other than_ to compute a result given its inputs;
      we say that it has _no side effects_.

    - /Referential transparency (RT)/ :: An expression e is referentially trans-
         parent if, for all programs p, all occurrences of e in p can be replaced
         by the result of evaluating e without affecting the meaning of p.

    - /purity/ :: A function f is /pure/ if the expression f(x) is referentially
                  transparent for all referentially transparent x.

*** 1.3 Referential transparency, purity, and the substitution model - 10
    - Referential transparency _force/enables_ /substitution model/

    - Computation proceeds by applying /substitution model/ (substituting
      /equals for equals/).
        In other words, RT enables /equational reasoning/ about programs.

    - Two examples,
      1. a RT example
      2. a non-RT example

    - RT featured code a purely local, and we NEED NOT mentally simulate
      sequences of state updates to understand the code. ONLY /local reasoning/.

    - RT => pure locality (only the expression being evaluated) => /modularity/
                                                                        |
                                                                        V
                                                                 /composability/ 

    - A pure function is /modular/ and /composable/
      because it _separates_
      the logic of the computation itself
                   _from_
      âwhat to do with the resultâ and âhow to obtain the inputâ; it's a black
      box.

    - From the process of eliminating the side effect from the ~buyCoffee~
      example, we were more easily to be able to reuse the logic of the function,
      both for purposes of _testing_ and for purposes of _further composition_.

*** 1.4 Summary - 13

** DONE 2 Getting started with functional programming in Scala - 14
   CLOSED: [2017-04-05 Wed 16:52]
   - /tail recursive functions/

   - /higher-order functions (HOFs)/

   - /polymorphic HOFs/

*** DONE 2.1 Introducing Scala the language: an example - 15
    CLOSED: [2017-03-15 Wed 21:37]
    - A method of ~String~: ~format~ with C language like placeholder.

    - If you're familiar with Java,
      declaring an ~object~ in Scala
      is a lot _like_
      creating a _new instance of an anonymous class_.

    - Scala has no equivalent to Java's ~static~ keyword, and ~object~ is often
      used in Scala where you might use a class with static members in Java.

    - /left-hand side/ or /signature/: the part of declaration _before_ the
      equals sign.

    - /right-hand side/ or /definition/: the part of declaration _after_ the
      equals sign.

    - Finally, our ~main~ method is an outer shell that calls into our purely
      functional core and prints the answer to the console.
        We'll sometimes call such methods /procedures (or impure functions)/
      rather than functions.
      #+BEGIN_SRC scala
      def main(args: Array[String]): Unit =
        println(formatAbs(-42))
      #+END_SRC

*** DONE 2.2 Running our program - 17
    CLOSED: [2017-03-18 Sat 03:11]
    - Book's source code repo: http://github.com/fpinscala/fpinscala

    - Compilation way:
      #+BEGIN_SRC bash
      #>
      scalac MyModule.scala
      # Then get MyModule.class
      #>
      scala MyModule
      #+END_SRC

    - Interpretation Way:
      #+BEGIN_SRC bash
      #>
      scala MyModule.scala
      #+END_SRC

    - Interactive Interpretation Way:
      + ~:load~
        #+BEGIN_SRC scala
        //> scala   # in shell

        // scala> :load MyModule.scala
        // Loading MyModule.scala...
        // defined module MyModule

        // scala>
        MyModule.abs(-42)
        // res0: Int = 42
        #+END_SRC

      + ~:paste~

*** DONE 2.3 Modules, objects, and namespaces - 18
    CLOSED: [2017-03-18 Sat 03:20]
    - /namespace/

    - Every value in Scala is what's called an /object/

    - /module/: An object whose _primary purpose_ is giving its members a
      /namespace/.

    - A member can be declared with ~def~, ~val~, or ~object~, etc (=TODO=).

    - TWO ways to access members within their enclosing object:
      + unqualified (without prefixing the object name)
      + ~this~ prefixed/qualified

    - Scala has no special notion of /operators/. ONLY method calls.

    - Single argument methods can be used as infix operations:
      + ~MyModule.abs(42)~ is the same as ~Module abs 42~.
      + ~set1.union(set2)~ is the same as ~set1 union set2~.

*** DONE 2.4 Higher-order functions: passing functions to functions - 19
    CLOSED: [2017-04-05 Wed 16:52]
    - _functions are values_

    - /higher-order function (HOF)/: A function that accepts other functions as
      arguments.

**** 2.4.1 A short detour: writing loops functionally - 20
     - /inner function (or local definition)/: functions that are local to the
       body of another function.
       =COMMENT= In functional programming, we shouldn't consider this a bigger
                 deal than local integers or strings

**** 2.4.2 Writing our first higher-order function - 21
     - _Variable-naming conventions_: It's a common convention to use names like
       ~f~, ~g~, and ~h~ for parameters to a higher order function.
          In functional programming, we tend to use very short variable names,
       even one-letter names.

     - _Rationale to Variable-naming conventions_:
       + This is usually because HOFs are so general that they have no opinion
         on what the argument should actually do.
           All they know about the argument is its type.

       + Many functional programmers feel that short names make code easier to
         read, since it makes the structure of the code easier to see at a
         glance.

*** DONE 2.5 Polymorphic functions: abstracting over types - 22
    CLOSED: [2017-03-18 Sat 04:18]
    - /monomorphic/

    - /polymorphic/

**** 2.5.1 An example of a polymorphic function - 23
     - a /polymorphic/ function, sometimes called a /generic/ function.

     - _Type Parameter Names Convention_: Use short, one-letter, uppercase type
       parameter names like [ ~A~, ~B~, ~C~ ].

     - /type variables/

**** 2.5.2 Calling HOFs with anonymous functions - 24
     - /anonymous functions/ and /function literals/ have the same meaning.
       Example:
       #+BEGIN_SRC scala
       (x: Int) => x == 9
       #+END_SRC

     - _Functions as values in Scala_: =TODO: RE-READ=
       + When we define a /function literal/, what is ACTUALLY being defined in
         Scala is
         an _object_ with a method called ~apply~.

       + Scala has a special rule for this method name, so that objects that have
         an ~apply~ method can be called _as if they were themselves methods_.

       + When we define a /function literal/ like ~(a, b) => a < b~, this is
         REALLY /syntactic sugar/ for /object/ creation:
         #+BEGIN_SRC scala
         val lessThan = new Function2[Int, Int, Boolean] {
           def apply(a: Int, b: Int) = a < b
         }
         #+END_SRC
         Here
         * ~lessThan~ has type ~Function2[Int, Int, Boolean]~, which is usually
           written ~(Int, Int) => Boolean~.
         * ~Function2~ is an oridinary (provided by the standard Scala library)
           trait, and it has an ~apply~ method. It represent function objects
           that take two arguments. Also provied are ~Function1~, ~Function3~,
           and others.
         * ~lessThan(10, 20)~ is REALLY syntatic sugar for calling its ~apply~
           method: ~lessThan.apply(10, 20)~
         * /first-class values/: ordinary Scala objects.
         * We'll often use /function/ to refer to either such a first-class
           function or a method, _depending on context_.

*** DONE 2.6 Following types to implementations - 25
    CLOSED: [2017-03-18 Sat 16:22]
    - In some cases, you'll find that the universe of possibilities for a given
      polymorphic type is constrained such that _ONLY ONE_ implementation is
      possible!

    - ~compose~:
      #+BEGIN_SRC scala
      def compose(f: B => C, g: A => B): A => C =
        x => f(g(x))
      #+END_SRC

    - ~andThen~: ~g andThen f~ is the same as ~f compose g~.

    - Polymorphic, higher-order functions often end up being _extremely widely
      applicable_,
      precisely because they say nothing about any particular domain and are
      simply abstracting over a common pattern that occurs in many contexts.

*** DONE 2.7 Summary - 28
    CLOSED: [2017-03-18 Sat 04:20]

** DONE 3 Functional data structures - 29
   CLOSED: [2017-03-18 Sat 22:02]
*** DONE 3.1 Defining functional data structures - 29
    CLOSED: [2017-03-18 Sat 16:37]
    - /functional data structures/ are by definition _immutable_.

    - Adding ~sealed~ in front means that all implementations of the ~trait~
      _MUST_ be declared in this file.

    - the ~+~ indicates that the type parameter ~A~ is covariant -- see sidebar
      "More about variance" for more information.

    - Each data constructor also introduces a /pattern/ that can be used for
      /pattern matching/ as in the given examples.

    - _More about variance_ =RE-READ=

*** DONE 3.2 Pattern matching - 32
    CLOSED: [2017-03-18 Sat 17:21]
    - _Companion objects in Scala_
      Companion objects are more of a convention in Scala.

    - _Variadic functions in Scala_ =TODO: RE-READ=
      Example:
      #+BEGIN_SRC scala
      def apply[A] (as: A*): List[A] =
        if (as.isEmpty) Nil
        else Cons(as.head, apply(as.tail: _*))
      #+END_SRC
      For data types,
      + it's a common idiom to have a _variadic_ ~apply~ method in the companion
        object to conveniently construct instances of the data type.

      + By placing it in the companion object, we can invoke it with syntax like
        ~List(1,2,3,4)~ or ~List("hi","bye")~, with as many values as we want
        separated by commas (we sometimes call this the /list literal/ or just
        /literal syntax/).

      + Variadic functions are just providing a little
        _syntactic sugar_
        for
        creating and passing a ~Seq~ of elements explicitly.

      + ~Seq~ is the interface in Scala's collections library implemented by
        sequence. Inside apply, the argument ~as~ will be bound to a ~Seq[A]~,
        The special ~_*~ type annotation allows us to pass a ~Seq~ to a variadic
        method.

*** DONE 3.3 Data sharing in functional data structures - 35
    CLOSED: [2017-03-18 Sat 18:34]
    - /data sharing/: The new data reuses the immutable data.
      Example:
      1. ~Cons(1, xs)~ doesn't copy =xs=.
      2. _tail_ operation doesn't real remove the head from a list, just returns
         a new reference pointer to the same linked list but a different element.

    - Sharing of immutable data often lets us implement functions more
      efficiently

    - footnote 6:
      Conclusion: We find that _in the large_, FP can often achieve _greater_
      efficiency than approaches that rely on side effects,
      _due to much greater sharing of data and computation_.

    - /persistent/

    - =TODO= Exercise 3.2

**** 3.3.1 The efficiency of data sharing - 36
     - Adds all the elements of one list to the end of another:
       #+BEGIN_SRC scala
       def append[A](a1: List[A], a2: List[A]): List[A] =
         a1 match {
           case Nil => a2
           case Cons(h,t) => Cons(h, append(t, a2))
         } 
       #+END_SRC
       The time complexity is O(a2.length)

     - If we were to implement this same function for two arrays, which is
       mutable in Scala,
       we'd be forced to _copy all_ the elements in both arrays into the result.
       In this case, the immutable linked list is much more efficient than an array!

     - Writing purely functional data structures that support different opera-
       tions efficiently
       _is all about finding clever ways to exploit data sharing_. =IMPORTANT=

     - Exercise 3.6,
       Q: Why can't this function be implemented in constant time like ~tail~?
       A: One ~case~ in pattern matching of this function body is
          ~case Cons(hd, tl) => Cons(hd, init(tl))~, which shows a copying
          operation and ~Cons~ construction.
          =Jian's Sentiment=: A linked list can be pointed by multiple head, but
                              it can't point to multiple tails.
          =IMPORTANT=

     - =TODO: Learn Vector in Scala standard library=

**** 3.3.2 Improving type inference for higher-order functions - 37
     - We _must_ annotate the type of the argument of ~f~,
       If we have ~dropWhile~ with the signature of
       ~def dropWhile[A](l: List[A], f: A => Boolean): List[A]~,
       #+BEGIN_SRC scala
       val xs: List[Int] = List(1, 2, 3, 4, 5)
       val ex1 = dropWhile(xs, (x: Int) => x < 4)
       #+END_SRC

     - We can group the arguments to improve type inference,
       If we have ~dropWhile~ with the signature of
       ~def dropWhile[A](l: List[A])(f: A => Boolean): List[A]~,
       #+BEGIN_SRC scala
       val xs: List[Int] = List(1, 2, 3, 4, 5)
       val ex1 = dropWhile(xs)(x => x < 4)
       #+END_SRC
       
     - We'll often group and order our function arguments into multiple argument lists
       to maximize type inference.
*** DONE 3.4 Recursion over lists and generalizing to higher-order functions - 38
    CLOSED: [2017-03-18 Sat 21:34]
    - _Underscore notation for anonymous functions_
      + The anonymous function ~(x,y) => x + y~ can be written as ~_ + _~ in
        situations where the types of ~x~ and ~y~ _could be inferred_ by Scala.

      + This is a useful shorthand in cases where _the function parameters are
        mentioned just once_ in the body of the function.

      + _Each underscore_ in an anonymous function expression like ~_ + _~
        _introduces a new (unnamed) function parameter_ and references it.

      + Arguments are introduced in _left-to-right order_.

    - Exercise 3.7 =TODO= Return to in chapter 5
      =Jian's Answer (now)=: For now, I can't add any short-circuit behavior
      to them without adding a ~if...else...~ test to eache of them.

**** 3.4.1 More functions for working with lists - 41
***** LISTS IN THE STANDARD LIBRARY
      - We'll use the standard library version in subsequent chapters.

      - Differences between
        our ~List~ library
        and 
        The ~List~ in the standard library:
        + We developed ~Cons~.
        + In the standard library, ~Cons~ is called ~::~, which is a
          right-associate infix operator.

      - Useful ~List~ methods in the standard library:
        + ~def take(n: Int): List[A]~
        + ~def takeWhile(f: A => Boolean): List[A]~
        + ~def forall(f: A => Boolean): Boolean~ is like the bulit-in ~all~ in
          Python.
        + ~def exists(f: A => Boolean): Boolean~ is like the bulit-in ~any~ in
          Python.
        + ~scanLeft~ and ~scanRight~ returns the List of partial results.

**** TODO 3.4.2 Loss of efficiency when assembling list functions from simpler components - 44
     - One of the problems with ~List~ is that,
       + _GOOD_: although we can often express operations and algorithms in terms
         of _very general-purpose functions_,

       + _BAD_: the resulting _implementation isn't always efficient_ -- * we may
         * end up making _multiple passes_ over the same input, or else
         * have to write _explicit recursive loops_ to _allow early termination_.

     - =TODO= EXERCISE 3.24, improve on it in chapter 5

*** DONE 3.5 Trees - 44
    CLOSED: [2017-03-18 Sat 22:01]
    - /Algebraic Data Type (ADT)/

    - Somewhat confusingly, ADT is sometimes used elsewhere to stand for
      /ABSTRACT data type/.

    - =TODO= footnote 14 =TODO=

    - _Tuple types in Scala_
      + ~(String,Int)~, which is syntactic sugar for ~Tuple2[String,Int]~.

    - Tree data structure:
      #+BEGIN_SRC scala
      sealed trait Tree[+A]
      case class Leaf[A] (value: A) extends Tree[A]
      case class Branch[A] (left: Tree[A], right: Tree[A]) extends Tree[A]
      #+END_SRC

    - Pattern matching again provides a convenient way of operating over elements
      of our ADT. =IMPORTANT=

    - _ADTs and encapsulation_:
      + Objection to ADTs ::
           _algebraic data types violate encapsulation by making public the_
           _internal representation of a type_.

      + Things are different in FP ::
           In FP, we approach concerns about encapsulation differently
        * we don't typically have delicate mutable state which could lead to
          bugs or violation of invariants if exposed publicly.

        * _Exposing_ the _data constructors_ of a type is _often fine_, and
          the decision to do so is approached much like any other decision about
          what the public API of a data type should be.

    - =TODO= footnote 15 I don't understand.

*** DONE 3.6 Summary - 47
    CLOSED: [2017-03-18 Sat 22:02]

** DONE 4 Handling errors without exceptions - 48 =ing...=
   CLOSED: [2018-06-28 Thu 01:16]
   - The functional solution, of returning errors as values, is
     + safer and
     + retains referential transparency,
     and through the use of higher-order functions, we can preserve the
     _primary benefit_ of exceptions -- /consolidation of error-handling logic/.

*** DONE 4.1 The good and bad aspects of exceptions - 48
    CLOSED: [2017-03-19 Sun 23:05]
    - NO RT and substitution model can be applied:
      #+BEGIN_SRC scala
      def failingFn(i: Int): Int = {
        val y: Int = throw new Exception("fail!")

        try {
          val x = 42 + 5
          x + y
        }
        catch { case e: Exception => 43 }
      }
      #+END_SRC

      is different from 
      #+BEGIN_SRC scala
      def failingFn(i: Int): Int = {
        try {
          val x = 42 + 5
          x + (throw new Exception("fail!"))
        }
        catch { case e: Exception => 43 }
      }
      #+END_SRC

    - There are _two_ main problems with /exceptions/:
      1. /Exceptions/ break /referential transparency/ and
         introduce /context dependence/,

      2. /Exceptions/ are *NOT* /type-safe/.
         For example: There is a function ~failingFn: Int => Int~.
         * It tells us nothing about the fact that  /exceptions/ may occur.

         * It doesn't force us to handle those exceptions.

         * If we forget to check for an exception in ~failingFn~, this won't be
           detected until runtime.

    - _Checked exceptions_: Java's checked exceptions
      + GOOD: _at least_ force a decision about whether to handle or reraise an
        error

      + BAD:
        * significant boilerplate for callers

        * Don't work for higher-order functions. For example:
          #+BEGIN_SRC scala
          def map[A,B](l: List[A])(f: A => B): List[B] = {
            // ...
          }
          #+END_SRC
          This ~map~ doesn't know what exceptions were possible be thrown by ~f~.

    - _Primary benefit of exceptions_
      They allow us to /consolidate/ and /centralize error-handling/ _logic_,

    - The technique we use is based on an old idea:
      _instead of_ *throwing* an /exception/,
      we *return* a /value/ indicating that an exceptional condition has occurred.
      This is like the /return codes/ in the C language.

    - However, unlike C-style error codes,
      + the error-handling strategy we use is /completely type-safe/, and

      + we get full assistance from the type-checker in *forcing* us to deal with
        errors,

      + with a minimum of syntactic noise.

        =From Jian=
        Avoid error-handling blocks before you really want to deal with it.

        In Java, you must re-throw the /exception/ if you don't want to deal with
        it in some places.

*** DONE 4.2 Possible alternatives to exceptions - 50
    CLOSED: [2017-03-19 Sun 23:05]
    - /partial function/: it's not defined for some inputs.

    - A function is typically /partial/
      BECAUSE it _makes some assumptions_ about its inputs that are *NOT implied
      by the /input types/.*

    - One "solution" is to return some sort of _bogus value_ of its type, this is
      how error handling is often doen in languages WITHOUT /exceptions/.
      We *REJECT* this solution for a few reasons:
      1. It allows errors to silently propagate
         * Callers should check this condition manually, but they may forget
           (error-prone).

         * If a caller forgets to check this, compiler won't alert because the
           returned value is legal.

         * Often the error won't be detected until much later in the code.

      2. It a caller do the right thing to check the error codes, he/she at same
         time introduces a fair amout of boilerplate code at each errorcode-check
         required call site.

      3. It's not applicable to polymorphic code. You CANNOT find a proper value
         for all possible types of the type variable ~A~.
         _NOTE_: ~null~ doesn't work for /primitive types/.

         =From Jian= Even if Scala's /primitive types/ can have /methods/, which
         is different from Java, they still CANNOT be assigned with ~null~.
         =???= A wierd design?!

      4. It demands a _special policy_ or _calling convention of callers_ --
         proper use of this kind of functions would require that callers do
         something other than call ~mean~ and make use of the result.
           Giving functions special policies like this makes it difficult to
         pass them to higher-order functions, which must treat all arguments
         uniformly.

    - The second possibile "solution" is to force the call to supply an argument
      that tells us what to do in case we don't know how to handle the input,
      for example:
      #+BEGIN_SRC scala
      def mean_1(xs: IndexedSeq[Double], onEmpty: Double): Double =
        if (xs.isEmpty) onEmpty
        else xs.sum / xs.length
      #+END_SRC
      It has DRAWBACKS -- it requires
      1. _immediate callers_ have direct knowledge of how to handle the undefined
         case
         and
      2. limits them to returning a ~Double~ (the type of the addtional argument).
           What if ~mean_1~ is called as part of a larger computation and we'd
         like to abort that computation if /mean/ is undefined?
         Or
           perhaps we'd like to take some completely different branch in the
         larger computation in this case?

         Simply passing an ~onEmpty~ parameter doesn't give us this freedom.

*** DONE 4.3 The ~Option~ data type - 52
    CLOSED: [2018-06-27 Wed 20:42]
    - The solution is to represent EXPLICITLY in the /return type/ that
      a function _may not always_ have an answer.
        We can think of this as _DEFERRING_ to the caller for the error-handling
      strategy.

    - Re-creating the ~Option~ type in the Scala standard library:
      #+BEGIN_SRC scala
        sealed trait Option[+A]
        case class Some[+A](get: A) extends Optioin[A]
        case object None extends Option[Nothing]
      #+END_SRC

**** DONE 4.3.1 Usage patterns for ~Option~ - 53
     CLOSED: [2018-06-27 Wed 18:44]
***** BASIC FUNCTIONS ON OPTION
      - Listing 4.2 The ~Option~ data type
        #+BEGIN_SRC scala
          trait Option[+A] {
            def map[B](f: A => B): Option[B]
            def flatMap[B](f: A => Option[B]): Option[B]
            def getOrElse[B >: A](default: => B): B
            def orElse[B >: A](ob: => Option[B]): Option[B]
            def filter(f: A => Boolean): Option[A]
          }
        #+END_SRC

***** USAGE SCENARIOS FOR THE BASIC OPTION FUNCTIONS
      - ~Option[A].map(f)~:
        1. proceeding with a computation on the assumption that an error hasn't
           occurred;
        2. deferring the error handling to later code.

      - ~Option[A].flatMap(f)~ is similar, except that the function we provide
        to transform the result can itself fail.

      - EXERCISE 4.2:
        I don't like the /anonymous function/ passed ~flatMap~ in this exercise --
        it's too long to understand with only one glance.

        My solution:
        #+BEGIN_SRC scala
          def variance(xs: Seq[Double]): Option[Double] =
            for {
              m <- mean(xs)
              r <- mean(xs.map(x => math.pow(x - m, 2)))
            } yield r
        #+END_SRC

      - We can use ~filter~ to *CONVERT successes INTO failures* _if the successful
        values DO NOT MATCH the given predicate_.

      - _A common pattern_:
        transform an ~Option~ via calls to ~map~, ~flatMap~, and/or ~filter~,
        and then
        use ~getOrElse~ to _do error handling_ at the end:
        #+BEGIN_SRC scala
        val dept: String =
          lookupByName("Joe").
          map(_.dept).
          filter(_ != "Accounting").
          getOrElse("Default Dept")
        #+END_SRC

      - ~orElse~: this is often useful when we need to _chain together possibly
        failing computations_, trying the second if the first hasn't succeeded.

      - A common idiom is to do ~o.getOrElse(throw new Exception("FAIL"))~ to convert
        the ~None~ case of an ~Option~ back to an exception.

        _The general rule of thumb_:
        We use /exceptions/ *ONLY* _if NO REASONABLE program would ever catch the
        exception_.

      - _Note_:
        1. We don't have to check for ~None~ at each stage of the computation --
           we can apply several transformations and then check for and handle
           ~None~ when we're ready -- the computation will _stop immediately_
           when it notice nothing need to be done, for example, ~map~, ~flatMap~,
           and ~filter~ has no cost if the ~this~ is ~None~.

        2. But we _also get additional safety_:
           since ~Option[A]~ is a DIFFERENT type than ~A~, the compiler will *NOT*
           let us forget to explicitly defer or handle the possibility of ~None~.

**** DONE 4.3.2 ~Option~ composition, lifting, and wrapping exception-oriented APIs - 56
     CLOSED: [2018-06-27 Wed 20:42]
     - Q :: How to apply a ~Option~ _unrelated_ functions to an ~Option~ value
            *WITHOUT* rewrite a whole function?

     - A :: We can use /lift/:
       #+BEGIN_SRC scala
         def lift[A, B](f: A => B): Option[A] => Option[B] = _ map f
       #+END_SRC

     - One example of applying ~lift~:
       ~val absO: Option[Double] => Option[Double] = lift(math.abs)~

     - The ~Try~ function is a general-purpose function we can use to *convert _FROM_
       an exception-based API _TO_ an ~Option~-oriented API*.
         This uses a non-strict or lazy argument, as indicated by the ~=> A~ as the
       /type/ of ~a~.
       #+BEGIN_SRC scala
         def parseInsuranceRateQuote(
             age: String,
             numberOfSpeedingTickets: String): Option[Double] = {
           val optAge: Option[Int] = Try(age.toInt)
           val optTickets: Option[Int] = Try(numberOfSpeedingTickets.toInt)
           insuranceRateQuote(optAge, optTickts)
         }

         def Try[A](a: => A): Option[A] =
           try Some(a)
           catch { case e: Exception => None }
       #+END_SRC

     - =Exercise 4.3
       Implement ~def map2[A, B, C](a: Option[A], b: Option[B])(f: (A, B) => C): Option[C]~

     - With ~map2~, we can do:
       #+BEGIN_SRC scala
         def parseInsuranceRateQuote(
             age: String,
             numberOfSpeedingTickets: String): Option[Double] = {
           val optAge: Option[Int] = Try { age.toInt }
           val optTickets: Option[Int] = Try { numberOfSpeedingTickets.toInt }
           map2(optAge, optTickes)(insuranceRateQuote)
         }
       #+END_SRC

     - Exercise 4.4
       ~def sequence[A](a: List[Option[A]]): Option[List[A]]~

     - Exercise 4.5
       ~def traverse[A, B](a: List[A])(f: A => Option[B]): Option[List[B]]~

     - *For-comprehensions*

       =From Jian= I prefer ~for~-comprehensions in some senarios -- they
       sometimes can be less clutter then using the /methods/ of ~Option~
       directly.
         I give my solution to solve Exercise 4.2 above with ~for~-comprehension.

     - =IMPORTANT=
       Between ~map~, ~lift~, ~sequence~, ~traverse~, ~map2~, ~map3~, and so on,
       you should _NEVER have to modify any existing functions_ to work with
       optional values.

*** DONE 4.4 The ~Either~ data type - 60
    CLOSED: [2018-06-28 Thu 01:16]
    The _big idea_ in this chapter:
    Represent _failures_ and /exceptions/ with _ordinary values_, and write
    functions that abstract out common patterns of error handling and recovery.

    - ~Option~ never tells you what went wrong, and it only tells there is no
      available value. Sometimes, we may need more information.

    - ~Either~ basic Definition:
      #+BEGIN_SRC scala
        sealed trait Either[+E, +A]
        case class Left[+E](value: E) extends Either[E, Nothing]
        case class Right[+A](value: A) extends Either[Nothing, A]
      #+END_SRC
      It is a /disjoint union/ of _two_ types.

    - ~Either~ is also often used more generally to encode one of two
      possibilities in cases where it isn't worth defining a fresh data type.

    - ~Option~ and ~Either~ in the standard library
      + Read both API's in the Scala standard library.

      + ~Either~ doesn't define a right-biased ~flatMap~ directly like we do here
        (in this chapter).

    - Examples:
      + ~mean~
        #+BEGIN_SRC scala
          def mean(xs: IndexedSeq[Double]): Either[String, Double] =
            if (xs.isEmpty)
              Left("mean of empty list!")
            else
              Right(xs.sum / xs.length)
        #+END_SRC

      + Sometimes we might want to include more information about the error, for
        example a stack trace showing the location of the error in the source
        code. In such cases we can simply return the exception in the ~Left~
        side of an ~Either~:
        #+BEGIN_SRC scala
          def safeDiv(x: Int, y: Int): Either[Exception, Int] =
              try Right(x / y)
              catch { case e: Exception => Left(e) }
        #+END_SRC

    - As we did with ~Option~ , we can write a function, ~Try~, which _factors
      out_ this common pattern of converting /thrown exceptions/ to values:
      #+BEGIN_SRC scala
        def Try[A](a: => A): Either[Exception, A] =
          try Right(a)
          catch { case e: Exception => Left(e) }
      #+END_SRC

    - EXERCISE 4.6

    - EXERCISE 4.7

    - EXERCISE 4.8

*** DONE 4.5 Summary - 63
    CLOSED: [2018-06-28 Thu 01:16]
    - The bigger idea:
      + represent exceptions _as ordinary values_

      + use higher-order functions to encapsulate common patterns of
        _handling_
        and
        _propagating_ errors.

        =From Jian= Rather than *explicit* /pattern matching/.

    - =TODO= In the next chapter, we'll look more closely at why /non-strictness/
      is important and how it can buy us greater modularity and efficiency in our
      functional programs.

** DONE 5 Strictness and laziness - 64
   CLOSED: [2017-03-22 Wed 21:40]
   - Inefficiency example:
     ~List(1,2,3,4).map(_ + 10).filter(_ % 2 == 0).map(_ * 3)~
     + _COMMENT_: During the calculation of this example, two temporary lists are
       created, and they are used once and discard immediately.
     + _QUESTION_: Can we create a more efficiency calculation about this, but
       keep the same highlevel composition style (Write a ~while~ loop can
       eliminate the intermediate temporary lists, but it won't retain the
       highlevel composition style)?
       
   - =From Jian=: I think _function composition_ is a good solution, but this
     chapter will talk about another solution: _non-strictness functions_.
     + _I THINK_ provide an example that can't be solved simply through function
       composition will be better.

     + _function composition_ solution: from the OPERATION viewpoint.

     + _non-strictness functions_ solution: from the
       * non-strictness DATA STRUCTION
       * non-strictness functions
       viewpoint.

   - We'll see that /non-strictness/ _is a fundamental technique_ for improving
     on the
     + efficiency and
     + modularity
     of functional programs in general.

*** 5.1 Strict and non-strict functions - 65
    - Complete form:
      #+BEGIN_SRC scala
      def if2[A](cond: Boolean, onTrue: () => A, onFalse: () => A): A =
        if (cond) onTrue() else onFalse()

      // call
      if2(a < 22,
        () => println("a"),
        () => println("b")
      )
      #+END_SRC

    - Syntactic Sugared form:
      #+BEGIN_SRC scala
      def if2[A](cond: Boolean, onTrue: => A, onFalse: => A): A =
        if (cond) onTrue else onFalse 
      #+END_SRC

    - That is, Scala _won't (by default) cache_ the result of evaluating an
      argument.
        This is not a big trouble in strict evaluation, while it is a big
      trouble in no-strict evaluation. Use ~lazy~ to cache the value:
      #+BEGIN_SRC scala
      // uncached
      def maybeTwice2(b: Boolean, i: => Int) =
        if (b) i+i else 0
      
      // cached
      def maybeTwice2(b: Boolean, i: => Int) = {
        lazy val j = i
        if (b) j+j else 0
      }
      #+END_SRC

    - _Formal definition of strictness_
      If the evaluation of an expression runs forever or throws an error instead
      of returning a definite value, we say that the expression doesn't
      terminate, or that it evaluates to bottom.

    - /strictness/: A function f is strict if the expression f(x) evaluates to
      bottom for all x that evaluate to bottom.

    - Non-strict function in Scala takes its arguments by name rather than by
      value.

*** 5.2 An extended example: lazy lists - 68
**** 5.2.1 Memoizing streams and avoiding recomputation - 69
     - _CONVENTION_: /smart constructors/ typically lowercase the first letter of
       the corresponding data constructor.

     - Comparison of constructor ~Cons~ and the smart constructor ~cons~:
       #+BEGIN_SRC scala
       // #1
       val x = Cons(() => expensive(x), tl)
       val h1 = x.headOption
       val h2 = x.headOption
       
       // #2
       def cons[A] (hd: => A, tl: => Scream[A]): Stream[A] = {
         lazy val head = hd
         lazy val tail = tl
         Cons(() => head, () => tail)
       }
       #+END_SRC
       _Comment_:
       1. Evaluate the head twice
       2. When applying ~cons~, cache =head= and =tail= by ~lazy val~ through
          the first force.
          Subsequent forces will return the cached ~lazy val~'s.

     - The ~empty~ smart constructor just returns ~Empty~, but annotates ~Empty~
       as a ~Stream[A]~, which is better for type inference in some cases.
       + _footnote 4_: Recall that Scala uses subtyping to represent data
         constructors, but we almost always want to infer Stream as the type,
         not Cons or Empty. Making smart constructors that return the base type
         is a common trick. =TODO: Better for type inference for what???=

**** 5.2.2 Helper functions for inspecting streams - 69
*** 5.3 Separating program description from evaluation - 70
    - A major theme in functional programming:
      /separation of concerns/.

    - For example,
      1. First-class functions capture some computation in their bodies but only
         execute it once they receive their arguments.

      2. Used ~Option~ to capture the fact that an error occurred, where the
         decision of what to do about it became a separate concern.

      3. With ~Stream~, we're able to build up a computation that produces a
         sequence of elements without running the steps of that computation
         until we actually need those elements.

    - More generally speaking,
      laziness lets us _separate_
      + the description of an expression
        from
      + the evaluation of that expression.

    - This gives us a powerful ability:
      we may choose to describe a "larger" expression that we need, and
      then evaluate only a portion of it.

    - =From Jian=: This is powerfull because sometimes describe the WHOLE
      expression is simpler than decribe part of this expression. In another
      words,
      + The WHOLE expression contains the general calculation ONLY.
      + Part of the whole expression contains the general calculation and the
        boundary condition. In real calculation, put the boundary condition in
        operation may simplify the expression, though it depneds.

    - Lazy ~foldRight~ can deal with the case of terminating early.
      #+BEGIN_SRC scala
      // Explicit recursion version
      def existExplicitRecur(p: A => Boolean): Boolean = this match {
        case Cons(h, t) => p(h()) || t().exists(p)
        case _ => false
      }

      // Lazy ```foldRight``` and ```exist``` implemented with this
      // ```foldRight```
      def foldRight[B] (z: => B) (f: (A, => B) => B): B =
        this match {
          case Cons(h, t) => f(h(), t().foldRight(z)(f))
          case _ => z
        }

      def exists(p: A => Boolean): Boolean =
        foldRight(false) ((a, b) => p(a) || b)
      #+END_SRC

    - Good Example: Listing 5.3 Program trace for Stream

    - This ~find~ is a method of ~Stream~, with the help of (lazy method) filter
      it only evaluate elements of ~this~ stream to the first founded element.
      #+BEGIN_SRC scala
      def find(p: A => Boolean): Option[A] =
        filter(p).headOption
      #+END_SRC

    - =TODO= We'll have a lot more to say about defining memory-efficient
      streaming calculations, in particular calculations that require I/O, in
      part 4 of this book.

*** TODO 5.4 Infinite streams and corecursion - 73
    - An example of /infinite streams/:
      ~val ones: Stream[Int] = Stream.cons(1, ones)~

    - It's easy to write expressions that _never terminate_ or _aren't stack-safe_.
      =TODO: aren't stack-safe???=

    - /corecursive/: Whereas a recursive function consumes data, a corecursive function
      _produces_ data.

    - =TODO= Exercise 5.11 ~ 5.16

*** 5.5 Summary - 77

** TODO 6 Purely functional state - 78
   We'll see how to write purely functional programs that manipulate /state/.

   - Using the simple domain of /random number generation/ as the example.
       This is NOT the most compelling use case, but a good first example that is
     simple enough.

   - =TODO= More compelling use cases in _parts 3 and 4_ of the book,
     ESPECIALLY part 4, where we'll say a lot more about dealing with /state/
     and /effects/.

   - *GOAL*:
     give you a basic pattern for how to *make _ANY_ /stateful API/ purely functional*.

*** DONE 6.1 Generating random numbers using side effects - 78
    CLOSED: [2018-06-30 Sat 09:31]
    - Scala has ~scala.util.Random~ with a pretty typical /imperative API/ that
      relies on /side effects/.
      #+BEGIN_SRC scala
        val rng = new scala.util.Random

        rng.nextDouble
        // res1: Double = 0.9867076608154569

        rng.nextDouble
        // res2: Double = 0.8455696498024141

        rng.nextInt
        // res3: Int = -623297295

        rng.nextInt(10)
        // res4: Int = 4
      #+END_SRC
      + Even if we don't know ~scala.util.Random~,
        we can assume an object ~rng~ has some /INTERNAL state/ that *gets updated
        after each invocation*,
        since we'd _otherwise_ get the SAME VALUE EACH TIME we called ~nextInt~ or
        ~nextDouble~.

        The _state updates_ are performed as a /side effect/, these /methods/ are
        *NOT* /referentially transparent/ -- this implies that they are *NOT* as
        /testable/, /composable/, /modular/, and /easily parallelized/ as they
        could be.

    - You *cannot* control the exact value of a random number.
      You *cannot* get a value a second time as you wish, or else it is NOT random.

    - Q :: If we can't control the random number values, how about pass in a
           generator?

    - A :: Even the "SAME" /generator/ has to
      + be both created with the *same* /seed/, and
      + also be in the *same* /state/.

        =???= =Is this a workable way, but only hard to handle???=
      This means its /methods/ have been called a certain number of times since it
      was created -- this will be really difficult to guarantee, because every time
      we call ~nextInt~, for example, the PREVIOUS /state/ of the random number
      generator is *destroyed*.
        Do we now need a separate mechanism to keep track of how many times
      we've called the /methods/ on ~Random~?

    - The answer to all of this is that *we should eschew /side effects/ on principle*!

    - =EN=
      eschew - é¿

*** DONE 6.2 Purely functional random number generation - 80
    CLOSED: [2018-06-30 Sat 09:45]
    The key to *recovering* /referential transparency/ is to make the *state
    updates* _EXPLICIT_ -- do NOT update /state/ as a /side effect/, but simply
    return the new /state/ along with the value that we're generating.

    - Here is one possible interface to a random number generator with *explicit
      state updates*.
      #+BEGIN_SRC scala
        trait RNG {
          def nextInt: (Int, RNG)
        }
      #+END_SRC
      Rather than work as ~scala.util.Random~, we return
      the random number *and* the new /state/,
      leaving the OLD /state/ unmodified.

      In effect, *SEPARATE* the concern of _computing_ what the NEXT /state/ is
      from the concern of _communicating_ the NEW /state/ to the rest of the
      program.

    - *No GLOBAL mutable memory is being used* -- we simply return the NEXT /state/
      back to the caller.
        This leaves *the caller of ~nextInt~ in _COMPLETE control_ of what to do
      with the NEW /state/.*

    - We need an implementation to illustrate the principles.
      Here is a simple one, use the /linear congruential generator/ algorithm, which
      is the same as the algorithm of the ~scala.util.Random~.
      #+BEGIN_SRC scala
        case class SimpleRNG(seed: Long) extends RNG {
          def nextInt: (Int, RNG) = {
            val newSeed = (seed * 0x5DEECE66DL + 0xBL) & 0xFFFFFFFFFFFFL
            val nextRNG = SimpleRNG(newSeed)
            val n = (newSeed >>> 16).toInt
            (n, nextRNG)
          }
        }
      #+END_SRC
      + Usage examples:
        #+BEGIN_SRC scala
          val rng = SimpleRNG(42)
          val (n1, rng2) = rng.nextInt
          // n1: Int = 16159453
          // rng2: RNG = SimpleRNG(1059025964525)

          val (n2, rng3) = rng2.nextInt
          // n2: Int = -1281479697
          // rng3: RNG = SimpleRNG(197491923327988)
        #+END_SRC
        If you call ~rng.nextInt~ or ~rng2.nextInt~ again, you'll get back the
        same random numbers again, respectively.

*** DONE 6.3 Making stateful APIs pure - 81
    CLOSED: [2018-09-02 Sun 19:41]
    - _footnote 4_:
      1. Efficiency loss and reason.
      2. Efficient purely functional data structures may help.
      3. Mutate the data in place without breaking RT, part 4 =TODO=

    - For instance:
      #+BEGIN_SRC scala
        class Foo {
          private var s: FooState = ...
          def bar: Bar
          def bza: Int
        }

        // Suppose `bar` and `baz` each mutate `s` in some way.

        // We can mechanically translate this to the purely functional API by making
        // explicit the transition from one state to the next:
        trait Foo (
          def bar: (Bar, Foo)
          def baz: (Int, Foo)
        )
      #+END_SRC
      + Whenever we use this pattern,
        we make the caller responsible for passing the computed /next state/
        through the rest of the program.

    - Examples:
      #+BEGIN_SRC scala
        def randomPair(rng: RNG): (Int,Int) = {
          val (i1,_) = rng.nextInt
          val (i2,_) = rng.nextInt
          (i1,i2)
        }
        // `i1` will always be the same with `i2`


        def randomPair(rng: RNG): ((Int,Int), RNG) = {
          val (i1,rng2) = rng.nextInt
          val (i2,rng3) = rng2.nextInt
          ((i1, i2), rng3)
        }
      #+END_SRC

    - *Dealing with awkwardness in functional programming*

      + _Awkwardness like this is ALMOST ALWAYS a sign of some *missing abstraction*
        waiting to be discovered._

      + With practice, experience, and more familiarity with the idioms contained
        in this book, expressing a program functionally will become _effortless
        and natural_.
          Of course, good design is still hard, but programming using pure
        functions _greatly simplifies the design space_.

    - You can see the general pattern, and perhaps you can also see how it might
      get tedious to use this API directly.

      =IMPORTANT=
      Let's write a few functions to
      1. generate random values
         and
      2. see if we notice any repetition that we can factor out.

*** DONE 6.4 A better API for state actions - 84
    CLOSED: [2018-09-03 Mon 18:13]
    - /state action (or /state transitions/)/
      A function has a type of the form ~StatefulValueType => (A, StatefulValueType)~. 
      They transform ~StatefulValue~ states from one to the next.

      These /state actions/ can be *combined* using /combinators/, which are
      higher-order functions that we'll define in this section =TODO=.

    - We want our /combinators/ to pass the /state/ from one action to the next
      _AUTOMATICALLY_, rather than writing down all the deails explicitly like we
      did before this section in the purely functional API random number example.
      1. ~type Rand[+A] = RNG => (A, RNG)~

      2. A simple ~RNG~ state transition:
         pass the ~RNG~ /state/ through without using it, always returning a
         constant value rather than a random value:
         #+BEGIN_SRC scala
           def unit[A](a: A): Rand[A] =
             rng => (a, rng)
         #+END_SRC

      3. Transform the output of a /state action/ _WITHOUT modifying_ the /state/
         itself.
           Remember, ~Rand[A]~ is just a /type alias/ for a /function type/ ~RNG
         => (A, RNG)~, so this is just a kind of /function composition/:
         #+BEGIN_SRC scala
           def map[A, B](s: Rand[A])(f: A => B): Rand[B] =
             rng => {
               val (a, rng2) = s(rng)
               (f(a), rng2)
             }
         #+END_SRC
         + Usage:
           #+BEGIN_SRC scala
             def nonNegativeEven: Rand[Int] =
               map(nonNegativeInt)(i => i - i % 2)
           #+END_SRC

    - EXERCISE 6.5
      =DONE=

**** DONE 6.4.1 Combining state actions - 85  ======= EXERCISE 6.7 =TODO=
     CLOSED: [2018-09-03 Mon 05:10]
     The ~map~ we defined above is NOT strong enough to combine _two_ ~RNG~ action.
     We need a new combinator ~map2~ that can combine two ~RNG~ actions into one
     using a binary rather than unary function.

    - EXERCISE 6.6
      Implement ~map2~

    - ~map2~ Examples:
      #+BEGIN_SRC scala
        def both[A,B](ra: Rand[A], rb: Rand[B]): Rand[(A,B)] =
          map2(ra, rb)((_, _))

        val randIntDouble: Rand[(Int, Double)] =
          both(int, double)

        val randDoubleInt: Rand[(Double, Int)] =
          both(double, int)
      #+END_SRC

    - EXERCISE 6.7
      =TODO=

**** TODO 6.4.2 Nesting state actions - 86
     - =TODO=
       NOTE

     - EXERCISE 6.8

     - EXERCISE 6.9

     - With the ~nonNegativeLessThan~, including the off-by-one error we had before:
       ~def rollDie: Rand[Int] = nonNegativeLessThan(6)~

       Fix the off-by-one error is trival:
       ~def rollDie: Rand[Int] = map(nonNegativeLessThan(6))(_ + 1)~

*** TODO 6.5 A general state action data type - 87
    The combinators we defined before this section, ~unit~, ~map~, ~map2~,
    ~flatMap~, and ~sequence~, can be general purpose combinators.
      The only thing we need change to make them can be used in general cases is
    their type.

    #+BEGIN_SRC scala
      case class State[S, +A](run: S => (A, S))

      // and then
      type Rand[A] = State[RNG, A]
    #+END_SRC

    - EXERCISE 6.10

*** TODO 6.6 Purely functional imperative programming - 88
    - *Aren't imperative and functional programming opposites?*

    - EXERCISE 6.10

*** DONE 6.7 Summary - 91
    CLOSED: [2018-09-03 Mon 04:39]
    - Topic of this chapter:
      how to write purely functional programs that have state.

    - Motivating Example:
      random number generation

    - The overall pattern we developed in this chapter comes up in many different
      domains.

      The idea is simple:
      use a pure function that accepts a state as its argument, and it returns
      the new state along-side its result.

    - Suggestion:
      Try to apply this pattern in you work:
      1. *convert* an /imperative API/ to a /purely functional API/
      2. Use some of the functions we wrote here to make working with it more convenient.

* TODO PART 2 FUNCTIONAL DESIGN AND COMBINATOR LIBRARIES - 93
  - In part 1, we covered the fundamentals of FP and saw how the commitment to
    using only pure functions affects the basic building blocks of programs:
    /loops/, /data structures/, /exceptions/, and so on.

  - In this part, we'll see how the assumptions of functional programming _affect_
    *library design*.

  - We'll create _THREE_ useful libraries in this part
    1. parallel and asynchronous computation

    2. testing programs

    3. parsing text

  - The primary goal *is NOT* to teach you about parallelism, testing, and parsing.

    The primary goal *IS* to _help you *develop skill in designing functional
    libraries*,_ even for domains that look nothing like the ones here.

  - One final note:
    as you work through part 2, you may notice *repeated patterns* of similar-looking
    code. Keep this in the back of your mind. _When we get to part 3_, we'll discuss
    + how to remove this duplication, and

    + we'll discover an entire world of fundamental abstractions that are common
      to all libraries.

** TODO 7 Purely functional parallelism - 95
   In this chapter, we'll build a _purely functional library_ for creating /parallel/
   and /asynchronous/ computations.

   - We'll rein in the complexity inherent in parallel programs by describing them
     using ONLY pure functions.
       This will let us use the /substitution model/ to simplify our reasoning
     and hopefully make working with concurrent computations both easy and enjoyable.

   - =EN= 
     rein in - æ§å¶ä½

   - *MAIN CONCERN*:
     make our library _HIGHLY_ /composable/ and /modular/.
     To this end, we'll keep with our theme of
     *separating* the concern of describing a computation *from* actually running it.

     + Goal:
       We want to allow users of our library to write programs at a very high level,
       *insulating* them *from* the nitty-gritty of how their programs will be executed.

       For example, towards the end of the chapter we'll develop a combinator,
       ~parMap~, that will let us easily apply a function ~f~ to every element in
       a collection simultaneously: ~val outputList = parMap(inputList)(f)~

   - =EN= 
     nitty-gritty - äºå¯¦çç¸

   - NOTE =TODO=

   - We'll emphasize /algebraic reasoning/ and introduce the idea that an API can
     *be DESCRIBED BY /an algebra/ that obeys specific /laws/.*

*** TODO 7.1 Choosing data types and functions - 96
    - Example for Illustration:
      #+BEGIN_SRC scala
        def sum(ints: Seq[Int]): Int =
          ints.foldLeft(0)((a, b) => a + b)
      #+END_SRC

    - INSTEAD of _folding sequentially_,
      we could use a /divide-and-conquer algorithm/; see the following code:
      #+BEGIN_SRC scala
        def sum(ints: IndexedSeq[Int]): Int =
          if (ints.size <= 1)
            ints.headOption getOrElse 0
          else {
            val (l,r) = ints.splitAt(ints.length/2)
            sum(l) + sum(r)
          }
      #+END_SRC

      + _UNLIKE_ the ~foldLeft~-based implementation, this implementation *can be
        parallelized* â the two halves can be summed _in parallel_.

    - Instead learning how to work with the implementation APIs directly (likely
      related to ~java.lang.Thread~ and ~java.util.concurrent~), we'll design our
      own ideal API as illuminated by our examples and work backward from there
      to an implementation.

**** TODO 7.1.1 A data type for parallel computations - 97
     - xxx
       + ~def unit[A](a: => A): Par[A]~
         for taking an unevaluated ~A~ and returning a computation that might
         evaluate it in a separate thread.

         We call it ~unit~ because in a sense it creates a unit of parallelism
         that just wraps a single value.

       + ~def get[A](a: Par[A]): A~
         for extracting the resulting value from a parallel computation.

     - Listing 7.2  Updating ~sum~ with our custom data type
       #+BEGIN_SRC scala
         def sum(ints: IndexedSeq[Int]): Int =
           if (ints.size <= 1)
             ints headOption getOrElse 0
           else {
             val (l, r) = ints.splitAt(ints.length/2)
             val sumL: Par[Int] = Par.unit(sum(l))
             val sumR: Par[Int] = Par.unit(sum(r))
             Par.get(sumL) + Par.get(sumR)
           }
       #+END_SRC

     - *The problem with using concurrency primitives directly*
       + Transcribed partial excerpt of ~java.lang.Thread~ and ~Runnable~ into Scala:
         #+BEGIN_SRC scala
           trait Runnable { def run: Unit }

           class Thread(r: Runnable) {
             def start: Unit  // Begins running `r` in a separate thread.
             def join: Unit   // Blocks the calling thread until `r` finishes running.
           }
         #+END_SRC

       + A problem of both of the types ~Runnable~ and ~Thread~ is their core
         functions do NOT have meaningful type -- they are used for /side effect/.
         This is BAD for /compositionality/.

       + ~Thread~ also has the _DISADVANTAGE_ that it maps directly onto /operating
         system threads/, which are a scarce resource.
           It would be preferable to create as many /logical threads/ as is natural
         for our problem, and LATER deal with mapping these onto actual /OS threads/.

       + This kind of thing can be handled by something like
         ~java.util.concurrent.Future~, ~ExecutorService~, and friends.

         *Why don't we use them directly?*

         Here's a portion of their API:
         #+BEGIN_SRC scala
           class ExecutorService {
             def submit[A](a: Callable[A]): Future[A]
           }

           trait Future[A] {
             def get: A
           }
         #+END_SRC
         Though these are a tremendous help in abstracting over physical threads,
         these primitives are still at a much lower level of abstraction than
         the library we want to create in this chapter.
         * A call to ~Future.get~, for example, *blocks* the calling thread *until*
           the ~ExecutorService~ has finished executing it, and its API provides
           _no means of composing futures_.

           Of course, we can build the implementation of our library on top of
           these tools (and this is in fact what we end up doing later in the
           chapter), but they don't present a modular and compositional API that
           we'd want to use directly from functional programs.

       + =TODO=

       + =TODO=

**** TODO 7.1.2 Combining parallel computations - 100
**** TODO 7.1.3 Explicit forking - 102

*** TODO 7.2 Picking a representation - 104
*** TODO 7.3 Refining the API - 105
*** TODO 7.4 The algebra of an API - 110
**** 7.4.1 The law of mapping - 110
**** 7.4.2 The law of forking - 112
**** 7.4.3 Breaking the law: a subtle bug - 113
**** 7.4.4 A fully non-blocking Par implementation using actors - 115

*** TODO 7.5 Refining combinators to their most general form - 120
*** TODO 7.6 Summary - 123

** TODO 8 Property-based testing - 124
*** TODO 8.1 A brief tour of property-based testing - 124
*** TODO 8.2 Choosing data types and functions - 127
**** 8.2.1 Initial snippets of an API - 127
**** 8.2.2 The meaning and API of properties - 128
**** 8.2.3 The meaning and API of generators - 130
**** 8.2.4 Generators that depend on generated values - 131
**** 8.2.5 Refining the Prop data type - 132

*** TODO 8.3 Test case minimization - 134
*** TODO 8.4 Using the library and improving its usability - 136
**** 8.4.1 Some simple examples - 137
**** 8.4.2 Writing a test suite for parallel computations - 138

*** TODO 8.5 Testing higher-order functions and future directions - 142
*** TODO 8.6 The laws of generators - 144
*** TODO 8.7 Summary - 144

** TODO 9 Parser combinators - 146
   We'll work through the design of a /combinator library/ for creating /parsers/.
   We'll use JSON parsing as a motivating use case.
   (Like chapters 7 and 8,
   this chapter is _NOT so much about parsing_
   as it is about _providing further insight into the process of functional design_.)

   - This chapter will introduce a _design approach_ that we'll call /algebraic
     design/.

   - *Parser combinators versus parser generators*

*** TODO 9.1 Designing an algebra, first - 147
    - There are MANY different kinds of _parsing libraries_.

      Ours will be designed for /expressiveness/ (weâd like to be able to parse
      ARBITRARY grammars), /speed/, and /GOOD error reporting/.

    - For simplicity and for speed,
      our library will create parsers that _operate on strings_ as input.

    - We need to pick some parsing tasks to help us discover a good algebra for our parsers.

      + As the first parsing task JSON or HTML are NOT simple enough!

        A good and simple domain to start with is parsing various combinations of
        _repeated letters_ and _gibberish words_ like "abracadabra" and "abba".

        Weâll see how simple examples like this help us ignore extraneous details
        and focus on the essence of the problem.

    - Let's start with the simplest of parsers.
      + ~def char(c: Char): Parser[Char]~

      + ~def run[A](p: Parser[A])(input: String): Either[ParseError, A]~

      + --
        #+BEGIN_SRC scala
          trait Parsers[ParseError, Parser[+_]] {
            def run[A](p: Parser[A])(input: String): Either[ParseError, A]
            def char(c: Char): Parser[Char]
          }
        #+END_SRC

      + ~run(char(c))(c.toString) == Right(c)~

      + ~def string(s: String): Parser[String]~

    - xxxx

    - *The advantages of algebraic design*

*** TODO 9.2 A possible algebra - 152
**** 9.2.1 Slicing and nonempty repetition - 154

*** TODO 9.3 Handling context sensitivity - 156
*** TODO 9.4 Writing a JSON parser - 158
**** 9.4.1 The JSON format - 158
**** 9.4.2 A JSON parser - 159

*** TODO 9.5 Error reporting - 160
**** 9.5.1 A possible design - 161
**** 9.5.2 Error nesting - 162
**** 9.5.3 Controlling branching and backtracking - 163

*** TODO 9.6 Implementing the algebra - 165
**** 9.6.1 One possible implementation - 166
**** 9.6.2 Sequencing parsers - 166
**** 9.6.3 Labeling parsers - 167
**** 9.6.4 Failover and backtracking - 168
**** 9.6.5 Context-sensitive parsing - 169

*** TODO 9.7 Summary - 171

* TODO PART 3 COMMON STRUCTURES IN FUNCTIONAL DESIGN - 173
** TODO 10  Monoids - 175
   - We'll see how /monoids/ are useful in _TWO_ ways:
     + they facilitate _parallel computation_ by giving us the freedom to break
       our problem into chunks that can be computed in parallel; and

     + they can be _composed to assemble_ complex calculations from simpler
       pieces.
    
*** DONE 10.1 What is a monoid? - 175
    CLOSED: [2018-09-02 Sun 03:44]
    - *Monoid Laws* ::
      + /associativity/
      + /identity/

    - A /monoid/ consists of the following:
      + Some type ~A~;

      + An /associative binary operation/, ~op~.
        For any ~x: A~, ~y: A~, and ~z: A~, ~op(op(x,y), z) == op(x, op(y,z))~

      + An /identity/ value, ~zero: A~, for that operation ~op~:
        For any ~x: A~,
        #+BEGIN_SRC haskell
          op(x, zero) == x
          op(zero, x) == x
        #+END_SRC

    - Examples of /monoid/:
      + ~Int~ with the ~+~ operation.
        * identity is ~0~

      + ~Int~ with the ~*~ operation.
        * identity is ~1~

      + ~Boolean~ with the ~||~ operation.
        * identity is ~false~

      + ~Boolean~ with the ~&&~ operation.
        * identity is ~true~

    - Standard way to _read out_ this algebraic system:

      Type ~A~ forms a /monoid/ under the operations defined by the ~Monoid[A]~
      instance.

    - Stated tersely,
      a /monoid/ is
      + a /type/
        together with
      + a /binary operation (op) over that type/,
      satisfying /associativity/ and having an /identity/ element (zero).

    - The ~Monoid~ /trait/:
      #+BEGIN_SRC scala
        trait Monoid[A] {
          def op(a1: A, a2: A): A  // Must satisfy `op(op(x, y), z) == op(x, op(y, z))`
          def zero: A              // Must satisfy `op(zero, x) == x`
        }
      #+END_SRC

    - Examples:
      #+BEGIN_SRC scala
        // String Monoid
        val stringMonoid = new Monoid[String] {
          def op(a1: String, a2: String) = a1 + a2
          val zero = ""
        }


        // List Monoid
        def listMonoid[A] = new Monoid[List[A]] {
          def op(a1: List[A], a2: List[A]) = a1 ++ a2
          val zero = Nil
        }
      #+END_SRC

    - =TODO= Can we write any interesting programs, knowing nothing about a type
      other than that it forms a monoid? Absolutely! Let's look at some examples.

*** DONE 10.2 Folding lists with monoids - 178
    CLOSED: [2018-09-02 Sun 03:44]
    /Monoids/ have an *intimate connection* with /lists/.

    If you look at the signatures of ~foldLeft~ and ~foldRight~ on ~List~,
    _you might notice something about the /argument types/:_
    #+BEGIN_SRC scala
      def foldRight[B](z: B)(f: (A, B) => B): B
      def foldLeft[B](z: B)(f: (B, A) => B): B
    #+END_SRC

    - Q :: What happens when ~A~ and ~B a~re the *same* /type/?
           #+BEGIN_SRC scala
             def foldRight(z: A)(f: (A, A) => A): A
             def foldLeft(z: A)(f: (A, A) => A): A
           #+END_SRC

    - A :: The components of a /monoid/ fit these /argument types/ like a glove.
           #+BEGIN_SRC scala
             val l: List[MonoidType] = v
             l.foldRight(monoidType.zero)(monoidType.op)
             l.foldLeft(monoidType.zero)(monoidType.op)
           #+END_SRC
      + You can see, because of the /monoid laws/ of /associativity/ and /identity/
        hold, it is doesn't matter if we choose ~foldLeft~ or ~foldRight~ -- given
        that both have tail-recursive implementations.

      + We can write a general function ~concatenate~ that folds a /list/ with
        a /monoid/:
        #+BEGIN_SRC scala
          def concatenate[A](xs: List[A], m: Monoid[A]): A =
            xs.foldLeft(m.zero)(m.op)
        #+END_SRC

    - Q :: What if our /list/ has an /element type/ that does *NOT* have a ~Monoid~
           instance?

    - A :: You can /map/ over the list to turn it into a type that does:
           #+BEGIN_SRC scala
             // Answer to the EXERCISE 10.5
             def foldMap[A, B](xs: List[A], m: Monoid[B])(f: A => B): B =
               xs.view.
                 map(f).
                 foldLeft(m.zero)(m.op)
           #+END_SRC

    - EXERCISE 10.6 is HARD
      =TODO= =TODO= =TODO= Try this later!!!

*** TODO 10.3 Associativity and parallelism - 179
    - /Balanced Fold/, like ~op(op(a, b), op(c, d))~, can have *less times of
      calculations*

      than

      /fold right/ ~op(a, op(b, op(c ,d)))~ and /fold left/ ~op(op(op(a, b), c), d)~.

*** TODO 10.4 Example: Parallel parsing - 181
*** TODO 10.5 Foldable data structures - 183
*** TODO 10.6 Composing monoids - 184
**** 10.6.1 Assembling more complex monoids - 185
**** 10.6.2 Using composed monoids to fuse traversals - 186

*** TODO 10.7 Summary - 186

** TODO 11  Monads - 187
*** TODO 11.1 Functors: generalizing the map function - 187
**** 11.1.1 Functor laws - 189

*** TODO 11.2 Monads: generalizing the flatMap and unit functions - 190
**** 11.2.1 The Monad trait - 191

*** TODO 11.3 Monadic combinators - 193
*** TODO 11.4 Monad laws - 194
**** 11.4.1 The associative law - 194
**** 11.4.2 Proving the associative law for a specific monad - 196
**** 11.4.3 The identity laws - 197

*** TODO 11.5 Just what is a monad? - 198
**** 11.5.1 The identity monad - 199
**** 11.5.2 The State monad and partial type application - 200

*** TODO 11.6 Summary - 204

** TODO 12  Applicative and traversable functors - 205
*** TODO 12.1 Generalizing monads - 205
*** TODO 12.2 The Applicative trait - 206
*** TODO 12.3 The difference between monads and applicative functors - 208
**** 12.3.1 The Option applicative versus the Option monad - 209
**** 12.3.2 The Parser applicative versus the Parser monad - 210

*** TODO 12.4 The advantages of applicative functors - 211
**** 12.4.1 Not all applicative functors are monads - 211

*** TODO 12.5 The applicative laws - 214
**** 12.5.1 Left and right identity - 214
**** 12.5.2 Associativity - 215
**** 12.5.3 Naturality of product - 216

*** TODO 12.6 Traversable functors - 218
*** TODO 12.7 Uses of Traverse - 219
**** 12.7.1 From monoids to applicative functors - 220
**** 12.7.2 Traversals with State - 221
**** 12.7.3 Combining traversable structures - 223
**** 12.7.4 Traversal fusion - 224
**** 12.7.5 Nested traversals - 224
**** 12.7.6 Monad composition - 225

*** TODO 12.8 Summary - 226

* TODO PART 4 EFFECTS AND I/O - 227
** TODO 13 External effects and I/O - 229
*** TODO 13.1 Factoring effects - 229
*** TODO 13.2 A simple IO type - 231
**** 13.2.1 Handling input effects - 232
**** 13.2.2 Benefits and drawbacks of the simple IO type - 235

*** TODO 13.3 Avoiding the ~StackOverflowError~ - 237
**** 13.3.1 Reifying control flow as data constructors - 237
**** 13.3.2 Trampolining: a general solution to stack overflow - 239

*** TODO 13.4 A more nuanced IO type - 241
**** 13.4.1 Reasonably priced monads - 242
**** 13.4.2 A monad that supports only console I/O - 243
**** 13.4.3 Pure interpreters - 246

*** TODO 13.5 Non-blocking and asynchronous I/O - 247
*** TODO 13.6 A general-purpose IO type - 250
**** 13.6.1 The main program at the end of the universe - 250

*** TODO 13.7 Why the IO type is insufficient for streaming I/O - 251
*** TODO 13.8 Summary - 253

** TODO 14 Local effects and mutable state - 254
*** TODO 14.1 Purely functional mutable state - 254
*** TODO 14.2 A data type to enforce scoping of side effects - 256
**** 14.2.1 A little language for scoped mutation - 256
**** 14.2.2 An algebra of mutable references - 258
**** 14.2.3 Running mutable state actions - 259
**** 14.2.4 Mutable arrays - 262
**** 14.2.5 A purely functional in-place quicksort - 263

*** TODO 14.3 Purity is contextual - 264
**** 14.3.1 What counts as a side effect? - 266

*** TODO 14.4 Summary - 267

** TODO 15 Stream processing and incremental I/O - 268
*** TODO 15.1 Problems with imperative I/O: an example - 268
*** TODO 15.2 Simple stream transducers - 271
**** 15.2.1 Creating processes - 272
**** 15.2.2 Composing and appending processes - 275
**** 15.2.3 Processing files - 278

*** TODO 15.3 An extensible process type - 278
**** 15.3.1 Sources - 281
**** 15.3.2 Ensuring resource safety - 283
**** 15.3.3 Single-input processes - 285
**** 15.3.4 Multiple input streams - 287
**** 15.3.5 Sinks - 290
**** 15.3.6 Effectful channels - 291
**** 15.3.7 Dynamic resource allocation - 201

*** TODO 15.4 Applications - 292
*** TODO 15.5 Summary - 293

* Tips
  - Variable-naming conventions
