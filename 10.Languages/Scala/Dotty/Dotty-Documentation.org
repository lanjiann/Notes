#+TITLE: Dotty Documentation
#+VERSION: 0.25.0-bin-SNAPSHOT
#+AUTHOR:
#+STARTUP: entitiespretty

* BLOG
* DONE USAGE
  CLOSED: [2019-11-04 Mon 16:17]
** Getting Started
   # *Getting Started: Users*
*** Trying out Dotty
**** In your web browser
**** sbt
     Use sbt (1.1.4+)

**** IDE support
**** Standalone installation

** sbt-projects
   # *Using Dotty with sbt*

** IDE support for Dotty
*** Prerequisites
*** Usage
*** Status
**** Fully supported features
**** Partial working features
**** Unimplemented features
**** Current limitations, to be fixed

*** Feedback

** Worksheet mode in Dotty IDE
*** How to use the worksheets
*** Implementation details

** cbt-projects
   # *Using Dotty with cbt*

** DONE Dottydoc
   CLOSED: [2020-02-15 Sat 02:33]
*** Using existing Templates and Layouts
*** Blog
*** Includes
*** Sidebar
*** Dottydoc Specific Tags and Behavior
**** Linking to API
**** Rendering Docstrings
**** Other extensions

*** Default Layouts
**** =main.html=
***** Variables

**** =sidebar.html=
***** Variables

**** =doc-page.html=
**** =api-page.html=
**** =blog-page.html=

*** Default Includes

* REFERENCE
** Overview
*** Goals
*** Essential Foundations
*** Simplifications
*** Restrictions
*** Dropped Constructs
*** Changes
*** New Constructs
*** Meta Programming
*** See Also

** DONE NEW TYPES
   CLOSED: [2020-03-08 Sun 21:34]
*** DONE Intersection types
    CLOSED: [2019-11-10 Sun 17:47]
    The ~&~ operator creates an /intersection type/.

**** Type Checking
     The type ~S & T~ represents values that are of the type ~S~ and ~T~ _at the
     same time_.

     - Example:
       #+begin_src scala
         trait Resettable {
           def reset(): Unit
         }

         trait Growable[T] {
           def add(x: T): this.type
         }

         def f(x: Resettable & Growable[String]) = {
           x.reset()
           x.add("first")
         }
       #+end_src

     - If a /member/ appears in both ~A~ and ~B~, its type in ~A & B~ is the
       /intersection of its type/ in ~A~ and its type in ~B~.
         For instance, assume the definitions:
       #+begin_src scala
         trait A {
           def children: List[A]
         }

         trait B {
           def children: List[B]
         }

         val x: A & B = new C
         val ys: List[A & B] = x.children
       #+end_src
       ~ys~ is of type ~List[A] & List[B]~, _which can be FURTHER SIMPLIFIED
       to_ ~List[A & B]~ _because_ ~List~ is /convariant/.

     - Q :: (One might wonder)
            How the compiler could come up with a definition for ~children~ of
            type ~List[A & B]~ since all its is given are ~children~ definitions
            of type ~List[A]~ and ~List[B]~.

     - A :: The answer is it *does not need to*. TODO ??? ??? ??? TODO
              ~A & B~ is just a type that represents a set of requirements for
            values of the type.
              At the point where a value is constructed, one must make sure that
            all inherited members are correctly defined. So if one _defines a class
             ~C~ that inherits ~A~ and ~B~,_ one needs to give at that point a
            definition of a ~children~ method with the required type.
       #+begin_src scala
         class C extends A with B {
           def children: List[A & B] = ???
         }
       #+end_src

**** More Details
***** Syntax
      Syntactically, an /intersection type/ ~S & T~ is similar to an /infix
      type/, where the _infix operator_ is ~&~.
      - ~&~ is treated as a /soft keyword/.
        + it is a _NORMAL identifier_ with the usual precedence.

        + *BUT*
          a type of the form ~A & B~
          _is *ALWAYS* recognized as_ an /intersection type/,
          _WITHOUT_ trying to resolve ~&~.

      - Syntax:
        #+begin_src text
          Type      ::=  ...| InfixType
          InfixType ::=  RefinedType {id [nl] RefinedType}
        #+end_src

***** Subtyping Rules
      - Subtyping rules
        TODO

      - It is can be proved that ~&~ is *commutative*.

      - Derived:
        Given type constructor ~C~,
        + If ~C~ is /covariant/, ~C[A] & C[B] ~> C[A & B]~
        + If ~C~ is /contravariant/, ~C[A] & C[B] ~> C[A | B]~

***** TODO Erasure
      TODO TODO TODO

***** Relationship with Compound Type (~with~)
      - =from Jian=
        ~A & B~ is different from the ~A with B~ in Scala 2.
        The latter is not commutative!

      - /Intersection types/ ~A & B~ *replace* /compound types/ ~A with B~ in
        Scala 2.
          For the moment, the syntax ~A with B~ is _still allowed_ and
        *interpreted as* ~A & B~, _but its usage as a type (as opposed to in a
        ~new~ or ~extends~ clause) will be *deprecated* and *removed* in the future._

*** DONE Union types
    CLOSED: [2019-07-01 Mon 15:49]
    A ~A | B~ value can be _any value_ of type ~A~ _and_ also _any value_ of
    type ~B~.

    - Example:
      #+begin_src scala
        final case class UserName(name: String)
        final case class Password(hash: Hash)

        def help(id: UserName | Password) = {
          val user = id match {
            case UserName(name) => lookupName(name)
            case Password(hash) => lookupPassword(hash)
          }
          // ...
        }
      #+end_src

    - /Union types/ are _DUALS of /intersection types/.

    - ~|~ is *commutative*: ~A | B~ is the _SAME type_ as ~B | A~.

    - The compiler will assign a /union type/ to an expression *only if such a
      type is _EXPLICITLY given_.*
      #+begin_src scala
        val password = Password(123)
        // val password: Password = Password(123)

        val name = UserName("Eve")
        // val name: UserName = UserName(Eve)

        if (true) name else password
        // val res2: Object & Product = UserName(Eve)

        val either: Password | UserName = if (true) name else password
          // val res2: Password | UserName = UserName(Eve)
      #+end_src
      + ~Object & Product~ is a /supertype/ of ~UserName~ and ~Password~,
        BUT NOT the /least supertype/ ~Password | UserName~
        * =from Jian= In the document, there is is a typo (not wrong, but not very
          meaningful): _Object & Product is a supertype of UserName and ~Product~._
          TODO Create a PR to correct this!

**** TODO More Details
***** Syntax
      Syntactically, /union types/ follow the same rules as /intersection types/,
      BUT have a _LOWER precedence_.

****** Intersection with pattern matching syntax - =IMPORTANT=
       ~|~ is also used in /pattern matching/ to _SEPARATE_ /pattern alternatives/ and
       *has _LOWER PRECEDENCE than_ ~:~ as used in /typed patterns/,* this means that:
       #+begin_src scala
         case _: A | B => ...

         // is still equivalent to:
         case (_: A) | B => ...

         // and NOT to:
         case _: (A | B) => ...
       #+end_src

***** Subtyping Rules
      - ~A~ is always a subtype of ~A | B~ for all ~A~, ~B~.

      - If ~A <: C~ and ~B <: C~ then ~A | B <: C~.

      - Like ~&~, ~|~ is /commutative/ and /associative/:
        #+begin_src text
          A | B       =:= B | A
          A | (B | C) =:= (A | B) | C
        #+end_src

      - ~&~ _is distributive over ~|~:_
        #+begin_src text
          A & (B | C) =:= A & B | A & C
        #+end_src

      - From these rules it follows that: TODO TODO TODO
        *the /least upper bound (lub)/ of a set of type is the union of these
        types.*

        + This *replaces* the definition of /least upper bound/ in the Scala 2
          specification. TODO

***** TODO Motivation - TODO NOTE, TODO Re-READ
***** TODO Join of a union type - TODO ???
****** Example

***** TODO Type inference
****** Example

***** TODO Members
****** Example

***** Exhaustivity checking
***** TODO Erasure

*** DONE Type lambdas
    CLOSED: [2019-07-01 Mon 15:55]
    A /type lambda/ lets one express a /higher-kinded type/ directly, *WITHOUT*
    a /type definition/.

    - =from Jian=
      Scala 2 can do this with /type definition/ and /type projection/.

    - Example:
      ~[+X, Y] =>> Map[Y, X]~

    - /Type parameters/ of /type lambdas/ can have /variances/ and /bounds/.

    - A /parameterized type definition or declaration/ such as ~type T[X] = (X, X)~
      is a shorthand for a PLAIN /type definition/ with a /type lambda/ as its RHS:
      ~type T = [X] =>> (X, X)~

    - TODO
      _More details_ link

*** DONE Match types - TODO _mechanism_
    CLOSED: [2020-03-08 Sun 21:34]
    - A /match type/ reduces to one of a number of right hand sides, depending on
      a /scrutinee type/. Example:
      #+begin_src scala
        type Elem[X] = X match {
          case String      => Char
          case Array[t]    => t
          case Iterable[t] => t
        }
      #+end_src
      + An ~Elem~ with /CONCRETE type parameter/ ~X~ can be reduced _as_ (NOT legal
        code you want to write out explicitly):
        #+begin_src scala
          Elem[String]      =:= Char
          Elem[Array[Int]]  =:= Int
          Elem[List[Float]] =:= Float
          Elem[Nil.type]    =:= Nothing
        #+end_src
        Here ~=:=~ is understood to mean that left and right hand sides are
        *mutually subtypes* of each other.

    - Syntax in general: ~S match { P1 => T1 .... Pn => Tn }~, where
      + ~S~, ~T1~, ..., ~Tn~ are types.
      + ~P1~, ..., ~Pn~ are patterns.
        * /Type variables/ in patterns start as usual with a lower case letter.

    - Match types can form part of *RECURSIVE TYPE definitions*. Example:
      #+begin_src scala
        type LeafElem[X] = X match {
          case String      => Char
          case Array[t]    => LeafElem[t]
          case Iterable[t] => LeafElem[t]
          case AnyVal      => X
        }
      #+end_src

    - _Recursive match type definitions_ can also be given an /upper bound/, like this:
      #+begin_src scala
        type Concat[+Xs <: Tuple, +Ys <: Tuple] <: Tuple = Xs match {
          case Unit    => Ys
          case x *: xs => x *: Concat[xs, Ys]
        }
      #+end_src
      + In this definition, every instance of ~Concat[A, B]~, whether reducible
        or not, is known to be a /subtype/ of ~Tuple~.

      + This is necessary to _make the recursive invocation ~x *: Concat[xs, Ys]~
        type check_, since ~*:~ demands a ~Tuple~ as its right operand.

**** DONE Representation of Match Types
     CLOSED: [2020-03-08 Sun 21:32]
     # =from Jian= Internal Representation of Match Types
     #+begin_src scala
       S match {
         case P1 => T1
         case P2 => T2
         // ...
         case Pn => Tn
       }
     #+end_src
     - It's _internal representation_ (=from Jian= Tasty???) is
       ~Match(S, C1, ..., Cn) <: B~
       + ~Ci~ is of the form ~[Xs] => P => T~
         * ~[Xs]~
           a /type parameter clause/ of the /variables bound/ in pattern ~Pi~.
           _It can be omitted if there is *NO* /bound/._

         * Each case (~Pi => Ti~) is either:
           - a /unary function type/ like ~String => Char~
             OR
           - a /type lambda over a unary function type/ like ~Array[t] => LeafElem[t]~.

         * ~B~ is the declared /upper bound/ of the /match type/, or ~Any~ if no
           such bound is given.

       + Scrutiny, /bound types/ and /pattern types/ must be /first-order types/.
         TODO =from Jian= ??? I don't quite understand this sentence!?!?

**** TODO Match type reduction
**** TODO Subtyping Rules for Match Types
**** TODO Variance Laws for Match Types
**** TODO Typing Rules for Match Expressions
**** TODO Overlapping Patterns
**** TODO Handling Termination
**** TODO Related Work

*** DONE Dependent Function Types
    CLOSED: [2019-07-01 Mon 16:10]
    - A /dependent function type/ describes functions where the _result type_ may
      DEPEND ON the _function's parameter values_. Example:
      #+begin_src scala
        trait Entry {
          type Key
          val key: Key
        }

        def extractKey(e: Entry): e.Key = e.key          // a dependent method
        val extractor: (e: Entry) => e.Key = extractKey  // a dependent function value
        //           ||                   ||
        //           ||     Dependent     ||
        //           ||   Function Type   ||
        //           =======================
      #+end_src

      - Scala _ALREADY_ has /dependent methods/.
        BUT so far (in Scala 2) it was _NOT possible_ to turn such /methods/ into
        /function values/, so that they can be passed as /parameters/ to other
        functions, or returned as results.
        + /Dependent methods/ COULD NOT be turned into /functions/ simply because
          there was no type that could describe them.

      - In dotty the /type/ of the ~extractor~ value above is ~(e: Entry) => e.Key~

    - The /dependent function type/ above is just /syntactic sugar/ for
      #+begin_src scala
        Function1[Entry, Entry#Key] {
          def apply(e: Entry): e.Key
        }
      #+end_src

**** More details

** TODO ENUMS
*** DONE Enumerations
    CLOSED: [2019-07-02 Tue 13:11]
    An /enumeration/ is used to define a /type/ consisting of _a set of NAMED values._

    - Example:
      #+begin_src scala
        enum Color {
          case Red, Green, Blue
        }
      #+end_src
      + This defined a new ~sealed~ /class/ ~Color~ with 3 values: ~Color.Red~,
        ~Color.Green~, ~Color.Blue~.

      + The _color values_ are members of ~Color~'s /companion object/.

**** DONE Parameterized enums
     CLOSED: [2019-11-10 Sun 22:12]
     /Enums/ CAN BE _parameterized_:
     #+begin_src scala
       enum Color(val rgb: Int) {
         case Red   extends Color(0xFF0000)
         case Green extends Color(0x00FF00)
         case Blue  extends Color(0x0000FF)
       }
     #+end_src
     As the example shows, you can _DEFINE_ the parameter value BY using an
     _EXPLICIT_ ~extends~ /clause/.

**** DONE Methods defined for enums
     CLOSED: [2019-11-10 Sun 22:12]
     - The values of an /enum/ correspond to _UNIQUE integers_.

     - The _integer_ associated with an /enum value/ is returned by its ~ordinal~
       /method/.

     - Example:
       #+begin_src scala
         val red = Color.Red
         // val red: Color = Red

         red.ordinal
         // val res0: Int = 0
       #+end_src

     - The /companion object/ of an /enum/ also defines *TWO* utility /methods/.
       + ~valueOf~: obtain an /enum value/ by its _name_.
       + ~values~: returns _ALL_ /enum values/ defined in an enumeration in an ~Array~.
       #+begin_src scala
         Color.valueOf("Blue")
         // val res0: Color = Blue

         Color.values
         // val res1: Array[Color] = Array(Red, Green, Blue)
       #+end_src

**** DONE User-defined members of enums
     CLOSED: [2019-11-10 Sun 22:12]
     It is _possible_ to add your own definitions to an /enum/.

     - Example:
       #+begin_src scala
         enum Planet(mass: Double, radius: Double) {
           private final val G = 6.67300E-11
           def surfaceGravity = G * mass / (radius * radius)
           def surfaceWeight(otherMass: Double) =  otherMass * surfaceGravity

           case Mercury extends Planet(3.303e+23, 2.4397e6)
           case Venus   extends Planet(4.869e+24, 6.0518e6)
           case Earth   extends Planet(5.976e+24, 6.37814e6)
           case Mars    extends Planet(6.421e+23, 3.3972e6)
           case Jupiter extends Planet(1.9e+27,   7.1492e7)
           case Saturn  extends Planet(5.688e+26, 6.0268e7)
           case Uranus  extends Planet(8.686e+25, 2.5559e7)
           case Neptune extends Planet(1.024e+26, 2.4746e7)
         }
       #+end_src

     - It is also possible to define an explicit /companion object/ for an /enum/:
       #+begin_src scala
         object Planet {
           def main(args: Array[String]) = {
             val earthWeight = args(0).toDouble
             val mass = earthWeight / Earth.surfaceGravity
             values map { p =>
               println(s"Your weight on $p is ${p.surfaceWeight(mass)}")
             }
           }
         }
       #+end_src

**** DONE Compatibility with Java Enums
     CLOSED: [2019-07-02 Tue 10:37]
     If you want to use a enum in Scala in Java, you need to extends
     ~java.lang.Enum[T]~, where ~T~ is your _enum type name_.
     - Example
       #+begin_src scala
         enum Color extends java.lang.Enum[Color] { case Red, Green, Blue }
       #+end_src

     - Example
       #+begin_src scala
         Color.Red.compareTo(Color.Green)
         // val res15: Int = -1
       #+end_src

     - For a more in-depth example of using Scala 3 /enums/ from Java, see this
       test (in GITHUB dotty project repo). In the test, the /enums/ are defined
       in the ~MainScala.scala~ file and used from a Java source, ~Test.java~.

**** DONE Implementation
     CLOSED: [2019-07-02 Tue 13:11]
     /Enums/ are represented as ~sealed~ /classes/ that extend the ~scala.Enum~
     /trait/.

     - ~scala.Enum~ defines a _SINGLE_ /public method/, ~ordinal~:
       #+begin_src scala
         package scala

         /** A base trait of all enum classes */
         trait Enum {
           /** A number uniquely identifying a case of an enum */
           def ordinal: Int
         }
       #+end_src

     - /Enum values/ *WITH* ~extends~ /clauses/ get *expanded* to /anonymous class
       instances/.
         For instance, the ~Venus~ value above (=from Jian= in Section _User-defined
       members of enums_) would be defined like this:
       #+begin_src scala
         val Venus: Planet = new Planet(4.869e24, 6.0518e6) {
           def ordinal: Int = 1
           override def toString: String = "Venus"
           // internal code to register value
         }
       #+end_src

     - /Enum values/ *WITHOUT* ~extends~ /clauses/ all share a single implementation
       that can be instantiated using a /private method/ that takes a tag and a name
       as arguments.
         For instance, ~Color.Red~ would expand to
         #+begin_src scala
           val Red: Color = $new(0, "Red")
         #+end_src

**** TODO Reference

*** DONE Algebraic Data Types
    CLOSED: [2019-07-02 Tue 13:35]
    The ~enum~ concept is general enough to ALSO support ADTs and GADTs. =TODO=

    - Example:
      #+begin_src scala
        enum Option[+T] {
          case Some(x: T)
          case None
        }
      #+end_src
      + The ~extends~ clauses can be given explicitly:
        #+begin_src scala
          enum Option[+T] {
            case Some(x: T) extends Option[T]
            case None       extends Option[Nothing]
          }
        #+end_src

      + If ~Option~ was /non-variant/, you'd need to give the ~extends~ /clause/
        of None *EXPLICITLY*.

    - Generally, for /enum classes/
      + all /covariant type parameters/  are *minimized* in a compiler-generated
        ~extends~ /clause/

      + all /contravariant type parameters/ are *maximized*.

    - If not directly ~new~ a enumeration, a type is always its parent.
      For example,
      #+begin_src scala
        Option.Some("hello")
        // val res1: t2.Option[String] = Some(hello)

        Option.None
        // val res2: t2.Option[Nothing] = None

        new Option.Some(2)
        // res3: t2.Option.Some[Int] = Some(2)
      #+end_src

    - /Enumerations/ and /ADTs/ have been presented as two *different concepts*.
      _BUT_
      since they share the same syntactic construct, they can be seen simply as
      two ends of a spectrum and it is perfectly possible to construct hybrids.
      For instance, the code below gives an implementation of Color either with
      three enum values or with a parameterized case that takes an RGB value.
      TODO TODO TODO
      TODO TODO TODO
      TODO TODO TODO
      #+begin_src scala
        enum Color(val rgb: Int) {
          case Red           extends Color(0xFF0000)
          case Green         extends Color(0x00FF00)
          case Blue          extends Color(0x0000FF)
          case Mix(mix: int) extends Color(mix)
        }
      #+end_src

**** DONE Syntax of Enums
     CLOSED: [2019-07-02 Tue 13:27]
     - TODO NOTE

**** TODO Reference

*** TODO Translation
    # *Translation of Enum and ADTs*
    1.
    2.
    3.
    4.
    5.
    6.
    7.
    8.
    9.

**** Translation of Enumerations
**** Scopes for Enum Cases
**** Translation of Java-compatible enums
**** Other Rules

** TODO CONTEXTUAL ABSTRACTIONS
*** TODO Overview
**** TODO Critique of the Status Quo
     TODO
     TODO
     TODO

**** TODO The New Design
     - The following pages introduce a *REDESIGN* of /contextual abstractions/ in
       Scala. *They introduce _four_ fundamental CHANGES*:
       1. /Given Instances/:
          a new way to define basic terms that can be synthesized.
          + They _replace_ /implicit definitions/.

          + The core principle of the proposal:
            rather than mixing the ~implicit~ /modifier/ with a large number of
            features, we have a SINGLE WAY to define terms that can be synthesized
            for types.

       2. /Using Clauses/:
          a new syntax for _IMPLICIT parameters and their arguments_.
          + Both are introduced with the same keyword, ~given~.

          + TODO
            It unambiguously aligns parameters and arguments, solving a number
            of language warts.

          + TODO
            It also allows us to have _SEVERAL_ ~using~ clauses in a definition.

       3. /"Given" Imports/:
          a new class of /import selectors/ that _SPECIFICALLY import givens_
          and nothing else.

       4. /Implicit Conversions/:
          now expressed as /given instances/ of a standard ~Conversion~ class.
          All other forms of /implicit conversions/ WILL _be phased out_.

     - This section also contains pages describing other language features that
       are _related to_ /context abstraction/. These are: TODO TODO TODO
       + /Context Bounds/, which carry over unchanged.

       + /Extension Methods/ REPLACE /implicit classes/ in a way that _integrates
         better with typeclasses_.

       + /Implementing Typeclasses/ demonstrates how some common typeclasses can be
         implemented using the new constructs.

       + /Typeclass Derivation/ introduces constructs to automatically derive /typeclass
         instances/ for ADTs.

       + /Multiversal Equality/ introduces a special typeclass to support /type safe
         equality/.

       + /Context Functions/ provide a way to abstract over /context parameters/.

       + /By-Name Context Parameters/ are an essential tool to DEFINE /recursive
         synthesized values/ WITHOUT looping.

       + _Relationship with Scala 2 Implicits_ discusses the relationship between
         old-style implicits and new-style givens and how to migrate from one to
         the other.

     - =START FROM=
       Overall, the new design achieves a better separation of term inference from the rest of the

*** DONE Given Instances
    CLOSED: [2020-03-08 Sun 23:12]
    /Given instances/ (or, simply, "givens") define "canonical" values of certain
    types that serve for /synthesizing arguments/ to /context parameters/.
    =from Jian= /context parameters/ describes a requirement to /given instances/.

    - Example:
      #+begin_src scala
        trait Ord[T] {
          def compare(x: T, y: T): Int

          def (x: T) < (y: T) = compare(x, y) < 0
          def (x: T) > (y: T) = compare(x, y) > 0
        }

        given intOrd as Ord[Int] {
          def compare(x: Int, y: Int) =
            if (x < y) -1 else if (x > y) +1 else 0
        }

        given listOrd[T](using ord: Ord[T]) as Ord[List[T]] {
          def compare(xs: List[T], ys: List[T]): Int = (xs, ys) match {
            case (Nil, Nil) => 0
            case (Nil, _)   => -1
            case (_, Nil)   => +1
            case (x :: xs1, y :: ys1) =>
              val fst = ord.compare(x, y)
              if (fst != 0) fst else compare(xs1, ys1)
          }
        }
      #+end_src
      This code defines a /trait/ ~Ord~ (typeclass) with two /given instances/.

**** DONE Anonymous Givens
     CLOSED: [2020-03-08 Sun 21:52]
     The name of a /given instance/ *can be left out*.
     #+begin_src scala
       given Ord[Int] { /* ... */ }
       given [T](using Ord[T]) as Ord[List[T]] { /* ... */ }
     #+end_src
     If the name of a given is missing,
     the compiler will _synthesize a name_ from the implemented type(s).
     =from Jian= The doc doesn't mention the rules of synthesizing this name, for
                 the users the rules is not important -- you define an anonymous
                 given means you plan not to use its name.

**** TODO Alias Givens
     An alias can be used to define a /given instance/ that is equal to some
     expression. E.g.:
     #+begin_src scala
       given global as ExecutioinContext = new ForkJoinPool()
     #+end_src
     When the first time ~global~ is accessed, the RHS is evaludated, which is then
     returned for this and all subsequent accesses to ~global~.
     =from Jian= A kind of /lazy evaluation/.
     =from Jian= More initialization rules in the "Given Instance Initialization"
                 below.

     - This operation is /thread-safe/.

     - /Alias givens/ can be _anonymous_ as well, e.g.
       #+begin_src scala
         given Position = enclosingTree.position
         given (using config: Config) as Factory = MemoizingFactory(config)
       #+end_src

     - An /alias given/ can have /type parameters/ and /context parameters/ just like
       any other /given/, _but it can ONLY implement a single type._
       =from Jian= Because it is an alias -- a name or concrete thing, not a
                   general instances.

**** TODO Given Macros
     Given aliases can have the ~inline~ and ~transparent~ modifiers.
     Example:
     #+begin_src scala
       transparent inline given mkAnnotations[A, T] as Annotations[A, T] = ${
         // code producing a value of a subtype of Annotations
       }
     #+end_src
     Since ~mkAnnotations~ is ~transparent~, the type of an application is the
     type of its right hand side, which can be a proper /subtype/ of the declared
     /result type/ ~Annotations[A, T]~.

**** DONE Given Instance Initialization
     CLOSED: [2020-03-08 Sun 23:11]
     - A /given instance/
       + without /type parameters/ or /context parameters/
         *is initialized on-demand, the first time it is accessed.*
         =from Jian= *FROM OLD Dotty Doc*
         * It is _NOT required to ENSURE_ /safe publication/, which means that
           DIFFERENT /threads/ might create DIFFERENT /instances/ for the SAME
           /given definition/.

       + has /type parameters/ or /context parameters/, a *FRESH* instance is
         created _for EACH reference_.

**** DONE Syntax
     CLOSED: [2020-03-08 Sun 23:11]

*** DONE Using Clauses
    CLOSED: [2020-03-09 Mon 00:56]
    - Functional programming tends to express most dependencies as simple function
      parameterization.
      + =from Jian=
        How does Functional programming express dependencies

    - This is clean and powerful, but it sometimes leads to functions that take
      many parameters where the same value is passed over and over again in long
      call chains to many functions.
      + =from Jian=
        The issue that following the way that Functional programming express
        dependencies

    - /Context parameters/ can help here since they enable the compiler to synthesize
      repetitive arguments instead of the programmer having to write them explicitly.
      + =from Jian=
        The way of Scala to resolve the issue mentioned in the last bullet.

    - Example:
      #+begin_src scala
        def max[T](x: T, y: T)(using ord: Ord[T]): T =
          if ord.compare(x, y) < 0 then y else x

        // The explicit way
        max(2, 3)(using intOrd)

        // The implicit way
        max(2, 3)
        max(List(1, 2, 3), Nil)
      #+end_src

**** DONE Anonymous Context Parameters
     CLOSED: [2020-03-09 Mon 00:20]
     - =from Jian=
       A functional /context parameter/ always co-exit with a /given instance/.
       Such as /given instances/, /context parameter/ can be anonymous, though the
       reason for /context parameter/ is different from the reason for /given
       instance/.
       + Anonymous /given instances/ (frequency: Almost Always):
         /given instances/ search is always match types.
         Name is not that important.

       + Anonymous /context parameters/ (frequency: Often):
         =from Doc=
         It is used only in synthesized arguments for OTHER /context parameters/.
         Example:
         #+begin_src scala
           def maximum[T](xs: List[T])(using Ord[T]): T =
             xs.reduceLeft(max)
         #+end_src
         Here the context parameter of type ~Ord[T]~ is synthesized for ~max~,
         not for explicit use as inside ~max~.

     - /Vararg parameters/ are not supported in /using clauses/.
       + =from Jian=
         In the example above,
         * ~Ord[T]~ is the /context parameter/.

         * ~using Ord[T]~ is the /using clause/.

**** DONE Inferring Complex Arguments
     CLOSED: [2020-03-09 Mon 00:49]
     #+begin_src scala
       def descending[T](using asc: Ord[T]): Ord[T] = new Ord[T] {
         def compare(x: T, y: T) = asc.compare(y, x)
       }

       def minimum[T](xs: List[T])(using Ord[T]) =
         maximum(xs)(using descending)

       // minimum(xs)
       // maximum(xs)(using descending)
       // maximum(xs)(using descending(using listOrd))
       // maximum(xs)(using descending(using listOrd(using intOrd)))
     #+end_src
     - =from Jian=
       The description of this section is NOT clear!!!
       Here is my understanding:
         If, in the example above, not ~using descending~ passed in, the ~maximum~
       function will find the maximum value. This why we must manually provide the
       ~using descending~ to make the code be functional as we expect. Or else, it
       is runnable (with a wrong synthesized ~Ord[T]~ instance) and returns a wrong
       result.

**** DONE Multiple Using Clauses
     CLOSED: [2020-03-09 Mon 00:52]
     There can be several using clauses in a definition and using clauses can be
     freely mixed with normal parameter clauses. Example:
     #+begin_src scala
       def f(u: Universe)(using ctx: u.Context)(using s: ctx.Symbol, k: ctx.Kind) = ...
     #+end_src

     - Multiple using clauses are matched left-to-right in applications. Example:
       #+begin_src scala
         object global extends Universe { type Context = ... }
         given ctx  as global.Context { type Symbol = ...; type Kind = ... }
         given sym  as ctx.Symbol
         given kind as ctx.Kind
       #+end_src

     - Then the following calls are all valid (and normalize to the last one)
       #+begin_src scala
         f(global)
         f(global)(using ctx)
         f(global)(using ctx)(using sym, kind)
       #+end_src

     - Invalid, for example:
       ~f(global)(using sym, kind)~

**** DONE Summoning Instances
     CLOSED: [2020-03-09 Mon 00:56]
     - =from Jian=
       ~sommon~ from ~Predef~ is a replacement of the ~implicitly~ in Scala 2.

     - The ~summon~ is simply defined as /the (*non-widening*) identity function/
       over a /context parameter/:
       #+begin_src scala
         def sommon[T](using x: T): x.type = x
       #+end_src

**** DONE Syntax
     CLOSED: [2020-03-09 Mon 00:56]

*** DONE Context Bounds
    CLOSED: [2019-11-12 Tue 02:20]
    A /context bound/ is a *SHORTHAND* for expressing the common pattern (a.k.a
    typeclass pattern) of an /context parameter/ that depends on *A* /type parameter/.
    #+begin_src scala
      def maximum[T: Ord](xs: List[T]): T = xs.reduceLeft(max)
    #+end_src

**** Context Bounds
     - The /context parameter(s)/ *generated from* /context bounds/ come *LAST*
       in the definition of the containing /method/ or /class/. E.g.
       #+begin_src scala
         def f[T: C1 : C2, U: C3](x: T)(using y: U, z: V): R

         // would expand to

         def f[T, U](x: T)(using y: U, z: V)(using C1[T], C2[T], C3[U]): R
       #+end_src

     - /Context bounds/ can be combined with /subtype bounds/.
       _If both are present, /subtype bounds/ *come first*,_ e.g.
       ~def g[T <: B : C](x: T):R = ...~

**** Migration
**** Syntax
     #+begin_src text
       TypeParamBounds ::= [SubtypeBounds] {ContextBound}
       ContextBound    ::= ':' Type
     #+end_src

*** DONE Given Imports
    # Importing Givens
    CLOSED: [2019-11-13 Wed 14:44]
    A _special form_ of /import wildcard selector/ is used to IMPORT /given
    instances/.
    - Example:
      #+begin_src scala
        object A {
          class TC
          given tc as TC
          def f(using TC) = ???
        }

        object B {
          import A._
          import A.{given _}
          // ...
        }
      #+end_src
      + In Dotty, ~import A._~ import all members of ~A~ *except* the /given instances/.

      + Merge the two import clauses: ~import A.{given _, _}~

    - There are _TWO_ main benefits arising from these rules:
      + It is made clearer where /givens/ in scope are coming from.

      + It enables importing all /givens/ without importing anything else.
        This is _particularly important since /givens/ can be ANONYMOUS_, so the
        usual recourse of using /named imports/ is NOT practical.

**** DONE Importing By Type
     CLOSED: [2019-11-13 Wed 14:37]
     Since /givens/ can be _anonymous_ it is _NOT always practical to import them
     by their name_, and /wildcard imports/ are typically used instead.
       /By-type imports/ provide a _MORE SPECIFIC alternative_ to /wildcard imports/,
     which makes it clearer what is imported.

     - Example:
       + ~import A.{given TC}~

       + ~import A.{given T1, given T2, ..., given Tn}~

       + ~import A.{given Ordering[?]}~ -- =IMPORTANT= easy to forget this usage

       + /By-type imports/ can be mixed with /by-name imports/.
         If BOTH are present in an import clause, *by-type imports come last*.
         ~import A.{im, given Ordering[?]}~

     - =from Jian= *EXIST BEFORE, but _DELETED_ from this page (ver 0.23.0)*
       /Bounded wildcard selectors/ *also work* for _normal imports and exports_.
       For instance,
       #+begin_src scala
         enum Color {
           case Red, Green, Blue, Megenta

           def isPrimary(c: Color): Boolean = ...
         }

         // Export all four `Color` values, but leaves the `isPrimary` method alone.
         export Color.{_: Color}
       #+end_src

**** DONE Migration
     CLOSED: [2019-11-13 Wed 14:42]
     TODO NOTE
**** DONE Syntax
     CLOSED: [2019-11-13 Wed 14:44]
     TODO NOTE

*** DONE Extension Methods
    CLOSED: [2020-03-10 Tue 00:59]
    /Extension methods/ allow one to add /methods/ to a /type/ after the /type/
    is defined.
    =from Jian= A way to extend a closed (not own, or better not change) system.

    - Example:
      + Definition:
        #+begin_src scala
          case class Circle(x: Double, y: Double, radius: Double)

          def (c: Circle).circumference: Double = c.radius * math.Pi * 2
        #+end_src

      + Invoke as regular methods:
        #+begin_src scala
          val circle = Circle(0, 0, 1)
          circle.circumference
        #+end_src

**** DONE Translation of Extension Methods
     CLOSED: [2020-03-09 Mon 23:15]
     - extension methods :: /methods/ that have a parameter clause in front of the
       defined identifier.

     - They translate to methods where the leading parameter section is moved to
       after the defined identifier.
         So, the definition of ~circumference~ above translates to the plain
       method, and can also be invoked as such:
       #+begin_src scala
         def circumference(c: Circle): Double = c.radius * math.Pi * 2

         assert(circle.circumference == circumference(circle))
       #+end_src

**** TODO Translation of Calls to Extension Methods
     - When is an /extension method/ applicable? There are two possibilities.
       An /extension method/ is applicable
       + if it is visible under a simple name,
         in a scope enclosing the application,
         by being
         * _defined_
           or
         * _inherited_
           or
         * _imported_

       + if it is a member of some /given instance/ at the point of the application.

     - Example:
       #+begin_src scala
         trait IntOps {
           def (i: Int).isZero: Boolean =
             i == 0

           def (i: Int).safeMod(x: Int): Option[Int] =
             // extension method defined in same scope IntOps
             if x.isZero then None
             else             Some(i % x)
         }

         object IntOpsEx extends IntOps {
           def (i: Int).safeDiv(x: Int): Option[Int] =
             // extension method brought into scope via inheritance from IntOps
             if x.isZero then None
             else             Some(i / x)  // TODO: in the doc, this is `i % x`, and I think it's a typo

         }

         trait SafeDiv {
           import IntOpsEx._  // brings safeDiv and safeMod into scope

           def (i: Int) divide(d: Int): Option[(Int, Int)] =
             // extension methods imported and thus in scope
             (i.safeDiv(d), i.safeMod(d)) match {
               case (Some(d), Some(r)) => Some((d, r))
               case _                  => None
             }
         }
       #+end_src
       + TODO
       + TODO
       + TODO
       + TODO

     - The _PRECISE_ *rules for RESOLVING a selection to an extension method* are
       as follows:
         Assume a selection ~e.m[Ts]~ where ~m~ is not a member of ~e~, where
       the /type arguments/ ~[Ts]~ are _OPTIONAL_, and where ~T~ is the expected
       type. The following two rewritings *are tried in order*:

       1. The selection is rewritten to ~m[Ts](e)~.

       2. If the first rewriting does not typecheck with expected type ~T~, and
          there is a /given instance/ ~g~ in either the /current scope/ or in
          the /context scope/ of ~T~, and ~g~ defines an /extension method/
          named ~m~, then selection is expanded to ~g.m[Ts](e)~. This second
          rewriting is attempted at the time where the compiler also tries an
          /implicit conversion/ from ~T~ to a type containing ~m~.
            *If there is more than one way of rewriting, an ambiguity error
          results.*

     - So ~circle.circumference~ translates to ~CircleOps.circumference(circle)~,
       provided ~circle~ has type ~Circle~ and ~CircleOps~ is /given/ (i.e. it is
       visible at the point of call or it is defined in the /companion object/ of
       ~Circle~).

**** DONE Operators
     CLOSED: [2020-03-10 Tue 00:16]
     - Use /extension method syntax/ to define operators.
       + This case is indicated by *omitting the period* between the leading
         parameter list and the operator.

       + This syntax mirrors the way the operator is applied.

     - Examples:
       #+begin_src scala
         def (x: String) < (y: String) = ...
         def (x: Elem) +: (xs: Seq[Elem]) = ...
         def (x: Number) min (y: Number) = ...

         "ab" < "c"
         1 +: List(2, 3)
         x min 3
       #+end_src
       + For /alphanumeric extension operators/ like ~min~ an ~@infix~ annotation
         is *implied*.

       + The translations:
         #+begin_src scala
           def <(x: String)(y: String) = ...
           def +:(xs: Seq[Elem])(x: Elem) = ...
           def min(x: Number)(y: Number) = ...
         #+end_src
         * Remember that in Scala ~:~ suffixed operators are all /right associative/!!!
           This is why ~+:~ in the translation, the order of ~x~ and ~xs~ are swapped!

**** DONE Generic Extensions
     CLOSED: [2020-03-10 Tue 00:33]
     We already discussed ~StringSeqOps~, which extends a specific instance of
     generic type (~Seq[String]~).
       This section will discuss /extension method of generic type/.

     - Examples:
       #+begin_src scala
         def [T](xs: List[T]) second =
           xs.tail.head

         def [T](xs: List[List[T]]) flattened =
           xs.foldLeft[List[T]](Nil)(_ ++ _)

         def [T: Numeric](x: T) + (y: T): T =
           summon[Numeric[T]].plus(x, y)
       #+end_src

     - Usage:
       ~List(1, 2, 3).second[Int]~

**** DONE Extension Instances
     CLOSED: [2020-03-10 Tue 00:59]
     It is quite common to wrap one or more /extension methods/ in a /given
     instance/, _in order to make them available as methods without needing to be
     imported explicitly_. This pattern is supported by a special /extension
     syntax/.

     - Example:
       #+begin_src scala
         extension ops {
           def (xs: Seq[String]).longestStrings: Seq[String] = {
             val maxLength = xs.map(_.length).max
             xs.filter(_.length == maxLength)
           }

           def (xs: Seq[String]).longestString: String = xs.longestStrings.head

           def [T](xs: List[T]).second: T = xs.tail.head
         }
       #+end_src

     - *An /extension instance/ can _ONLY_ contain /extension methods/.*
       *Other definitions are not allowed.* The name ~ops~ of the ~extension~ is
       *optional*. It can be left out:
       #+begin_src scala
         extension {
           def (xs: Seq[String]).longestStrings: Seq[String] = ...
           def [T](xs: List[T]).second: T = ...
         }
       #+end_src
       + If no name is given explicitly for ~extension~, a name will be synthesized
         from the _name_ and _type_ of the *first* implemented /extension method/.

     - /Extension instances/ map DIRECTLY to /given instances/.
       The code above would expand to
       #+begin_src scala
         given ops as AnyRef {
           def (xs: Seq[String]).longestStrings: Seq[String] = ...
           def (xs: Seq[String]).longestString: String = ...
           def [T](xs: List[T]).second: T = ...
         }
       #+end_src

     - The type "implemented" by this /given instance/ is ~AnyRef~, which is _not
       a type one can summon by itself._ TODO TODO TODO TODO TODO TODO ??? TODO TODO
         This means that the instance can _ONLY_ be used for its /extension methods/.

**** DONE Collective Extensions
     CLOSED: [2020-03-10 Tue 00:47]
     Define several /extension methods/ that *SHARE the SAME left-hand parameter type.*
       In this case one can "pull out" the common parameters into the /extension
     instance/ itself. Examples:
     #+begin_src scala
       extension stringOps on (ss: Seq[String]) {
         def longestStrings: Seq[String] = {
           val maxLength = ss.map(_.length).max
           ss.filter(_.length == maxLength)
         }
         def longestString: String = longestStrings.head
       }

       extension listOps on [T](xs: List[T]) {
         def second: T = xs.tail.head
         def third: T = xs.tail.second
       }

       extension on [T](xs: List[T])(using Ordering[T]) {
         def largest(n: Int) = xs.sorted.takeRight(n)
       }
     #+end_src
     + The /collective extensions/ above expand to the following /extension instances/:
       #+begin_src scala
         extension stringOps {
           def (ss: Seq[String]).longestStrings: Seq[String] = {
             val maxLength = ss.map(_.length).max
             ss.filter(_.length == maxLength)
           }
           def (ss: Seq[String]).longestString: String =
             ss.longestStrings.head
         }

         extension listOps {
           def [T](xs: List[T]).second: T = xs.tail.head
           def [T](xs: List[T]).third: T = xs.tail.second
         }

         extension {
           def [T](xs: List[T]).largest(using Ordering[T])(n: Int) =
             xs.sorted.takeRight(n)
         }
       #+end_src
       * Illustrate the code transformation by inspecting
         ~def longestString: String = longestStrings.head~
         #+begin_src scala
           def (ss: Seq[String]).longestString: String =
             ss.longestString.head
         #+end_src

**** DONE Syntax
     CLOSED: [2020-03-10 Tue 00:47]
     - TODO

     - ~extension~ and ~on~ are /soft keywords/, recognized only when they appear
       at the start of a statement in one of the patterns
       #+begin_src scala
         extension on ...

         extension <ident> on ...

         extension { ...

         extension <ident> { ...
       #+end_src

*** DONE Implementing Typeclasses
    CLOSED: [2020-03-09 Mon 01:00]
    /Given instances/, /extension methods/ and /context bounds/ allow a concise and
    natural expression of /typeclasses/.

    - /Typeclasses/ are just /traits/ with canonical implementations defined by
      /given instances/.

    - Here are some examples of standard typeclasses:

**** Semigroups and monoids
     #+begin_src scala
       trait SemiGroup[T] {
         def (x: T) combine (y: T): T
       }

       trait Monoid[T] extends SemiGroup[T] {
         def unit: T
       }

       object Monoid {
         def apply[T](using m: Monoid[T]) = m
       }

       given Monoid[String] {
         def (x: String) combine (y: String): String = x.concat(y)
         def unit: String = ""
       }

       given Monoid[Int] {
         def (x: Int) combine (y: Int): Int = x + y
         def unit: Int = 0
       }

       def sum[T: Monoid](xs: List[T]): T =
         xs.foldLeft(Monoid[T].unit)(_ combine _)
     #+end_src

     - TODO

     - TODO

**** TODO Functors
     #+begin_src scala
       trait Functor[F[?]] {
         def [A, B](x: F[A]).map(mapper: A => B): F[B]
       }
     #+end_src

     - The instance of ~Functor~ for ~List~ now becomes:
       #+begin_src scala
         given Functor[List] {
           def [A, B](original: List[A]).map(mapper: A => B): List[B] =
             original.map(mapper)  // List already has a `map` method
         }
       #+end_src

**** TODO Monads
     #+begin_src scala
       // "A `Monad` for type `F[?]` is a `Functor[F]`" => thus has the `map` ability
       trait Monad[F[?]] extends Functor[F] {
         // `pure` can construct F[A] from a single value A
         def pure[A](x: A): F[A]

         // the flattening ability is named `flatMap`, using extension methods as previous exmaples
         def [A, B](x: F[A]).flatMap(f: A => F[B]): F[B]

         // the `map(f)` ability is simply a combination of applying `f` then
         // turning the result into an `F[A]` then applying `flatMap` to it
         def [A, B](x: F[A]).map(f: A => B) = x.flatMap(f `andThen` pure)
       }
     #+end_src

***** List
      #+begin_src scala
        given listMonad as Monad[List] {
          def pure[A](x: A): List[A] =
            List(x)

          def [A, B](xs: List[A]).flatMap(f: A => List[B]): List[B] =
            xs.flatMap(f)  // Let's rely on the existing `flatMap` method of `List`
        }
      #+end_src

***** Option
      #+begin_src scala
        given optionMonad as Monad[Option] {
          def pure[A](x: A): Option[A] =
            Option(x)

          def [A, B](xs: Option[A]).flatMap(f: A => Option[B]): Option[B] =
            xs.flatMap(f)  // Let's rely on the existing `flatMap` method of `Option`
        }
      #+end_src

***** TODO The Reader Monad

**** TODO Summary

*** TODO Typeclass Derivation
    # Type class Derivation
**** Types supporting ~derives~ clauses
**** Type classes supporting automatic deriving
***** How to write a type class ~derived~ method using low level mechanisms

**** Deriving instances elsewhere
**** Syntax
**** Discussion

*** TODO Multiversal Equality
**** Deriving ~Eql~ Instances
**** Precise Rules for Equality Checking
**** Predefined ~Eql~ Instances
**** Why Two Type Parameters?

*** TODO Context Functions
**** Example: Builder Pattern
**** Example: Postconditions
**** Reference

*** DONE Implicit Conversions
    CLOSED: [2020-03-11 Wed 00:14]
    /Implicit conversions/ are defined by /given instances/ of the
    ~scala.Conversion~ class.

    - ~scala.Conversion~ class is defined in package scala as follows:
      #+begin_src scala
        abstract class Conversion[-T, +U] extends (T => U)
      #+end_src

    - Example:
      #+begin_src scala
        given Conversion[String, Token] {
          def apply(str: String): Token = new KeyWord(str)
        }
      #+end_src
      + Express more concisely as:
        #+begin_src scala
          given Conversion[String, Token] = new KeyWord(_)
        #+end_src

    - An /implicit conversion/ is applied automatically by the compiler in _THREE_
      situations:
      + _Type_ doesn't match, but an after an /implicit conversion/, type can match.

      + _Method Name_ doesn't match, but an after an /implicit conversion/, method
        can be found.

      + _Method Name matches, but Method Signature doesn't match_, but an after
        an /implicit conversion/, /method signature/ can match.

**** Examples
     1. In ~Predef~
        #+begin_src scala
          given int2Integer as Conversion[Int, java.lang.Integer] =
            java.lang.Integer.valueOf(_)
        #+end_src

     2. /Magnet pattern/ that use /implicit conversion/:
        #+begin_src scala
          object Completions {

            // The argument "magnet" type
            enum CompletionArg {
              case Error(s: String)
              case Response(f: Future[HttpResponse])
              case Status(code: Future[StatusCode])
            }

            object CompletionArg {

              // conversions defining the possible arguments to pass to `complete`
              // these always come with CompletionArg
              // They can be invoked explicitly, e.g.
              //
              //   CompletionArg.fromStatusCode(statusCode)

              given fromString     as Conversion[String, CompletionArg]               = Error(_)
              given fromFuture     as Conversion[Future[HttpResponse], CompletionArg] = Response(_)
              given fromStatusCode as Conversion[Future[StatusCode], CompletionArg]   = Status(_)
            }

            import CompletionArg._

            def complete[T](arg: CompletionArg) = arg match {
              case Error(s)     => ...
              case Response(f)  => ...
              case Status(code) => ...
            }
          }
        #+end_src
        + =from Jian= Why does ~complete~ have a /type parametr/ ~T~.

        + This setup is more complicated than simple overloading of ~complete~ (the
          traditional way of implementing the /magnet pattern/),
          BUT it can still be useful
          * *if normal /overloading/ is not available* (as in the case above, since
            we cannot have two overloaded methods that take ~Future[...]~ arguments),
            =from Jian= ??? /Type erasure/ ???
            _OR_
          * if normal overloading would lead to a _combinatorial explosion of variants_.

*** TODO By-Name Context Parameters
**** Reference

*** TODO Relationship with Scala 2 Implicits
**** Simulating Scala 3 Contextual Abstraction Concepts with Scala 2 Implicits
***** Given Intances
***** Anonymous Given Intances
***** Anonymous Collective Extensions
***** Given Clauses
***** Context Bounds
***** Extension Methods
***** Typeclass Derivation
***** Implicit Function Types
***** Implicit By-Name Parameters

**** Simulating Scala 2 Implicits in Scala 3
***** Implicit Conversions
***** Implicit Classes
***** Implicit Values
***** Abstract Implicits

**** Implementation Status and Timeline

** TODO METAPROGRAMMING
*** DONE Overview
    CLOSED: [2019-06-24 Mon 02:35]
    The following fundamental facilities:
    1. /Inline/ NOTE DONE
       ~inline~ is a new /soft modifier/ that *guarantees* that a definition will
       be inlined at the point of use.

       - The primary motivation:
         *reduce the overhead* behind
         + _function calls_
         + _access to values_.

       - The _expansion_ will be performed by the Scala compiler _during the *Typer*
         /compiler phase/._

       - =IMPORTANT=
         ~inline~ is a command to the *compiler* (=from Jian= *MUST DO*, and fail
         to do will lead to a compilation error -- when the code doesn't follow the
         requirement of ~inline~). This is different from some other ecosystems, in
         which /inline/ is a request that _might be_ satisfied by the compiler.

       - The reason is that /inlining/ in Scala can drive other _compile-time
         operations_, like
         TODO TODO TODO - =from Jian= I don't understand these terminology!!!
         + /inline/ /pattern matching/ (enabling type-level programming)
         + /macros/ (enabling compile-time, generative, metaprogramming)
         + /runtime code generation/ (multi-stage programming)

    2. /Macros/ construct code at /compile-time/
       - /Macros/ are built on two well-known fundamental operations:
         + quotation ::
           *converts program code to data*, specifically, a (tree-like)
           representation of this code. It is expressed as
           * ~'{...}~ for /expressions/
           * ~'[...]~ for /types/

         + splicing :: *converts a program's representation to program code*
           * expressed as ~${ ... }~.

       - The /inline/ and /splicing/ abstractions allow to construct program
         code programmatically.

    3. /Staging/ construct new code at /runtime/.
       That way, code generation can depend not only on static data but also on
       data available at runtime. This splits the evaluation of the program in
       two or more phases or ... /stages/.
         Consequently, this method generative programming is called /"Multi-Stage
       Programming"/. /Staging/ is built on the _SAME_ foundations as /macros/.
       It uses /quotes/ and /splices/, but _LEAVES OUT_ /inline/.

    4. /TASTy Reflection/
       + /Quotations/ are a "black-box" representation of code.
         They can be parameterized and composed using /splices/ but their
         structure cannot be analyzed from the outside.
       + /Tasty reflection/ gives a way to analyze code structure by partly
         revealing the representation type of a piece of code in a standard API.
         TODO
         The _representation type_ is a form of /typed abstract syntax tree/,
         which gives rise to the "TASTy` moniker.

    5. /TASTy Inspection/
       /Typed abstract syntax trees/ are serialized in a custom compressed
       binary format in =.tasty= files. /TASTy inspection/ allows to _load_
       these files and _analyze_ their content's tree structure.

*** TODO Inline
**** DONE Inline Definitions
     CLOSED: [2020-03-11 Wed 00:43]
     - ~inline~ :: a new /soft modifier/ that *guarantees* that a definition will
                   be inlined at the point of use.
     - Example:
       #+begin_src scala
         object Config {
           inline val logging = false
         }

         object Logger {

           private var indent = 0

           inline def log[T](msg: String, indentMargin: =>Int)(op: => T): T =
             if (Config.logging) {
               println(s"${"  " * indent}start $msg")
               indent += indentMargin
               val result = op
               indent -= indentMargin
               println(s"${"  " * indent}$msg = $result")
               result
             }
             else op
         }
       #+end_src
       + The ~Config~ object contains a definition of the /inline value/ ~logging~.
         This means that logging is treated as a constant value, equivalent to
         its RHS ~false~. The RHS of such an ~inline val~ must itself be a
         /constant expression/.
         * Used in this way, ~inline~ is *equivalent to* Java and Scala 2's ~final~.
           =IMPORTANT=
           Note that ~final~, meaning /inlined constant/,
           - is still supported in Dotty,
           - but *will be Phased Out*.

       + The ~Logger~ object contains a definition of the /inline method/ ~log~.
         This method will always _be inlined at the point of call_.

       + Usage and re-write:
         #+begin_src scala
           var indentSetting = 2

           def factorial(n: BigInt): BigInt = {
             log(s"factorial($n)", indentSetting) {
               if (n == 0) 1
               else n * factorial(n - 1)
             }
           }
         #+end_src

         - With current definition ~inline val logging = false~,
           The usage code will be re-written as
           #+begin_src scala
             def factorial(n: BigInt): BigInt = {
               if (n == 0) 1
               else        n * factorial(n - 1)
             }
           #+end_src

         - If the example code define ~inline val logging = false~, then the
           usage code will be re-written as
           #+begin_src scala
             def factorial(n: BigInt): BigInt = {
               val msg = s"factorial($n)"
               println(s"${"  " * indent}start $msg")
               Logger.inline$indent_=(indent.+(indentSetting))
               val result =
                 if (n == 0) 1
                 else        n * factorial(n - 1)
               Logger.inline$indent_=(indent.-(indentSetting))
               println(s"${"  " * indent}$msg = $result")
               result
             }
           #+end_src
           NOTE:
           + The /by-value parameter/ ~msg~ is _evaluated only once_,
             per the usual Scala semantics, by binding the value and reusing the
             ~msg~ through the body of ~factorial~.

           + The special handling of the assignment to the ~private var indent~.
             It is achieved by *generating* a /setter method/ ~def
             inline$indent_=~ and calling it instead.

**** DONE Recursive Inline Methods
     CLOSED: [2019-12-29 Sun 02:39]
     /Inline methods/ can be *recursive*.
     - For instance, when called with a constant exponent ~n~, the following method
       for ~power~ will be implemented by straight inline code *WITHOUT ANY
       /loop/ or /recursion/.*
       #+begin_src scala
         inline def power(x: Double, n: Int): Double = {
           if (n == 0) 1.0
           else if (n == 1) x
           else {
             val y = power(x, n / 2)
             if (n % 2 == 0) y * y else y * y * x
           }
         }

         power(expr, 10)
         // translates to
         //
         //    val x = expr
         //    val y1 = x * x   // ^2
         //    val y2 = y1 * y1 // ^4
         //    val y3 = y2 * x  // ^5
         //    y3 * y3          // ^10
       #+end_src

     - /Parameters/ of /inline methods/ can have an ~inline~ modifier as well.
         This means that actual arguments to these parameters *must be constant
       expressions*. For example:
       ~inline def power(x: Double, inline n: Int): Double~

     - There also can be /inline parameters/.
       /Inline parameters/ have call semantics *equivalent* to /by-name parameters/
       but allow for duplication of the code in the argument.
       TODO ??? TODO ??? TODO
         It is usually useful when /constant values/ need to be propagated to
       allow further optimizations/reductions.

     - The difference in translation between /by-value/, /by-name/, and ~inline~
       parameters:
       #+begin_src scala
         inline def funkyAssertEquals(actual: Double,
                                      expected: =>Double,
                                      inline delta: Double): Unit =
           if ((actual - expected).abs > delta)
             throw new AssertionError(s"difference between ${expected} and ${actual} was larger than ${delta}")

         funkyAssertEquals(computeActual(), computeExpected(), computeDelta())
         // translates to
         //
         //    val actual = computeActual()
         //    def expected = computeExpected()
         //    if (actual - expected).abs > computeDelta() then
         //      throw new AssertionError(s"difference between ${expected} and ${actual} was larger than ${computeDelta()}")
       #+end_src

**** DONE Relationship to ~@inline~
     CLOSED: [2019-12-28 Sat 23:21]
     - The ~inline~ modifier is a _MORE POWERFUL_ than the ~@inline~ annotation.

       + ~@inline~ annotation ::
         * A _hint_
           - _Hint_ here means _try with BEST EFFORT, but NOTHING GUARANTEED!_

         * The _hint_ is for the *backend*


       + ~inline~ /modifier/ ::
         * A _command_
           - _Command_ here means _GUARANTEED!_

         * The _command_ is for the *frontend*

         * it also applies to recursive methods.

     - Cross compilation between Dotty and Scala 2:
       + Introduce ~@forceInline~ in Dotty.
         * For dotc it is the same as ~inline~.
         * For scalac it will be ignored.

       + Usage:
         Always use ~@forceInline @inline~ if cross compilation between Dotty
         and Scala 2 is required. This can make
         * Dotty always inline the annotated code (becase of ~@forceInline~)
         * Scala 2 try its best to inline (because of ~@inline~)

         =from Jian= TODO TODO TODO TODO TODO
         What exactly is this /Cross compilation between Dotty and Scala 2/???
         It seems due to this cross compilation, both dotc and scalac will see
         ~@forceInline @inline~.
         TODO TODO TODO
           My old understanding of /cross compilation/ is dotc compiles Scala 3
         code, scalac compiles Scala 2 code, and the compiled code will be
         combined together in some way. It seems this understanding is wrong!

***** The definition of constant expression

      Scala Language Specification 2.13 - _6.24 Constant Expressions_

**** TODO Specializing Inline (Whitebox)
**** DONE Inline Conditionals
     CLOSED: [2019-06-24 Mon 03:05]
     #+begin_src scala
       inline def update(delta: Int) =
         inline if (delta >= 0) increaseBy(delta)
                else            decreaseBy(-delta)
     #+end_src
     + Use ~inline~ means in the call site ~delta~ _MUST be_ a /compile-time
       constant/.

     + A call ~update(22)~ would re-write to ~increaseBy(22)~.

     + A call with a value of not compile-time constant will trigger a compile
       error:
       #+begin_src text
            |  inline if (delta >= 0) ???
            |  ^
            |  cannot reduce inline if
            |   its condition
            |     delta >= 0
            |   is not a constant value
            | This location is in code that was inlined at ...
       #+end_src

**** TODO Inline Matches
     - TODO
       #+begin_src scala
         inline def g(x: Any) <: Any = inline x match {
           case x: String => (x, x)  // Tuple2[String, String](x, x)
           case x: Double => x
         }

         g(1.0d)  // Has type 1.0d which is a subtype of Double
           g("test")  // Has type (String, String)
       #+end_src

     - TODO
       #+begin_src scala
         trait Nat
         case object Zero extends Nat
         final case class Succ[N <: Nat](n: N) extends Nat

         inline def toInt(n: Nat) <: Int = inline n match {
           case Zero     => 0
           case Succ(n1) => toInt(n1) + 1
         }

         final val natTwo = toInt(Succ(Succ(Zero)))
         val intTwo: 2 = natTwo
       #+end_src

**** DONE The ~scala.compiletime~ Package
     CLOSED: [2019-06-24 Mon 16:36]
     The ~scala.compiletime~ package contains _helper definitions_ that provide
     support for /compile time/ OPERATIONS over _values_. They are described in the
     following.
***** ~constValue~, ~constValueOpt~, and the ~S~ combinator
      - ~constValue[T]~ generate a constant value of type ~T~

      -                0.200.13@25.3.1 (spacema~constValueOpt[T]~ generate a constant value of type ~Option[T]~

      - ~S~ is the type of the successor of some singleton type.
        For example, ~S[1]~ is the /singleton type/ ~2~.

***** ~erasedValue~
      - The ~erasedValue[T]~ function in ~scala.comiletime.erasedValue~ is not
        implemented -- it would always raise a ~NotImplementedError~ exception
        when called.
          _However, it can in fact never be called, since it is declared ~erased~ --
        it is only used at /compile-time/ during type checking._

      - Example:
        #+begin_src scala
          import scala.comiletime.erasedValue
          // erased def erasedValue[T]: T = ???

          inline def defaultValue[T] = inline erasedValue[T] match {
            case _: Byte    => Some(0: Byte)
            case _: Char    => Some(0: Char)
            case _: Short   => Some(0: Short)
            case _: Int     => Some(0)
            case _: Long    => Some(0L)
            case _: Float   => Some(0.0f)
            case _: Double  => Some(0.0d)
            case _: Boolean => Some(false)
            case _: Unit    => Some(())
            case _          => None
          }

          val dInt:     Some[Int]     = defaultValue[Int]
          val dDouble:  Some[Double]  = defaultValue[Double]
          val dBoolean: Some[Boolean] = defaultValue[Boolean]
          val dAny:     Any.type      = defaultValue[Any]
        #+end_src

      - Another example:
        #+begin_src scala
          inline def toIntT[N <: Nat] <: Int = inline erasedValue[N] match {
            case _: Zero.type => 0
            case _: Succ[n]   => toIntT[n] + 1
          }

          final val two = toIntT[Succ[Succ[Zero.type]]]
        #+end_src
        + =from Jian= I think the ~final~ here is not the best practice!!!
          #+begin_quote
          Used in this way, inline is equivalent to Java and Scala 2's final.
          Note that ~final~, meaning /inlined constant/,
          is still supported in Dotty, BUT *will be phased out*.
            -- from "Inline Definitions" subsection in this doc
          #+end_quote


      - TODO
        Last paragraph???

***** ~error~
      The ~error~ /method/ is used to produce _user-defined_ /compile errors/
      *DURING /inline expansion/.* It has the following signature:
      #+begin_src scala
        inline def error(inline msg: String): Nothing
      #+end_src

      - If an /inline expansion/ results in a call ~error(msgStr)~ the compiler produces
        an _error message_ containing the given ~msgStr~.
        + Example 1
          #+begin_src scala
            inline def fail() = {
              error("failed for a reason")
            }

            fail()  // error: failed for a reason
          #+end_src

          OR

        + Example 2
          #+begin_src scala
            inline def fail(p1: => Any) = {
              error(code"failed on: $p1")
            }

            fail(indentity("foo"))  // error: failed on: indentity("foo")
          #+end_src

***** The ~scala.compiletime.ops~ package

**** DONE Summoning Implicits Selectively
     CLOSED: [2019-06-24 Mon 16:46]
     Example: Generate differnt type of values based on the ~given~ context.
     - The old way is full of boilterplate:
       #+begin_src scala
         trait SetFor[T, S <: Set[T]]

         class LowPriority {
           implicit def hashSetFor[T]: SetFor[T, HashSet[T]] = ...
         }

         object SetFor extends LowPriority {
           implicit def treeSetFor[T: Ordering]: SetFor[T, TreeSet[T]] = ...
         }
       #+end_src
       + TODO NOTE
       + TODO NOTE
       + TODO NOTE

     - The ~scala.compiletime.summonFrom~ construct makes /implicit search/ available
       in a functional context.
       #+begin_src scala
         inline def setFor[T]: Set[T] = implicit match {
           case _: Ordering[T] => new TreeSet[T]
           case _              => new HashSet[T]
         }
       #+end_src
       + A ~summonFrom~ /call/ takes a /pattern matching closure/ as argument.
           All patterns in the /closure/ are /type ascriptions/ of the form
         ~identifier : Type~.

       + Patterns are tried in sequence (=from Jian= This help us avoiding using
         inheritance to solve the _implicit search priority issue_).

       + ~summonFrom~ application *must be reduced at /compile time/.*

     - Of course, when there is /contextual abstractions/, /ambiguity errors/ can
       happen:
       #+begin_src scala
         class A
         implicit val a1: A = new A
         implicit val a2: A = new A

         inline def f: Any = summonFrom {
           case given _: A => ???  // error: ambiguous implicits
         }
       #+end_src

***** ~summonInline~

**** TODO Reference

*** TODO Macros
**** DONE Macros: Quotes and Splices
     CLOSED: [2020-03-31 Tue 17:27]
     - Macros are built on two well-known fundamental operations:
       + quotation :: ~'{...}~ for /expressions/;
                      ~'[...]~ for /types/.

       + splicing :: ~${ ... }~

     - Additionally,
       _within_ a /quote/ or a /splice/ we can /quote/ or /splice/ _identifiers_
       directly (i.e. ~'e~ and ~$e~).

     - Readers may notice the _RESEMBLANCE_ of the two aforementioned syntactic
       schemes with the familiar /string interpolation syntax/. /Quotes/ and
       /splices/ in this section allow us to treat code in a similar way,
       effectively supporting /macros/.
       #+begin_src scala
         println(s"Hello, $name, here is the result of 1 + 1 = ${1 + 1}")
       #+end_src
       In string interpolation we /quoted/ a string and then we /spliced/ into it,
       two others.
       1. ~name~, is a reference to a value of type string,
       2. an _arithmetic expression_ that will be evaluated followed by the /splicing/
          of its string representation.

     - The entry point for /macros/ is an /inline method/ with a *top-level* /splice/.
       We call it a top-level because it is the *only occasion* where we encounter a
       /splice/ *outside* a /quote/ (consider as a /quote/ the compilation-unit at the
       call-site).

       For example, the code below presents an ~inline~ /method/ ~assert~ which
       calls at compile-time a method ~assertImpl~ with a /boolean expression
       tree/ as argument. ~assertImpl~ evaluates the expression and prints it again
       in an error message if it evaluates to ~false~.
       #+begin_src scala
         import sala.quoted._

         inline def assert(expr: => Boolean): Unit =
           ${ assertImpl('expr) }

         def assertImpl(expr: Expr[Boolean])(using QuoteContext) = '{
           if (!$expr)
             throw new AssertionError(s"failed assertion: ${${ showExpr(expr) }}")
         }

         def showExpr(expr: Expr[Boolean])(using QuoteContext): Expr[String] =
           '{ "<some source code>" }  // Better implementation later in this document
       #+end_src

     - /Quotations/ can have _spliced_ parts in them; in this case the embedded /splices/
       _are evaluated and embedded as part of_ the formation of the /quotation/.

     - /Quotes/ and /splices/ can also be applied *DIRECTLY* to _identifiers_.
       + An /identifier/ ~$x~ starting with a ~$~ that appears _INSIDE_ a /quoted
         expression or type/ is _treated as_ a /splice/ ~${x}~.

       + Analogously, an /quoted identifier/ ~'x~ that appears _INSIDE_ a /splice/
         is _treated as_ a /quote/ ~'{x}~.

     - /Quotes/ and /splices/ are *DUALS of each other*.
       For arbitrary /expressions/ ~e~ and /types/ ~T~ we have:
       #+begin_src scala
         ${'{e}} = e
         '{${e}} = e
         ${'[T]} = T
         '{$[T]} = T
       #+end_src

**** DONE Types for Quotations
     CLOSED: [2020-03-31 Tue 17:37]
     - The /type signatures/ of /quotes/ and /splices/ can be described using
       _TWO_ _FUNDAMENTAL /types/:_
       + ~Expr[T]~: /abstract syntax trees/ representing /expressions/ of /type/ ~T~

       + ~Type[T]~: /type structures/ representing /type/ ~T~.

     - /Quoting/ takes
       + /expressions/ of /type/ ~T~ to /expressions/ of /type/ ~Expr[T]~
       + /types/ ~T~ to /expressions/ of /type/ ~Type[T]~.

     - /Splicing/ takes
       + expressions of /type/ ~Expr[T]~ to /expressions/ of /type/ ~T~
       + expressions of /type/ ~Type[T]~ to /types/ ~T~.

     - The two types can be defined in package ~scala.quoted~ as follows:
       #+begin_src scala
         package scala.quoted

         sealed abstract calss Expr[+T]
         sealed abstract calss Type[T]
       #+end_src
       Both ~Expr~ and ~Type~ are ~abstract~ and ~sealed~, so _ALL /constructors/
       for these types are PROVIDED BY THE SYSTEM._

     - One way to construct values of type ~Expr[T]~ or ~Type[T]~ is by /quoting/,
       TODO ??? TODO
       the other is by /type-specific lifting operations/ that will be discussed
       later on.

**** DONE The Phase Consistency Principle - TODO RE-READ
     CLOSED: [2020-03-31 Tue 18:08]
     - A fundamental /phase consistency principle (PCP)/ regulates accesses to /free
       variables/ in /quoted/ and /spliced/ code:
       #+begin_quote
       For any /free variable reference/ ~x~,
       the _number_ of /quoted scopes/ and the _number_ of /spliced scopes/
       between the reference to ~x~ and the definition of ~x~ *must be equal*.
       #+end_quote
       + ~this~-reference count as /free variables/.

       + We assume
         * ALL _imports_ are fully expanded
         * ~_root_~ is *NOT* a /free variable/.
         So /references/ to /global definitions/ are allowed everywhere.

     - The /phase consistency principle/ can _be motivated as follows_:
       1. Suppose the result of a program _P_ is some /quoted text/ ~'{ ... x ... }~
          that refers to a /free variable/ ~x~ in _P_. This can be represented only
          by referring to the original variable ~x~.

       2. Hence, the result of the program will need to persist the program state
          itself as one of its parts. We don't want to do this, hence this situation
          should be made illegal.

          Dually, suppose a top-level part of a program is a /spliced text/ ~${
          ... x ... }~ that refers to a /free variable/ ~x~ in _P_. This would
          mean that we refer during construction of _P_ to a value that is
          _available ONLY during execution of P._
          *This is of course impossible and therefore needs to be ruled out.*

       Now, the small-step evaluation of a program will reduce /quotes/ and
       /splices/ in equal measure using the cancellation rules above. But it will
       neither create nor remove /quotes/ or /splices/ individually. So the PCP
       ensures that program elaboration will lead to neither of the two unwanted
       situations described above.

     - In what concerns the range of features it covers, this form of macros (Scala 3
       macro) introduces a principled meta programming framework that is quite
       close to the /MetaML family of languages/.
       + One difference is that MetaML does NOT have an equivalent of the PCP.
           quoted code in MetaML can access variables in its immediately
         enclosing environment, with some restrictions and caveats since such
         accesses involve serialization. _However, this does not constitute a
         fundamental gain in expressiveness._

**** TODO From ~Expr~'s to Functions and Back
     It is possible to convert back and forth any ~Expr[T => R]~ into ~Expr[T] => Expr[R]~!

     - The conversions can be implemented as follows:
       #+begin_src scala
         def to[T, R](f: Expr[T] => Expr[R])(using QuoteContext): Expr[T => R] =
           '{ (x: T) => ${ f('x) } }

         def from[T, R](f: Expr[T => R])(using QuoteContext): Expr[T] => Expr[R] =
           (x: Expr[T]) => '{ $f($x) }
       #+end_src
       This decorator gives ~Expr~ the ~apply~ operation of an /applicative functor/,

     - Example:
       TODO TODO TODO

     - One limitation of ~from~ is that it does NOT \beta{}-reduce when a lambda is called
       immediately, as evidenced in the mode ~{ ((x: Int) => x.toString)(2) }~.
         In some cases we want to remove the lambda from the code, for this we provide
       the method ~Expr.betaReduce~ that turns a tree describing a function into a
       function mapping trees to trees. TODO TODO TODO
       #+begin_src scala
         object Expr {
           // ...
           def betaReduce[...](...)(...): ... = ...
         }
       #+end_src

     - OLD NOTE
       where ~Expr~'s over /function types/ can be applied to ~Expr~ _arguments_.
       The definition of ~AsFunction(f).apply(x)~ is assumed to be functionally
       the same as ~'{($f)($x)}~, however it should *optimize* this call by
       returning the result of /beta-reducing/ ~f(x)~ if ~f~ is a known lambda
       expression.

     - OLD NOTE
       The ~AsFunction~ decorator distributes applications of ~Expr~ over /function
       arrows/:
       #+begin_src scala
         AsFunction(_).apply: Expr[S => T] => (Expr[S] => Expr[T])
       #+end_src
       Its _dual_, let's call it ~reflect~, can be defined as follows:
       #+begin_src scala
         def reflect[T, U](f: Expr[T] => Expr[U]): Expr[T => U] = '{
           (x: T) => ${ f('x) }
         }
       #+end_src

     - OLD NOTE
       Note how the FUNDAMENTAL /phase consistency principle/ works in _two different
       directions_ here for ~f~ and ~x~.
       The reference to ~f~ is legal because it is _quoted, then spliced_,
       whereas the reference to ~x~ is legal because it is _spliced, then quoted_.

**** TODO Lifting Types - TODO =WIERD= TODO
**** TODO Lifting Expressions
     - Consider the following implementation of a staged interpreter that implements
       a compiler through staging.
       #+begin_src scala
         import scala.quoted._

         enum Exp {
           case Num(n: Int)
           case Plus(e1: Exp, e2: Exp)
           case Var(x: String)
           case Let(x: String, e: Exp, in: Exp)
         }
       #+end_src

     - The interpreted language consists of numbers ~Num~, addition ~Plus~, and
       variables ~Var~ which are bound by ~Let~. Here are two sample expressions
       in the language:
       #+begin_src scala
         val exp    = Plus(Plus(Num(2), Var("x")), Num(4))
         val letExp = Let("x", Num(3), exp)
       #+end_src

     - Here's a compiler that maps an expression given in the interpreted language
       to /quoted/ Scala code of type ~Expr[Int]~. The compiler takes an environment
       that maps variable names to Scala ~Expr~'s.
       #+begin_src scala
         import scala.quoted.{given _, _}

         def compile(e: Exp, env: Map[String, Expr[Int]])(using QuoteContext): Expr[Int] = e match {
           case Num(n)          => Expr(n)
           case Plus(e1, e2)    => '{ ${ compile(e1, env) } + ${ compile(e2, env) } }
           case Var(x)          => env(x)
           case Let(x, e, body) => '{ val y = ${ compile(e, env) }; ${ compile(body, env + (x -> 'y)) } }
         }
       #+end_src

     - Running compile(letExp, Map()) would yield the following Scala code:
       #+begin_src scala
         '{ val y = 3; (2 + y) + 4 }
       #+end_src

     - The body of the first clause, ~case Num(n) => n.toExpr~, looks suspicious.
       ~n~ is declared as an ~Int~, yet it is converted to an ~Expr[Int]~ with
       ~toExpr~. Shouldn't ~n~ be /quoted/? In fact this would _NOT_ work since
       replacing ~n~ by ~'n~ in the clause _would NOT be phase correct_.

     - The ~Expr.apply~ method is defined in package ~quoted~:
       #+begin_src scala
         package quoted

         object Expr {
           // ...
           def apply[T: Liftable](x: T)(using QuoteContext): Expr[T] = summon[Liftable[T]].toExpr(x)
           // ...
         }
       #+end_src

     - The extension says that values of types implementing the ~Liftable~ /type
       class/ can be converted ("lifted") to ~Expr~ values using ~toExpr~,
       provided a /delegate import/ of ~scala.quoted._~ is in scope.

     - Dotty comes with /delegate definitions/ of ~Liftable~ for several types
       including ~Boolean~, ~String~, and /ALL primitive number types/.
         For example, ~Int~ values can be converted to ~Expr[Int]~ values by
       wrapping the value in a ~Literal~ /tree node/. This makes use of the
       underlying tree representation in the compiler for efficiency. But the
       ~Liftable~ instances are nevertheless not magic in the sense that they
       could all be defined in a user program without knowing anything about the
       representation of ~Expr~ trees. For instance, here is a possible instance
       of ~Liftable[Boolean]~:
       #+begin_src scala
         given Liftable[Boolean] {
           def toExpr(b: Boolean) = if (b) '{ true } else '{ false }
         }
       #+end_src

     - Once we can lift bits, we can work our way up. For instance, here is a
       possible implementation of ~Liftable[Int]~ that does not use the
       underlying tree machinery:
       #+begin_src scala
         given Liftable[Int] {
           def toExpr(n: Int): Expr[Int] = n match {
             case Int.MinValue    => '{ Int.MinValue }
             case _ if n < 0      => '{ - ${ toExpr(-n) } }
             case 0               => '{ 0 }
             case _ if n % 2 == 0 => '{ ${ toExpr(n / 2) } * 2 }
             case _               => '{ ${ toExpr(n / 2) } * 2 + 1 }
           }
         }
       #+end_src

     - Since Liftable is a type class, its instances can be conditional.
       For example, a List is liftable if its element type is:
       #+begin_src scala
         given [T: Liftable : Type] for Liftable[List[T]] {
           def toExpr(xs: List[T]) = xs match {
             case head :: tail => '{ ${ Expr(head) } :: ${ Expr(tail) } }
             case Nil          => '{ Nil: List[T] }
           }
         }
       #+end_src

     - In the end, Liftable resembles very much a serialization framework.
       Like the latter it can be derived systematically for all collections,
       case classes and enums. Note also that the synthesis of type-tag values
       of type Type[T] is essentially the type-level analogue of lifting.

     - Using /lifting/, we can now give the missing definition of ~showExpr~ in
       the introductory example:
       #+begin_src scala
         def showExpr[T](expr: Expr[T])(using QuoteContext): Expr[String] = {
           val code: String = expr.show
           Expr(code)
         }
       #+end_src
       That is, the ~showExpr~ /method/ _converts_ its ~Expr~ argument to a
       string (~code~), and *lifts* the result back to an ~Expr[String]~ using
       the ~toExpr~ method.

     - Note:
       the ~toExpr~ extension /method/ can be ommited by importing an /implicit
       conversion/ with ~import scala.quoted.autolift._~. The programmer is able
       to declutter slightly the code at the cost of readable phase distinction
       between stages.

**** TODO Lifting Types - TODO =WIERD= TODO *WHY 2 "Lifting Types"*
**** TODO Relationship with ~inline~
**** TODO Scope Extrusion
**** TODO Example Expansion
**** TODO Find implicits within a macro
**** TODO Relationship with Whitebox ~Inline~
     ~Inline~ documents inlining.
     The code below introduces a /whitebox inline method/ that can calculate
     either a value of /type/ ~Int~ or a value of /type/ ~String~.
     #+begin_src scala
       transparent inline def defaultOf(inline str: String) =
         ${ defaultOfImpl('str) }

       def defaultOfImpl(strExpr: Expr[String])(using QuoteContext): Expr[Any] =
         strExpr.unliftOrError match {
           case "int"    => '{1}
           case "string" => '{"a"}
         }

       // in a separate file
       val a: Int    = defaultOf("int")
       val b: String = defaultOf("string")
     #+end_src

**** TODO Defining a macro and using it in a single project
**** TODO Pattern matching on quoted expressions
***** Quoted patterns

**** TODO Recovering precise types using patterns
**** TODO More details

*** TODO Staging
    # *Multi-Stage Programming*
**** API
**** Create a new Dotty project with staging enabled
**** Example

*** TODO TASTy Reflection
    # *TASTy Reflect*
**** API: From quotes and splices to TASTy reflect trees and back
***** Extractors
***** Obtaining and underlying argument
***** Positions
***** Tree Utilities
****** Let

**** More Examples

*** TODO TASTy Inspection
**** Inspecting TASTy files
**** Template project

** TODO OTHER NEW FEATURES
*** TODO Trait Parameters
**** Reference

*** DONE Creator Applications
    CLOSED: [2019-12-28 Sat 17:32]
    - creator applications :: use simple _function call syntax_ to *create* /instances/
      of a /class/, even if there is no ~apply~ /method/ implemented.

    - Example:
      #+begin_src scala
        class StringBuilder(s: String) {
          def this() = this("")
        }

        StringBuilder("abc")  // same as `new StringBuilder("abc")`
        StringBuilder()       // same as `new StringBuilder()`
      #+end_src

    - There was _THREE_ rules for the function call syntax ~f(args)~, and
      a forth rule (fallback rule) for the _function call syntax_ can be added:
      1. if is a /method/ applicable to ~args~, typecheck ~f(args)~ unchanged,

      2. if ~f~ has an ~apply~ /method/ applicable to ~args~ as a member, continue
         with ~f.apply(args)~,

      3. if ~f~ is of the form ~p.m~ and there is an /implicit conversion/ ~c~
         applicable to ~p~ so that ~c(p).m~ is applicable to ~args~, continue
         with ~c(p).m(args)~

      4. if ~f~ is syntactically a /stable identifier/, and ~new f~ where ~f~ is
         interpreted as a /type identifier/ is applicable to ~args~, continue
         with ~new f(args)~.

    - Similarly, the possible interpretations of a /function call with type arguments
      ~f[targs]~ syntax/ are augmented with the following interpretation as a _FINAL
      fallback_:
      + if ~f~ is syntactically a /stable identifier/, and ~new f[targs]~ where ~f~
        is interpreted as a /type identifier/ is _well-typed_, continue with ~new
        f[targs]~.

**** DONE Motivation
     CLOSED: [2019-12-28 Sat 17:18]
     - This doc mentions _TWO_ motivation:
       1. Leave out ~new~ *hides* an implementation detail
       2. makes code more pleasant to *read*

     - =from Jian= I think 1 is objective, and 2 is subjective.

     - Q :: What's the cose of this change?

     - A :: _Add a new rule_ (a fallback rule) to the interpretation of the /function
            call syntax/. =from Jian= All the rules are listed above before this
            "Motivation" section.

     - Q :: Why this cost is valuable?

     - A :: It increase the perceived regularity of the language, since /case classes/
            already provide /function call creation syntax/ (and are often defined for
            this reason alone).

**** DONE Discussion
     CLOSED: [2019-12-28 Sat 17:24]
     An alternative design would auto-generate ~apply~ /methods/ for _non /case
     classes/._
     - =from Jian= From the first glance, this alternative design has one good
       point -- NO need to add new (fallback) rule for the interpretation of
       /function call syntax/.

     - However, this alternative design can *cause numerous problems*:
       + overloading ambiguities TODO ???
       + overriding errors TODO ???
       + shadowing of user-defined ~apply~ /methods/ by more specific auto-generated ones.
         TODO ???

*** TODO Export Clauses
    *An ~export~ clause defines aliases for selected members of an object.*
    - Example:
      #+begin_src scala
        class BitMap
        class InkJet

        class Printer {
          type PrinterType
          def print(bits: BitMap): Unit = ???
          def status: List[String] = ???
        }

        class Scanner {
          def scan(): BitMap = ???
          def status: List[String] = ???
        }

        class Copier {
          private val printUnit = new Printer { type PrinterType = InkJet }
          private val scanUnit = new Scanner

          export scanUnit.scan
          export printUnit.{status => _, _}

          def status: List[String] = printUnit.status ++ scanUnit.status
        }
      #+end_src
      - Here the two ~export~ clauses define the following /export aliases/ in
        class ~Copier~:
        #+begin_src scala
          final def scan(): BitMap            = scanUnit.scan()
          final def print(bits: BitMap): Unit = printUnit.print(bits)
          final type PrinterType              = printUnit.PrinterType
        #+end_src

      - The exported members can be accessed inside ~Copier~ as well as from
        outside:
        #+begin_src scala
          val copier = new Copier
          copier.print(copier.scan())
        #+end_src

      - Syntax (similar to ~import~):
        TODO
        TODO
        TODO
        TODO

**** Motivation
     - It is a standard recommendation to *prefer composition over inheritance*.
       + This is really an application of /the principle of least power/:
         * Composition treats components as blackboxes
           _WHEREAS_
         * inheritance can affect the internal workings of components through overriding

       + Sometimes the close coupling implied by /inheritance/ is the best solution
         for a problem, but hwere this is not necessary the looser coupling of
         composition is better.

     - So far, OO Language including Scala made it much easier to use /inheritance/
       than /composition/, which pushing programmers to a solution that is often
       too powerful as well as complicated (=from Jian= hard to verify in the concept of math).
       + For example, in Scala,
         * /inheritance/: Use ~extends~ clause
         * /composition/: Require a verbose elaboration of a sequence of forwarders. TODO ???

       + ~export~ clauses redress the balance, and
         make /composition relationships/ *as CONCISE and EASY to* express as
         /inheritance relationships/.
         * Actually, ~export~ clauses is MORE FLEXIBLE than ~extends~ clauses --
           members can be _renamed_ or _ommited_.

     - /Export clauses/ also fill a gap opened by the shift from /package objects/
       (DEPRECATED in Scala 3) to /toplevel definitions/.
       + In Scala 2, sometimes /package objects/ is created also with ~extends~ clauses.

       + /Toplevel definitions/ doesn't reside in semantics in a user-defined object,
         so they _can't inherit anyting_. However, ~export~ can be applied in
         toplevel, and make a similar result to the /package object/ _inheritance_ way.

**** Syntax changes
**** Elaboration of Export Clauses
     TODO ???
     TODO ???
     TODO ???
     TODO ???

*** DONE Opaque Type Alias
    CLOSED: [2019-09-13 Fri 02:50]
    /Opaque types aliases/ provide type abstraction without any runtime overhead.

    - Example:
      #+begin_src scala
        object Logarithms {

          opaque type Logarithm = Double

          object Logarithm {
            // These are the ways to lift to the Logarithm type

            def apply(d: Double): Logarithm = math.log(d)

            def safe(d: Double): Option[Logarithm] =
              if (d > 0.0) Some(math.log(d)) else None
          }

          // Extension methods define opaque type aliases' public APIs
          extension LogarithmOps on (x: Logarithm) {
            def toDouble: Double = math.exp(x)
            def + (y: Logarithm): Logarithm = Logarithm(math.exp(x) + math.exp(y))
            def * (y: Logarithm): Logarithm = Logarithm(x + y)
          }
        }
      #+end_src
      + ~Logarithm~ is the same as ~Double~ is *only known in the scope where
        ~Logarithm~ is defined* which in this case is object ~Logarithms~.
        * This in scope knowledge of their equivalence is very important!
            Without this knowledge, type-check will say functions ~apply~, ~safe~,
          ~toDouble~, ~+~, and ~*~ have wrong type signature, there there will
          be no simple way to override it.

      + Outside ~Logarithms~, ~Logarithm~ is treated as a _NEW abstract type_.
        * Legal operations example:
          #+begin_src scala
            import Logarithms.Logarithm

            val l = Logarithm(1.0)
            val l2 = Logarithm(2.0)
            val l3 = l1 * l2
            val l4 = l1 + l2
          #+end_src
          - =IMPORTANT=
            The ~import Predef.{any2stringadd => _}~ is necessary!!!
              Without this import clause, the universal ~+~ in ~Predef~ would
            take precedence over the ~+~ extension method in ~LogarithmOps~.
            + Solution: eliminate ~any2stringadd~ -- this is already in DEPRECATED
                        status.

        * Illegal operations example:
          #+begin_src scala
            val d: Double = l        // error: found: Logarithm, required: Double
            val l2: Logarithm = 1.0  // error: found: Double, required: Logarithm
            l * 2                    // error: found: Int(2), required: Logarithm
            l / l2                   // error: `/` is not a member fo Logarithm
          #+end_src

**** Bounds For Opaque Type Alias
     /Opaque type aliases/ can also come with /bounds/.
     Example:
     #+begin_src scala
       object Access {

         opaque type Permissions = Int
         opaque type PermissionChoice = Int
         opaque type Permission <: Permissions & PermissionChoice = Int

         def (x: Permissions) & (y: Permissions): Permissions = x | y
         def (x: PermissionChoice) | (y: PermissionChoice): PermissionChoice = x | y
         def (granted: Permissions).is(required: Permissions): Boolean = (granted & required) == required
         def (granted: Permissions).isOneOf(required: PermissionChoice): Boolean = (granted & required) != 0

         val NoPermission: Permission = 0
         val Read: Permission = 1
         val Write: Permission = 2
         val ReadWrite: Permissions = Read | Write
         val ReadOrWrite: PermissionChoice = Read | Write
       }
     #+end_src
     - The ~Access~ object defines THREE /opaque type aliases/:
       + ~Permission~,       representing a single permission,
       + ~Permissions~,      representing a conjunction (logical "and") of permissions,
       + ~PermissionChoice~, representing a disjunction (logical "or") of permissions.

     - /Type bound/ of ~Permission~ makes it known outside the ~Access~ object that
       ~Permission~ is a /subtype/ of the other two types. Hence, the following
       usage scenario type-checks:
       #+begin_src scala
         object User {
           import Access._

           case class Item(rights: Permissions)

           val roItem = Item(Read)  // OK, since Permission <: Permissions
           val rwItem = Item(ReadWrite)
           val noItem = Item(NoPermission)

           assert(!roItem.rights.is(ReadWrite))
           assert(roItem.rights.isOneOf(ReadOrWrite))

           assert(rwItem.rights.is(ReadWrite))
           assert(rwItem.rights.isOneOf(ReadOrWrite))

           assert(!noItem.rights.is(ReadWrite))
           assert(!noItem.rights.isOneOf(ReadOrWrite))
         }
       #+end_src
       + On the other hand, ~roItem.rights.isOneOf(ReadWrite)~ can't pass the type check.

**** TODO More details
***** Syntax
***** Type Checking
***** Realtionship to SIP 35

*** TODO Open Classes
    An ~open~ /modifier/ on a class signals that the class _is planned for
    extensions_.
    - Example:
      #+begin_src scala
        // File Writer.scala
        package p

        open class Writer[T] {

          /** Sends to stdout, can be overridden */
          def send(x: T) = println(x)

          /** Sends all arguments using `send` */
          def sendAll(xs: T*) = xs.foreach(send)
        }

        // File EncryptedWriter.scala
        package p

        class EncryptedWriter[T: Encryptable] extends Writer[T] {
          override def send(x: T) = super.send(encrypt(x))
        }
      #+end_src

    - An /open class/ typically comes with
      *some documentation that describes the internal calling patterns between
      methods of the class as well as hooks that can be overridden.*
      + We call this the /extension contract/ of the /class/.
        It is DIFFERENT FROM the /external contract/ between a /class/ and its
        users.

    - /Classes/ that are _not open_ *can still be extended*, *but only if* at least
      one of two alternative conditions is met:
      + TODO
      + TODO

**** Motivation
**** Details
**** Relationship with ~sealed~
**** Migration

*** DONE Parameter Untupling
    CLOSED: [2019-12-31 Tue 00:56]
    For data like ~val xs: List[(Int, Int)]~,
    - In Scala 2.x,
      use _EXPLICIT_ /pattern matching/ (partial function) decomposition:
      #+BEGIN_SRC scala
        xs map {
          case (x, y) => x + y
        }
      #+END_SRC

    - Dotty allows the syntax:
      #+BEGIN_SRC scala
        xs map {
          (x, y) => x + y
        }

        // OR, EQUIVALENTLY:
        xs.map(_ + _)
      #+END_SRC

    - Generally, a /function value/ with *n > 1 parameters* is _converted to_ a
      /pattern-matching closure/ using ~case~ if the expected type is a /unary
      function type/ of the form ~((T_1, ..., T_n)) => U~.

**** Reference

*** TODO Kind Polymorphism
*** TODO Tupled Function
**** Tupled Function
**** Examples

*** DONE ~threadUnsafe~ Annotation
    CLOSED: [2019-12-31 Tue 04:24]
    When the compiler see a ~@threadUnsafe lazy val~, it can pick a faster
    mechanism to do the initialization.

    - =from Jian= TODO TODO TODO
      Does this mean before introducing the ~threadUnsafe~ annotation, we only
      have one mechanism that initialize all ~lazy val~ in a /thread safe/
      way???

**** Examples
     #+begin_src scala
       import scala.annotation.threadUnsafe

       class ThreadUnsafeExample {
         @threadUnsafe lazy val x: Int = 1
       }
     #+end_src

*** DONE New Control Syntax
    CLOSED: [2019-12-28 Sat 17:53]
    #+begin_src scala
      if x < 0 then
        "negative"
      else if x == 0
        "zero"
      else
        "positive"

      if x < 0 then -x else x

      while x >= 0 do x = f(x)

      for x <- xs if x > 0
      yield x * x

      for
        x <- xs
        y <- ys
      do
        println(x + y)
    #+end_src
    - The rules in details:
      TODO
      + Two choices for new ~if~ syntax:
        * with a ~then~ that FOLLOWS the ~if~-condition
        * with proper INDENTATION

      + ~while~-loop with ~do~ following the ~while~-condition
        =from Jian=
        Remember:
        ~do ... while~ syntax is removed from Scala 3.
        In Scala 3, ~do~ will only show up in the _new control syntax_.

      + For the enumerators of ~for~-expression,
        * /comprehensions/ still use ~yield~
        * /side effect loops/ use ~do~

**** Rewrites
     The Dotty compiler _can rewrite_ source code bidirectionally
     - old to new: option =-rewrite -new-syntax=
     - new to old: option =-rewrite -old-syntax=

*** TODO Optional Braces
    *As an /experimental feature/,*
    Scala 3 _enforces some rules on indentation_ and _allows some occurrences of
    braces {...} to be optional_.
    1. Some badly indented programs are ruled out, which means they are flagged
       with warnings.

    2. Some occurrences of braces ~{...}~ are made optional.
       Generally, the rule is that adding a pair of optional braces will NOT
       change the meaning of a well-indented program.

**** DONE Indentation Rules
     CLOSED: [2019-12-29 Sun 03:37]
     - The compiler enforces *TWO* rules for well-indented programs, _flagging
       violations as warnings_. =from Jian= WHY NOT Error???
       1. In a brace-delimited region, no statement is allowed to start to the left
          of the first statement after the opening brace that starts a new line.
          This rule is helpful for finding missing closing braces. It prevents
          errors like:
          #+begin_src scala
            if (x < 0) {
              println(1)
              println(2)

              println("done")  // error: indented too far to the left
          #+end_src

       2. If significant indentation is turned off (i.e. under Scala-2 mode or
          under ~-noindent~) and we are at the start of an indented sub-part of an
          expression, and the indented part ends in a newline, the next statement
          must start at an indentation width less than the sub-part. This prevents
          errors where an opening brace was forgotten, as in
          #+begin_src scala
            if (x < 0)
              println(1)
            println(2)   // error: missing `{`
          #+end_src

     - These rules still leave a lot of leeway how programs should be indented.
       For instance, they do *NOT impose* any restrictions on
       + indentation within expressions,
       + all statements of an indentation block line up exactly. TODO =???=
         =???= =???= =???=

     - The rules are _generally helpful in pinpointing_ the root cause of errors
       related to _missing opening or closing braces_.

**** TODO Optinal Braces
**** TODO Optinal Braces Around Template Bodies
**** DONE Spaces vs Tabs
     CLOSED: [2019-12-29 Sun 03:29]
     - _Mix SPACES and TABS is legal._
       However, there is no rule defined about how many SPACES equals to a TAB, or
       vice versa. This means
       + "2 tabs, fllowed by 4 spaces" is strictly less than "2 tabs, followed by
         5 spaces",

       + BUT "2 tabs, followed by 4 spaces" is *incomparable*
         * to "6 tabs"
           or
         * to "4 spaces, followed by 2 tabs".

     - *CAUTION*:
       NOT all the legal ways are recommended!!!
       *Do NOT MIX Spaces and Tabs!!!*

**** TODO Indentation and Braces
**** DONE Special Treatment of Case Clauses - TODO
     CLOSED: [2019-12-29 Sun 03:34]
     - NOTE NOTE NOTE
       Rules for ~match~ and ~catch~

     - Legal form (the ~println~ in example do not belong to ~match~ block)
       + Next leval indentation:
         #+begin_src scala
           x match
             case 1 => print("I")
             case 2 => print("II")
             case 3 => print("III")
             case 4 => print("IV")
             case 5 => print("V")

           println(".")
         #+end_src

       + Same level indentation:
         #+begin_src scala
           x match
           case 1 => print("I")
           case 2 => print("II")
           case 3 => print("III")
           case 4 => print("IV")
           case 5 => print("V")

           println(".")
         #+end_src

**** TODO The End Marker
***** TODO When to Use End Markers
***** TODO Syntax

**** TODO Example
**** TODO Settings and Rewrites
**** TODO Variant: Indentation Marker ~:~
     NOT STABLE -- Learn when this feature is stable!!!

*** TODO Explicit Nulls
    Explicit nulls is an /opt-in feature/ that _modifies the Scala type system_,
    which *makes /reference types/ (anything that extends ~AnyRef~) non-nullable.*

    - opt-in feature :: A feature need to enabled via a flag.
      + For this /explicit nulls/ feature, the flag is ~-Yexplicit-nulls~.

    - After introducing this feature, some old style code will no longer typecheck:
      #+begin_src scala
        val x: String = null  // error: found `Null`, but required `String`
      #+end_src

      Instead, if consider the code above is a piece of Scala 2 code which can
      typecheck, translate it into Scala 3 form:
      #+begin_src scala
        val x: String | Null = null
      #+end_src

**** DONE New Type Hierarchy
     CLOSED: [2019-12-31 Tue 04:05]
     - NEW - Without /explicit nulls/:
       ~Null~ is the subtype of all ~AnyRef~ subtypes.
       The only subtype of ~Null~ is the /bottom type/ ~Noting~.

     - OLD - With /explicit nulls/:
       ~Null~ is a subtype of ~Any~.
       Its only subtype doesn't change, still ~Noting~.

     - Of course, the /NEW type hierarchy/ descried above is the one for typechecker
       -- before /type erasure/.
         After /type erasure/, ~Null~, as JVM enforced, remains a /subtype/ of
       all /reference types/

**** DONE Unsoundness
     CLOSED: [2020-03-21 Sat 02:26]
     The new type system is unsound with respect to ~null~.
     Enforcing /sound initialization/, which is can be done, is a non-goal of
     this proposal.

     - The /unsoundness/ happens because uninitialized fields in a class start out
       as ~null~:
       #+begin_src scala
         // -Yexplicit-nulls
         class C with
           val f: String = foo(f)
           def foo(f2: String): String = f2

         val c = new C
         // c.f == "field is null"
       #+end_src

**** DONE Equality
     CLOSED: [2019-12-31 Tue 02:43]
     - NOT Allowed:
       Compare a value of ~AnyRef~ /subtypes/ with ~null~ is not allowed!!!
       The related operators are ~==~, ~!=~, ~eq~, and ~ne~.

     - ~null~ can _only_ be compared with values of type
       + ~Null~
       + nullable union ~(T | Null)~
       + ~Any~ type.

     - For some reason, if we really want to compare ~null~ with non-null values,
       we can use /cast/. For example,
       #+begin_src scala
         val x: String = ???
         val y: String | Null = ???

         x == null        // error: Values of types String and Null cannot be compared with == or !=
         x eq null        // error
         "hello" == null  // erro

         y == null  // ok
         y == x     // ok

         (x: String | Null) == null  // ok
         (x: Any) == null            // ok
       #+end_src

**** DONE Working with ~Null~
     CLOSED: [2019-12-31 Tue 04:01]
     To make working with nullable values easier, we *propose* adding a few
     utilities to the standard library. So far, we have found the following
     useful:
     - An extension method ~.nn~ to "cast away" nullability
       #+begin_src scala
         def[T] (x: T|Null) nn: x.type & T =
           if (x == null) throw new NullPointerException("tried to cast away nullability, but value is null")
           else           x.asInstanceOf[x.type & T]
       #+end_src
       This means that given ~x: String|Null~, ~x.nn~ has type ~String~, so we
       can call all the usual methods on it. Of course, ~x.nn~ will _throw a
       NPE_ if ~x~ is ~null~.
         *Don't use ~.nn~ on /mutable variables/ DIRECTLY*, which may introduce
       unknown value into the type. TODO TODO TODO ???

**** TODO Java Interop
***** ~UncheckedNull~

**** TODO Flow Typing
***** Logical Operators
***** Inside Conditions
***** Match Case
***** Mutable Variable
***** Unsupported Idioms

**** TODO Binary Compatibility

*** TODO Safe Initialization
    Dotty implements experimental safe initialization check, which can be
    enabled by the compiler option ~-Ycheck-init~.

**** A Quick Glance
***** Parent-Child Interaction
***** Inner-Outer Interaction
***** Functions

**** Design Goals
**** Principles and Rules
**** Modularity
**** Theory
**** Back Doors
**** Caveats
**** References

** OTHER CHANGED FEATURES
*** TODO Numeric Literals
**** Meaning of Numeric Literals
**** The ~FromDigits~ Class
**** Error Handling
**** Example
**** Compile-Time Errors

*** DONE Structural Types
    CLOSED: [2020-01-18 Sat 14:23]
    # *Programmatic Structural Types*
    - Some usecases are more awkward in statically typed languages than in
      dynamically typed languages

    - Example: modelling database access
      1. With dynamically typed languages, it's quite natural to _model a /row/ as
         a /record/ or /object/_, and to select entries with simple dot notation
         (e.g. ~row.columnName~).

      2. Achieving the same experience in /statically typed language/ requires
         + defining a class for every possible row arising from database manipulation
           (including rows arising from joins and projections)
         + setting up a scheme to map between a row and the class representing it.

      3. This requires a large amount of boilerplate, which leads developers
         to trade the advantages of static typing for simpler schemes where
         colum names are represented as strings and passed to other operators
         (e.g. ~row.select("columnName")~). _This approach is unatural in both
         sides_
         + forgoes the advantages of static typing,
         + is still not as natural as the dynamically typed version.

    - Structural types help in situations where we would like to support simple
      dot notation in dynamic contexts without losing the advantages of static
      typing.
        They allow developers to use dot notation and configure how fields and
      methods should be resolved.

**** Example
     #+begin_src scala
       object StructuralTypeExample {
         case class Record(elems: (String, Any)*) extends Selectable {
           def selectDynamic(name: String): Any = elems.find(_._1 == name).get._2
         }

         type Person = Record {
           val name: String
           val age: Int
         }

         def main(args: Array[String]): Unit = {
           val person = Record("name" -> "Emma", "age" -> 42).asInstanceOf[Person]
           println(s"${person.name} is ${person.age} years old.")
           // Prints: Emma is 42 years old.
         }
       }
     #+end_src

**** Extensibility
     New instances of ~Selectable~ can be defined to *support means of access*
     _othr than_ /Java reflection/, which would enable usages such as the
     database access example given at the beginning of this document.

**** TODO Relation with ~scala.Dynamic~
     TODO =from Jian= I need to learn more about ~scala.Dynamic~

*** DONE Operators
    CLOSED: [2020-01-18 Sat 16:07]
    *Rules for Operators*
**** DONE The ~@alpha~ Annotation
     CLOSED: [2020-01-18 Sat 14:52]
     - ~@alpha~ annotation :: it is applied on a /method definition/ defines an
       _alternate name_ for the implementation of that method.

     - Example:
       #+begin_src scala
         object VecOps {
           @alpha("append") def (xs: Vec[T]) ++= [T] (ys: Vec[T]): Vec[T] = // ...
         }
       #+end_src
       + The ~++=~ operation is implemented (in bytecode or native code) under
         the name ~append~.

     - The /implementation name/
       + affects the code that is generated
       + is the name under which code _from OTHER languages_ can call the method.
         *ONLY from OTHER languages! You can't use the name in Scala.*
         For instance, ~++=~ could be invoked from Java like this:
         #+begin_src java
           VecOps.append(vec1, vec2)
         #+end_src

     - An ~@alpha~ /annotation/ will be *MANDATORY*
       _if the /method name/ is symbolic_!!!
       + Symbolic name methods without ~@alpha~ annotation are *DEPRECATED*.

***** Motivation
      The ~@alpha~ annotation serves a dual purpose:
      + It helps *interoperability* between Scala and other languages.
      + It serves _as a documentation tool_ by providing an alternative regular
        name as an alias of a symbolic operator.

***** Details
      1. Syntax:
         ~@scala.annotation.alpha(externalName)~.
         ~externalName~ is a string.

      2. An ~@alpha~ annotation can be given for all kinds of definitions.
         _NOT ONLY for symbolic method._

      3. ~externalName~ must be a legal name on the host platform.

      4. Lack of an ~@alpha~ annotation will raise a _deprecation warning_.

      5. Definitions with names in backticks that are not legal host platform
         names should have an ~@alpha~ annotation. Lack of such an annotation
         will raise a deprecation warning.
         =from Jian= TODO EXAMPLE???

      6. ~@alpha~ annotations must agree:
         *There must be a one-to-one relationship between external and internal
         names*

**** DONE The ~@infix~ Annotation
     CLOSED: [2020-01-18 Sat 15:23]
     - ~@infix~ annotation :: it is applied on a /method definition/ allows using
       the method as an _infix operation_.

     - Example:
       #+begin_src scala
         trait MultiSet[T] {
           @infix
           def union(other: MultiSet[T]): MultiSet[T]

           def difference(other: MultiSet[T]): MultiSet[T]

           @alpha("intersection")
           def *(other: MultiSet[T]): MultiSet[T]
         }

         val s1, s2: MultiSet[Int]

         s1 union s2   // OK
         s1.union(s2)  // also OK

         s1.difference(s2)   // OK
         s1 `difference` s2  // OK
         s1 difference s2    // gives a deprecation warning

         s1 * s2   // OK
         s1.*(s2)  // also OK, but unusual
       #+end_src
       + *Infix operations involving alphanumeric operators are deprecated*,
         unless one of the following conditions holds:
         * the operator definition carries an ~@infix~ annotation, or
         * the operator was compiled with Scala 2, or
         * the operator is followed by an opening brace. TODO ??? TODO

     - alphanumeric operator :: an operator *consisting ENTIRELY* of
       + letters
       + digits
       + ~$~
       + ~_~
       + any unicode character for which ~java.lang.Character.isIdentifierPart(c)~
         returns ~true~.

     - /Infix operations/ involving /symbolic operators/ are *ALWAYS* allowed, so
       ~@infix~ is redundant for methods with _symbolic names_.

     - The ~@infix~ annotation can also _be given to a /type/:_
       #+begin_src scala
         @infix type or[X, Y]
         val x: String or Int
       #+end_src

***** Motivation
      The purpose of the @infix annotation is to achieve consistency across a
      code base in how a method or type is applied. The idea is that the author
      of a method decides whether that method should be applied as an infix
      operator or in a regular application. Use sites then implement that
      decision consistently.

***** Details
      1. ~@scala.annotation.infix~

      2. ~@infix~ annotations must agree when overriding.

      3. The first non-receiver parameter list of an ~@infix~ method must define
         exactly one parameter. For example,
         #+begin_src scala
           @infix def op(x: S): R                  // OK
           @infix def op[T](x: T)(y: S): R         // OK
           @infix def op[T](x: T, y: S): R         // error: two parameters

           @infix def (x: A) op (y: B): R          // OK
           @infix def (x: A) op (y1: B, y2: B): R  // error: two parameters
         #+end_src

      4. ~@infix~ annotations can also be given to /type/, /trait/ or /class/
         definitions that have exactly _two type parameters_. An /infix type/
         like
         #+begin_src scala
           @infix type op[X, Y]
         #+end_src
         can be applied using infix syntax, i.e. ~A op B~

      5. To smooth migration to Scala 3.0, alphanumeric operations will only be
         deprecated from Scala 3.1 onwards, or if the ~-strict~ option is given
         in Dotty/Scala 3.

**** DONE Syntax Change
     CLOSED: [2020-01-18 Sat 16:07]
     Infix operators can now appear at the start of lines in a multi-line expression.
     Thanks to the change of semicolon inference.

     - Illustrate by examples:
       + The leading infix operator should be followed by at least one space
         character (=from Jian= and then another operand).
         #+begin_src scala
           freezing
           | boiling
         #+end_src

       + No space, no infix operation
         #+begin_src scala
           freezing
           !boiling
         #+end_src

       + No following legal operand
         #+begin_src scala
           println("hello")
           ???
           ??? match { case 0 => 1 }
         #+end_src
         * The second line ~???~ doesn't have a following operand.
         * The thrid line ~???~ doesn't have a legal following operand -- ~match~
           is not a token that can start an expression.

*** TODO Wildcard Types
    *Wildcard Arguments in Types*
**** Motivation
**** Migration Strategy

*** Type Checking
    *Type Checking*
    - [//]:# todo: fill in

*** Type Inference
    *Changes in Type Inference*
    - [//]:# todo: fill in

*** Implicit Resolution
    # *Changes in Implicit Resolution*

*** Implicit Conversions
**** Examples

*** Overload Resolution
    # Changes in Overload Resolution

**** Looking Beyond the First Argument List
**** Parameter Types of Function Values

*** TODO Match Expressions
**** Syntax

*** Vararg Patterns
**** Compatibility considerations

*** Pattern Bindings
**** Bindings in Pattern Definitions
**** Pattern Bindings in For Expressions
**** Syntax Changes
**** Migration

*** Pattern Matching
    # Option-less pattern matching

**** Extractors
***** Fixed-Arity Extractors
***** Variadic Extractors

**** Boolean Match
**** Product Match
**** Single Match
**** Name-based Match
**** Sequence Match
**** Product-Sequence Match

*** Eta Expansion
    # Automatic Eta Expansion
**** Automatic eta-expansion and nullary methods

*** Compiler Plugins
    # Changes in Compiler Plugins

**** Using Compiler Plugins
**** Writing a Standard Compiler Plugin
**** Writing a Research Compiler Plugin

*** Lazy Vals initialization
**** Motivation
**** Implementation
**** Note on recursive lazy vals
**** Reference
     - SIP-20

*** Main Functions

** DROPPED FEATURES
*** DelayedInit
    # *Dropped: DelayedInit*

*** Macros
    # *Dropped: Scala 2 Macros*

*** Existential Types
    # *Dropped: Existential Types*

*** Type Projection
    # *Dropped: General Type Projection*

*** Do-While
    # *Dropped: Do-While*

*** Procedure Syntax
    # *Dropped: Procedure Syntax*

*** Package Objects
    # *Dropped: Package Objects*

*** Early Initializers
    # *Dropped: Early Initializers*

*** Class Shadowing
    # *Dropped: Class Shadowing*

*** TODO Limit 22
    # *Dropped: Class Shadowing*

*** XML Literals
    # *Dropped: XML Literals*

*** TODO Symbol Literals
    # *Dropped: Symbol Literals*

*** Auto-Application
    # *Dropped: Auto-Application*
**** Migrating code
**** Reference

*** Weak Conformance
    # *Dropped: Weak Conformance*

*** Nonlocal Returns
    # *Deprecated: Nonlocal Returns*

*** ~[this]~ Quanlifier
    # *Dropped: ~private[this]~ and ~protected[this]~*

* CONTRIBUTING
** Contribute Knowledge
*** Contribute Internals-related Knowledge

** Getting Started
*** Requirements
*** Compiling and Running
*** Starting a REPL
*** Generating Documentation

** Workflow
*** Compiling files with dotc
*** Inspecting Trees with Type Stealer
*** Pretty-printing
*** SBT Commands Cheat Sheet

** Testing
*** Unit tests
**** Testing with checkfiles

*** Integration tests
**** Bootstrapped-only tests
**** From TASTy tests

** Debugging
*** Setting up the playground
*** Show for human readable output
*** How to disable color
*** Reporting as a non-intrusive println
*** Printing out trees after phases
*** Printing out stack traces of compile time errors
*** Configuring the printer output
*** Figuring out an object creation site
**** Via ID
**** Via tracer

*** Built-in Logging Architecture
**** Printers
**** Tracing
**** Reporter

** IDEs and Tools
*** Mill
*** Scalafix

** Procedures
*** Release Model
**** Model
**** Example
***** At the Dotty Repo
***** At the CI
****** Canceling CI builds

***** Documentation
****** Release Procedure Checklist
****** GitHub Releases and Blog Post

***** Ecosystem

**** Procedure in Bash Scripts

*** Modifying the Test framework
    *Test Vulpix Framework*

* INTERNALS
** Backend
*** Data Flow
*** Architecture
**** (a) The queue subsystem
**** (b) Bytecode-level types, ~BType~
**** (c) Utilities offering a more "high-level" API to bytecode emission
**** (d) Mapping between type-checker types and ~BType~'s
**** (e) More "high-level" utilities for bytecode emission
**** (f) Building an ASM ~ClassNode~ given an AST ~TypeDef~

** Classpaths
** Core Data Structrues
*** Symbols and SymDenotations
*** Why is this important?
*** Are We Done Yet?
*** What Are the Next Steps?

** Contexts
*** Contexts in the typer
*** In other phases
*** Using contexts

** Dotc vs Scalac
   # Differences between Dotc and Scalac
*** Denotation
**** Denotation vs. SymDenotation
**** Implicit Conversion

*** Symbol
*** Flags
*** Tree
*** Type

** Higher-Kinded Types
   *This page is out of date and preserved for posterity. Please see
   Implementing Higher-Kinded Types in Dotty for a more up to date version*

*** Higher-Kinded Types in Dotty V2
**** The duality
**** Named type parameters
**** Wildcards
**** Type parameters in the encodings
**** Partial applications
**** Modelling polymorphic type declarations
**** Modelling polymorphic type aliases: simple case
**** Modelling polymorphic type aliases: general case
**** Modelling higher-kinded types
**** Full example
**** Status of ~#~

** Overall Structure
   # Dotty Overall Structure
*** Package Structure
*** Contexts
*** Compiler Phases

** Periods
   # Dotc's concept of time*

** Syntax
   # Scala Syntax Summary
*** Lexical Syntax
*** Keywords
**** Regular keywords
**** Soft keywords

*** Context-free Syntax
**** Literals and Paths
**** Types
**** Expressions
**** Type and Value Parameters
**** Bindings and Imports
**** Declarations and Definitions

** Type System
*** Class diagram
*** Proxy types and ground types
*** Representations of types
**** Representation of methods

*** Subtyping checks
**** Type rebasing

*** Type caching
    # TODO

*** Type inference via constraint solving
    # TODO

** Dotty Internals 1: Trees & Symbols (Meeting Notes)
*** Entry point
*** Phases
*** Trees
**** Untyped trees
**** Typed trees
**** Notes on some tree types
***** ThisTree

**** Creating trees
**** Meaning of trees
**** Errors
**** Assignment

*** Symbols
**** ClassSymbol
**** SymDenotation

** Debug Macros
*** position not set
*** unresolved symbols in pickling

* RESOURCES
*** Talks
**** Talks on Dotty
**** Deep Dive with Dotty
     :PROPERTIES:
     :ID:       b5b2ba1a-6e8d-4f0c-a3c4-14f0e17ee56a
     :END:
