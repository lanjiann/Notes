#+TITLE: Dotty Documentation
#+VERSION: 0.26.0-bin-20200710-a162b7b-NIGHTLY
#+AUTHORS: Dotty Contributors
#+STARTUP: entitiespretty

* BLOG
* DONE USAGE
  CLOSED: [2019-11-04 Mon 16:17]
** Getting Started
   # *Getting Started: Users*
*** Trying out Dotty
**** In your web browser
     The online Scala playground [[https://scastie.scala-lang.org][Scastie]] -- a project of _Scala Center_.

**** sbt
     Use sbt (1.1.4+)
     - Dotty project:
       ~sbt new lampepfl/dotty.g8~

     - Dotty project that _cross compiles_ with Scala 2:
       ~sbt new lampepfl/dotty-cross.g8~

**** IDE support
     Check the *IDE support for Dotty* section.

**** Standalone installation
     - Releases include _THREE_ executables:
       #+begin_src text
         .
         |\under_ bin
             |\under_ dotc
             |\under_ dotd
             |\under_ dotr
       #+end_src
       + dotc is the Dotty compiler
       + dotd is the Dotty Documentation tool
       + dotc is the Dotty REPL

** sbt-projects
   # *Using Dotty with sbt*
   A redirect link to the sbt subsection in the -Getting Started- section.

** IDE support for Dotty
*** Prerequisites
    Follow the instructions for the dotty-example-project in github under lampepfl.

*** Usage
    Install _Visual Studio Code_, and use command ~sbt launchIDE~.

*** TODO Status
**** Fully supported features
**** Partial working features
**** Unimplemented features
**** Current limitations, to be fixed

*** Feedback

** TODO Worksheet mode in Dotty IDE
*** How to use the worksheets
*** TODO Implementation details
    More details in [[https://dotty.epfl.ch/docs/usage/worksheet-mode-implementation-details.html][Worksheet mode - Implementation details]]

** TODO Language Versions
** cbt-projects
   # *Using Dotty with cbt*

** DONE Dottydoc
   CLOSED: [2020-02-15 Sat 02:33]
*** Using existing Templates and Layouts
*** Blog
*** Includes
*** Sidebar
*** Dottydoc Specific Tags and Behavior
**** Linking to API
**** Rendering Docstrings
**** Other extensions

*** Default Layouts
**** =main.html=
***** Variables

**** =sidebar.html=
***** Variables

**** =doc-page.html=
**** =api-page.html=
**** =blog-page.html=

*** Default Includes

* TODO REFERENCE
** Overview
*** Goals
*** Essential Foundations
*** Simplifications
*** Restrictions
*** Dropped Constructs
*** Changes
*** New Constructs
*** Metaprogramming
*** See Also

** DONE NEW TYPES
   CLOSED: [2020-03-08 Sun 21:34]
*** DONE Intersection types
    CLOSED: [2019-11-10 Sun 17:47]
    The ~&~ operator creates an /intersection type/.

**** Type Checking
     The type ~S & T~ represents values that are of the type ~S~ and ~T~ _at the
     same time_.

     - Example:
       #+begin_src scala
         trait Resettable {
           def reset(): Unit
         }

         trait Growable[T] {
           def add(x: T): this.type
         }

         def f(x: Resettable & Growable[String]) = {
           x.reset()
           x.add("first")
         }
       #+end_src

     - If a /member/ appears in both ~A~ and ~B~, its type in ~A & B~ is the
       /intersection of its type/ in ~A~ and its type in ~B~.
         For instance, assume the definitions:
       #+begin_src scala
         trait A {
           def children: List[A]
         }

         trait B {
           def children: List[B]
         }

         val x: A & B = new C
         val ys: List[A & B] = x.children
       #+end_src
       ~ys~ is of type ~List[A] & List[B]~, _which can be FURTHER SIMPLIFIED
       to_ ~List[A & B]~ _because_ ~List~ is /convariant/.

     - Q :: (One might wonder)
            How the compiler could come up with a definition for ~children~ of
            type ~List[A & B]~ since all its is given are ~children~ definitions
            of type ~List[A]~ and ~List[B]~.

     - A :: The answer is it *does not need to*. TODO ??? ??? ??? TODO
              ~A & B~ is just a type that represents a set of requirements for
            values of the type.
              At the point where a value is constructed, one must make sure that
            all inherited members are correctly defined. So if one _defines a class
             ~C~ that inherits ~A~ and ~B~,_ one needs to give at that point a
            definition of a ~children~ method with the required type.
       #+begin_src scala
         class C extends A with B {
           def children: List[A & B] = ???
         }
       #+end_src

**** More Details
***** Syntax
      Syntactically, an /intersection type/ ~S & T~ is similar to an /infix
      type/, where the _infix operator_ is ~&~.
      - ~&~ is treated as a /soft keyword/.
        + it is a _NORMAL identifier_ with the usual precedence.

        + *BUT*
          a type of the form ~A & B~
          _is *ALWAYS* recognized as_ an /intersection type/,
          _WITHOUT_ trying to resolve ~&~.

      - Syntax:
        #+begin_src text
          Type      ::=  ...| InfixType
          InfixType ::=  RefinedType {id [nl] RefinedType}
        #+end_src

***** Subtyping Rules
      - Subtyping rules
        TODO

      - It is can be proved that ~&~ is *commutative*.

      - Derived:
        Given type constructor ~C~,
        + If ~C~ is /covariant/, ~C[A] & C[B] ~> C[A & B]~
        + If ~C~ is /contravariant/, ~C[A] & C[B] ~> C[A | B]~

***** TODO Erasure
      TODO TODO TODO

***** Relationship with Compound Type (~with~)
      - =from Jian=
        ~A & B~ is different from the ~A with B~ in Scala 2.
        The latter is not commutative!

      - /Intersection types/ ~A & B~ *replace* /compound types/ ~A with B~ in
        Scala 2.
          For the moment, the syntax ~A with B~ is _still allowed_ and
        *interpreted as* ~A & B~, _but its usage as a type (as opposed to in a
        ~new~ or ~extends~ clause) will be *deprecated* and *removed* in the future._

*** DONE Union types
    CLOSED: [2019-07-01 Mon 15:49]
    A ~A | B~ value can be _any value_ of type ~A~ _and_ also _any value_ of
    type ~B~.

    - Example:
      #+begin_src scala
        final case class UserName(name: String)
        final case class Password(hash: Hash)

        def help(id: UserName | Password) = {
          val user = id match {
            case UserName(name) => lookupName(name)
            case Password(hash) => lookupPassword(hash)
          }
          // ...
        }
      #+end_src

    - /Union types/ are _DUALS of /intersection types/.

    - ~|~ is *commutative*: ~A | B~ is the _SAME type_ as ~B | A~.

    - The compiler will assign a /union type/ to an expression *only if such a
      type is _EXPLICITLY given_.*
      #+begin_src scala
        val password = Password(123)
        // val password: Password = Password(123)

        val name = UserName("Eve")
        // val name: UserName = UserName(Eve)

        if (true) name else password
        // val res2: Object & Product = UserName(Eve)

        val either: Password | UserName = if (true) name else password
          // val res2: Password | UserName = UserName(Eve)
      #+end_src
      + ~Object & Product~ is a /supertype/ of ~UserName~ and ~Password~,
        BUT NOT the /least supertype/ ~Password | UserName~
        * =from Jian= In the document, there is is a typo (not wrong, but not very
          meaningful): _Object & Product is a supertype of UserName and ~Product~._
          TODO Create a PR to correct this!

**** TODO More Details
***** Syntax
      Syntactically, /union types/ follow the same rules as /intersection types/,
      BUT have a _LOWER precedence_.

****** Intersection with pattern matching syntax - =IMPORTANT=
       ~|~ is also used in /pattern matching/ to _SEPARATE_ /pattern alternatives/ and
       *has _LOWER PRECEDENCE than_ ~:~ as used in /typed patterns/,* this means that:
       #+begin_src scala
         case _: A | B => ...

         // is still equivalent to:
         case (_: A) | B => ...

         // and NOT to:
         case _: (A | B) => ...
       #+end_src

***** Subtyping Rules
      - ~A~ is always a subtype of ~A | B~ for all ~A~, ~B~.

      - If ~A <: C~ and ~B <: C~ then ~A | B <: C~.

      - Like ~&~, ~|~ is /commutative/ and /associative/:
        #+begin_src text
          A | B       =:= B | A
          A | (B | C) =:= (A | B) | C
        #+end_src

      - ~&~ _is distributive over ~|~:_
        #+begin_src text
          A & (B | C) =:= A & B | A & C
        #+end_src

      - From these rules it follows that: TODO TODO TODO
        *the /least upper bound (lub)/ of a set of type is the union of these
        types.*

        + This *replaces* the definition of /least upper bound/ in the Scala 2
          specification. TODO

***** TODO Motivation - TODO NOTE, TODO Re-READ
***** TODO Join of a union type - TODO ???
****** Example

***** TODO Type inference
****** Example

***** TODO Members
****** Example

***** Exhaustivity checking
***** TODO Erasure

*** DONE Type lambdas
    CLOSED: [2019-07-01 Mon 15:55]
    A /type lambda/ lets one express a /higher-kinded type/ directly, *WITHOUT*
    a /type definition/.

    - =from Jian=
      Scala 2 can do this with /type definition/ and /type projection/.

    - Example:
      ~[+X, Y] =>> Map[Y, X]~

    - /Type parameters/ of /type lambdas/ can have /variances/ and /bounds/.

    - A /parameterized type definition or declaration/ such as ~type T[X] = (X, X)~
      is a shorthand for a PLAIN /type definition/ with a /type lambda/ as its RHS:
      ~type T = [X] =>> (X, X)~

    - TODO
      _More details_ link

*** DONE Match types - TODO _mechanism_
    CLOSED: [2020-03-08 Sun 21:34]
    - A /match type/ reduces to one of a number of right hand sides, depending on
      a /scrutinee type/. Example:
      #+begin_src scala
        type Elem[X] = X match {
          case String      => Char
          case Array[t]    => t
          case Iterable[t] => t
        }
      #+end_src
      + An ~Elem~ with /CONCRETE type parameter/ ~X~ can be reduced _as_ (NOT legal
        code you want to write out explicitly):
        #+begin_src scala
          Elem[String]      =:= Char
          Elem[Array[Int]]  =:= Int
          Elem[List[Float]] =:= Float
          Elem[Nil.type]    =:= Nothing
        #+end_src
        Here ~=:=~ is understood to mean that left and right hand sides are
        *mutually subtypes* of each other.

    - Syntax in general: ~S match { P1 => T1 .... Pn => Tn }~, where
      + ~S~, ~T1~, ..., ~Tn~ are types.
      + ~P1~, ..., ~Pn~ are patterns.
        * /Type variables/ in patterns start as usual with a lower case letter.

    - Match types can form part of *RECURSIVE TYPE definitions*. Example:
      #+begin_src scala
        type LeafElem[X] = X match {
          case String      => Char
          case Array[t]    => LeafElem[t]
          case Iterable[t] => LeafElem[t]
          case AnyVal      => X
        }
      #+end_src

    - _Recursive match type definitions_ can also be given an /upper bound/, like this:
      #+begin_src scala
        type Concat[+Xs <: Tuple, +Ys <: Tuple] <: Tuple = Xs match {
          case Unit    => Ys
          case x *: xs => x *: Concat[xs, Ys]
        }
      #+end_src
      + In this definition, every instance of ~Concat[A, B]~, whether reducible
        or not, is known to be a /subtype/ of ~Tuple~.

      + This is necessary to _make the recursive invocation ~x *: Concat[xs, Ys]~
        type check_, since ~*:~ demands a ~Tuple~ as its right operand.

**** DONE Representation of Match Types
     CLOSED: [2020-03-08 Sun 21:32]
     # =from Jian= Internal Representation of Match Types
     #+begin_src scala
       S match {
         case P1 => T1
         case P2 => T2
         // ...
         case Pn => Tn
       }
     #+end_src
     - It's _internal representation_ (=from Jian= Tasty???) is
       ~Match(S, C1, ..., Cn) <: B~
       + ~Ci~ is of the form ~[Xs] => P => T~
         * ~[Xs]~
           a /type parameter clause/ of the /variables bound/ in pattern ~Pi~.
           _It can be omitted if there is *NO* /bound/._

         * Each case (~Pi => Ti~) is either:
           - a /unary function type/ like ~String => Char~
             OR
           - a /type lambda over a unary function type/ like ~Array[t] => LeafElem[t]~.

         * ~B~ is the declared /upper bound/ of the /match type/, or ~Any~ if no
           such bound is given.

       + Scrutiny, /bound types/ and /pattern types/ must be /first-order types/.
         TODO =from Jian= ??? I don't quite understand this sentence!?!?

**** TODO Match type reduction
**** TODO Subtyping Rules for Match Types
**** TODO Variance Laws for Match Types
**** TODO Typing Rules for Match Expressions
**** TODO Overlapping Patterns
**** TODO Handling Termination
**** TODO Related Work

*** DONE Dependent Function Types
    CLOSED: [2019-07-01 Mon 16:10]
    - A /dependent function type/ describes functions where the _result type_ may
      DEPEND ON the _function's parameter values_. Example:
      #+begin_src scala
        trait Entry {
          type Key
          val key: Key
        }

        def extractKey(e: Entry): e.Key = e.key          // a dependent method
        val extractor: (e: Entry) => e.Key = extractKey  // a dependent function value
        //           ||                   ||
        //           ||     Dependent     ||
        //           ||   Function Type   ||
        //           =======================
      #+end_src

      - Scala _ALREADY_ has /dependent methods/.
        BUT so far (in Scala 2) it was _NOT possible_ to turn such /methods/ into
        /function values/, so that they can be passed as /parameters/ to other
        functions, or returned as results.
        + /Dependent methods/ COULD NOT be turned into /functions/ simply because
          there was no type that could describe them.

      - In dotty the /type/ of the ~extractor~ value above is ~(e: Entry) => e.Key~

    - The /dependent function type/ above is just /syntactic sugar/ for
      #+begin_src scala
        Function1[Entry, Entry#Key] {
          def apply(e: Entry): e.Key
        }
      #+end_src

**** More details

** TODO ENUMS
*** DONE Enumerations
    CLOSED: [2020-07-10 Fri 23:57]
    An /enumeration/ is used to define a /type/ consisting of _a set of NAMED values._

    - Example:
      #+begin_src scala
        enum Color {
          case Red, Green, Blue
        }
      #+end_src
      Desugare to core Scala features are explained in the section _Translation_.
      + This defined a new ~sealed~ /class/ ~Color~ with 3 values:
        * ~Color.Red~
        * ~Color.Green~
        * ~Color.Blue~

      + The _color values_ are members of ~Color~'s /companion object/.

**** DONE Parameterized enums
     CLOSED: [2020-07-10 Fri 19:08]
     /Enums/ CAN BE _parameterized_:
     #+begin_src scala
       enum Color(val rgb: Int) {
         case Red   extends Color(0xFF0000)
         case Green extends Color(0x00FF00)
         case Blue  extends Color(0x0000FF)
       }
     #+end_src
     As the example shows, you can _DEFINE_ the parameter value BY using an
     _EXPLICIT_ ~extends~ /clause/.

**** DONE Methods defined for enums
     CLOSED: [2020-07-10 Fri 19:15]
     - The values of an /enum/ correspond to _UNIQUE integers_.
       The _integer_ associated with an /enum value/ is returned by its ~ordinal~
       /method/.

     - Example:
       #+begin_src scala
         val red = Color.Red
         // val red: Color = Red

         red.ordinal
         // val res0: Int = 0
       #+end_src

     - The /companion object/ of an /enum/ also defines *TWO* utility /methods/.
       + ~valueOf~: obtain an /enum value/ by its _name_:
         ~Color.valueOf("Blue")  // val res0: Color = Blue~

       + ~values~: returns _ALL_ /enum values/ defined in an enumeration in an
         ~Array~:
         ~Color.values  // val res1: Array[Color] = Array(Red, Green, Blue)~

**** DONE User-defined members of enums
     CLOSED: [2020-07-10 Fri 19:23]
     It is _possible_ to add your own definitions to an /enum/.

     - Example:
       #+begin_src scala
         enum Planet(mass: Double, radius: Double) {
           private final val G = 6.67300E-11
           def surfaceGravity = G * mass / (radius * radius)
           def surfaceWeight(otherMass: Double) =  otherMass * surfaceGravity

           case Mercury extends Planet(3.303e+23, 2.4397e6)
           case Venus   extends Planet(4.869e+24, 6.0518e6)
           case Earth   extends Planet(5.976e+24, 6.37814e6)
           case Mars    extends Planet(6.421e+23, 3.3972e6)
           case Jupiter extends Planet(1.9e+27,   7.1492e7)
           case Saturn  extends Planet(5.688e+26, 6.0268e7)
           case Uranus  extends Planet(8.686e+25, 2.5559e7)
           case Neptune extends Planet(1.024e+26, 2.4746e7)
         }
       #+end_src

     - It is also possible to define an *EXPLICIT* /companion object/ for an /enum/:
       #+begin_src scala
         object Planet {
           def main(args: Array[String]) = {
             val earthWeight = args(0).toDouble
             val mass = earthWeight / Earth.surfaceGravity
             for (p <- values)
               println(s"Your weight on $p is ${p.surfaceWeight(mass)}")
           }
         }
       #+end_src
       + =from Jian= ???
         Before compiling, will ~case~'s be merged into the generated /companion
         object/???

**** DONE Compatibility with Java Enums
     CLOSED: [2020-07-10 Fri 21:53]
     If you want to use a enum in Scala in Java, you need to extends
     ~java.lang.Enum[T]~, where ~T~ is your _enum type name_.
     - Example
       #+begin_src scala
         enum Color extends java.lang.Enum[Color] { case Red, Green, Blue }

         // Use `Color` as you would use a Java enum:
         Color.Red.compareTo(Color.Green)
         // val res15: Int = -1
       #+end_src
       + There is _NO need to provide_ /constructor arguments/ (as defined in the
         Java API docs) to ~java.lang.Enum~ when extending it – _the compiler will
         GENERATE them AUTOMATICALLY._

     - For a more in-depth example of using Scala 3 /enums/ from Java, see this
       test (in GITHUB dotty project repo) -- the /enums/ are defined in the
       ~MainScala.scala~ file and used from a Java source, ~Test.java~.

**** DONE Implementation
     CLOSED: [2020-07-10 Fri 23:56]
     /Enums/ are represented as ~sealed~ /abstract classes/ that extend the
     ~scala.Enum~ /trait/.

     - ~scala.Enum~ defines a _SINGLE_ /public method/, ~ordinal~:
       #+begin_src scala
         package scala

         /** A base trait of all enum classes */
         trait Enum {
           /** A number uniquely identifying a case of an enum */
           def ordinal: Int
         }
       #+end_src

     - /Enum values/ *WITH* ~extends~ /clauses/ get *expanded* to /anonymous class
       instances/.
         For instance, the ~Venus~ value above (=from Jian= in Section _User-defined
       members of enums_) would be defined like this:
       #+begin_src scala
         val Venus: Planet = new Planet(4.869e24, 6.0518e6) {
           def ordinal: Int = 1
           override def toString: String = "Venus"
           // internal code to register value
         }
       #+end_src

     - /Enum values/ *WITHOUT* ~extends~ /clauses/ all share a single implementation
       that can be instantiated using a /private method/ that takes _a tag (=from Jian=
       /ordinal/???)_ and _a name_ as /arguments/.
         For instance, ~Color.Red~ would expand to
         #+begin_src scala
           val Red: Color = $new(0, "Red")
         #+end_src

**** TODO Reference
     For more info, see [[https://github.com/lampepfl/dotty/issues/1970][Issue #1970]] and [[https://github.com/lampepfl/dotty/pull/4003][PR #4003]].

*** DONE Algebraic Data Types
    CLOSED: [2020-07-11 Sat 01:28]
    The ~enum~ concept is general enough to ALSO support ADTs and GADTs.

    - Example:
      #+begin_src scala
        enum Option[+T] {
          case Some(x: T)
          case None
        }
      #+end_src
      + ~case Some~ is a shorthand for writing a /case class/ that _extends_
        ~Option~.

      + ~None~ is NOT parameterized, it is treated as a _normal_ enum value.

      + The ~extends~ clauses can be given explicitly:
        #+begin_src scala
          enum Option[+T] {
            case Some(x: T) extends Option[T]
            case None       extends Option[Nothing]
          }
        #+end_src

      + Note:
        The /parent type/ of the ~None~ value is inferred as ~Option[Nothing]~.
        Generally,
        * all /covariant/ /type parameters/ of the /enum class/ are *minimized* in
          a compiler-generated ~extends~ clause

        * whereas all /contravariant/ /type parameters/ are *maximized*.

        * If ~Option~ was /non-variant/, you would need to give the ~extends~
          /clause/ of ~None~ *EXPLICITLY*.

    - If not directly ~new~ a enumeration, the /type/ is always its parent.
      For example,
      + ~Option.Some(2)~ is of /type/ ~Option[Int]~
      + ~Option.None~ is of /type/ ~Option[Nothing]~
      + ~new Option.Some(2)~ is of /type/ ~Option.Some[Int]~

    - As all other enums, ADTs can define methods.
      #+begin_src scala
        enum Option[+T] {
          case Some(x: T)
          case None

          def isDefined: Boolean = this match {
            case None => false
            case some => true
          }
        }

        object Option {
          def apply[T >: Null](x: T): Option[T] =
            if (x == null) None else Some(x)
        }
      #+end_src

    - /Enumerations/ and /ADTs/ have been presented as two *DIFFERENT concepts*.
      _BUT_ since they _share the SAME /syntactic construct/,_
      1. they can be seen simply as two ends of a spectrum
         AND
      2. it is perfectly possible to construct *hybrids*.

    - For instance, the code below gives an implementation of ~Color~ either with
      three /enum values/ or with a /parameterized case/ that takes an RGB value.
      #+begin_src scala
        enum Color(val rgb: Int) {
          case Red           extends Color(0xFF0000)
          case Green         extends Color(0x00FF00)
          case Blue          extends Color(0x0000FF)
          case Mix(mix: int) extends Color(mix)
        }
      #+end_src

**** DONE Syntax of Enums
     CLOSED: [2019-07-02 Tue 13:27]
     - TODO NOTE

**** TODO Reference
     For more info, see [[https://github.com/lampepfl/dotty/issues/1970][Issue #1970]].

*** TODO Translation
    # *Translation of Enum and ADTs*
    1. An ~enum~ definition
       + ~enum E ... { <defs> <cases> }~ expands to
         * a ~sealed abstract class~ that extends the ~scala.Enum~ /trait/
           AND
         * an associated /companion object/ that CONTAINS the _defined cases_,
           =TODO= expanded according to rules (2 - 8) =TODO=.

       + The /enum trait/
         * _starts with_ a compiler-generated import that imports the names ~<caseIds>~
           of all cases _so that they can be used WITHOUT prefix *IN* the trait._
           #+begin_src scala
             sealed abstract class E ... extends <parents> with scala.Enum {
               import E.{ <caseIds> }
               <defs>
             }

             object E { <cases> }
           #+end_src

    2. =TODO= Re-write =TODO= A /simple case/ consisting of a comma-separated list
       of enum names:
       ~case C_1, ..., C_n~ expands to ~case C_1; ...; case C_n~
       + Any /modifiers/ or /annotations/ on the ORIGINAL case _extend_ to ALL
         EXPANDED cases.

    3. For a /enum/ ~E~, its /simple case/
       ~case C~ -----> ~val C = $new(n, "C")~.
       + Here, ~$new~ is a /private method/ that creates an instance of ~E~
         (=TODO= see below).

    4. For a enum ~E[V1 T1 >: L1 <: U1, ..., Vn Tn >: Ln <: Un]~, where _n > 0_ and
       the /variances/ ~Vi~ is either ~+~ or ~\minus~,
       /simple case/ ~case C~ -----> ~case C extends E[B1, ..., Bn]~, where
       ~Bi~ is ~Li~ if ~Vi~ is ~+~ and ~Ui~ if ~Vi~ is ~\minus~.
       + =TODO= This result is then further rewritten with *rule (8)*.

       + /Simple cases/ of /enums/ with /NON-VARIANT/ /type parameters/ are *not
         permitted* (however /value cases/ with *EXPLICIT* ~extends~ clause are)
         =TODO= ??? =TODO=

    5. For a ~enum E~, its /class case/
       ~case C <type-params> <value-params>~  ----->
       ~case C <type-parmas> <value-parmas> extends E~.
       + =TODO= This result is then further rewritten with *rule (9)*.

    6. For a ~enum E[Ts]~, its /class case/ with NEITHER /type parameters/ NOR an
       ~extends~ clause
       ~case C <value-params>~ -----> ~case C[Ts] <value-params> extends E[Ts]~.
       + =TODO= This result is then further rewritten with *rule (9)*.
       + For /class cases/ that have /type parameters/ themselves, an /extends
         clause/ needs to be GIVEN EXPLICITLY.

    7. For a ~enum E[Ts]~,
       its /class case/
       ~case C <value-params> extends <parents>~ ----->
       ~case C[Ts] <value-parmas> extends <parents>~
       *provided* at least one of the /type parameters/ ~Ts~ is mentioned
       + in a /parameter type/ in ~<value-params>~
         OR
       + in a /type argument/ in ~<parents>~.

    8. ~enum E[Ts]~'s /value case/
       ~case C extends <parents>~ ----->
       ~val C = new <pareents> { <body>; def ordinal = n; $values.register(this) }~
       in ~E~'s /companion object/, and
       + ~n~ starting from ~0~.

       + The statement ~$values.register(this)~ registers the value as one of the
         ~values~ of the enumeration (=TODO= see below). ~$values~ is a
         /compiler-defined _private_ value/ in the /companion object/.

       + The /anonymous class/ (the value referenced by ~C~) also implements the
         /abstract/ ~Product~ /methods/ that it inherits from ~Enum~.

       + It's an *error*
         if a /value case/ referes to a /type parameter/ of the enclosing ~enum~
         in a /type argument/ of ~<parents>~.

    9. ~enum E[Ts]~'s /class case/
       ~case C <params> extends <parents>~ ----->
       ~final case class C <params> extends <parents>~ in ~E~'s /companion object/.
       + However, *unlike* for a REGULAR /case class/, the return type of the associated
         ~apply~ method is a /fully parameterized type instance/ of the /enum class/
         ~E~ itself instead of ~C~.

       + ~ordinal~ /method/ is defined as ~def ordinal = n~, where ~n~ the /ordinal
         number/ of the /case/ in the /companion object/, starting from ~0~.

       + It is an *error*
         if a /value case/ refers to a /type parameter/ of the ENCLOSING ~enum~
         in a /parameter type/ in ~<params>~ or in a /type argument/ of ~<parents>~,
         unless that parameter is already a /type parameter/ of the case, i.e. the
         parameter name is defined in <params>.

**** TODO Translation of Enumerations
     - enumerations :: /non-generic enums/ that define one or more *singleton* cases.

     - /Companion objects/ of /enumerations/ define the following additional
       /synthetic members/.
       + A /method/ ~valueOf(name: String): E~.
         It returns the singleton case value whose toString representation is
         name.

       + A /method/ ~values~ which returns an ~Array[E]~ of *ALL* /singleton case/
         values in ~E~, _in the *ORDER* of their definitions._

     - /Companion objects/ of /enumerations/ that contain _at least_ one /simple case/
       define in addtion:
       + A /private method/ ~$new~ which defines a new simple /case value/ with given
         /ordinal number/ and /name/.
         This /method/ can be thought as being defined as follows:
         #+begin_src scala
           private of $new(_$ordinal: Int, $name: String) = new E {
             def $ordinal = $_ordinal
             override def toString = $name
             $values.register(this)  // register enum value so that `valueOf` and `values` can return it.
           }
         #+end_src

     - The /anonymous class/ also implements the /abstract/ ~Product~ /methods/
       that it _inherits_ from ~Enum~. The ~$ordinal~ /method/ above is used to
       generate the ~ordinal~ /method/ if the /enum/ does NOT /extend/ a
       ~java.lang.Enum~ *(as /Scala enums/ do NOT /extend/ ~java.lang.Enums~ unless
       explicitly specified)*.
         In case it does, there is no need to generate ~ordinal~ as
       ~java.lang.Enum~ defines it.

**** TODO Scopes for Enum Cases
**** TODO Translation of Java-compatible enums
**** TODO Other Rules

** TODO CONTEXTUAL ABSTRACTIONS
*** TODO Overview
**** TODO Critique of the Status Quo
     TODO
     TODO
     TODO

**** TODO The New Design
     - The following pages introduce a *REDESIGN* of /contextual abstractions/ in
       Scala. *They introduce _four_ fundamental CHANGES*:
       1. /Given Instances/:
          a new way to define basic terms that can be synthesized.
          + They _replace_ /implicit definitions/.

          + The core principle of the proposal:
            rather than mixing the ~implicit~ /modifier/ with a large number of
            features, we have a SINGLE WAY to define terms that can be synthesized
            for types.

       2. /Using Clauses/:
          a new syntax for _IMPLICIT parameters and their arguments_.
          + Both are introduced with the same keyword, ~given~.

          + TODO
            It unambiguously aligns parameters and arguments, solving a number
            of language warts.

          + TODO
            It also allows us to have _SEVERAL_ ~using~ clauses in a definition.

       3. /"Given" Imports/:
          a new class of /import selectors/ that _SPECIFICALLY import givens_
          and nothing else.

       4. /Implicit Conversions/:
          now expressed as /given instances/ of a standard ~Conversion~ class.
          All other forms of /implicit conversions/ WILL _be phased out_.

     - This section also contains pages describing other language features that
       are _related to_ /context abstraction/. These are:
       + /Context Bounds/, which carry over unchanged.

       + /Extension Methods/ REPLACE /implicit classes/ in a way that _INTEGRATES
         BETTER with /type classes/._

       + /Implementing Type classes/ demonstrates how some common /type classes/ can
         be implemented using the new constructs. TODO ??? TODO

       + /Type class Derivation/ introduces constructs to AUTOMATICALLY *derive*
         /type class instances/ for ADTs.

       + /Multiversal Equality/ introduces a special type class to support /type safe
         equality/.

       + /Context Functions/ provide a way to abstract over /context parameters/.

       + /By-Name Context Parameters/ are an essential tool to DEFINE /recursive
         synthesized values/ WITHOUT looping.

       + _Relationship with Scala 2 Implicits_ discusses the relationship between
         old-style implicits and new-style givens and how to migrate from one to
         the other.

     - Overall, the new design achieves a BETTER *separation* of /term inference/
       *from* *the rest of the language*:

       + There is a *single way* to define /givens/ instead of a multitude of forms
         all taking an ~implicit~ /modifier/.

       + There is a *single way* to introduce /implicit parameters and arguments/
         _instead of_ conflating implicit with normal arguments.

       + There is a *separate way* to _import givens_ that does *NOT allow* them
         to *hide* in a sea of normal imports.

       + And there is a *single way* to define an /implicit conversion/ which is
         clearly marked as such and _does NOT require SPECIAL syntax._

     - TODO =What we get from the new design= TODO
       This design thus avoids feature interactions and makes the language more
       consistent and orthogonal. It will make implicits easier to learn and
       harder to abuse. It will greatly improve the clarity of the 95% of Scala
       programs that use implicits. It has thus the potential to fulfil the
       promise of term inference in a principled way that is also accessible and
       friendly.

     - TODO TODO TODO
       + Q :: Could we achieve the same goals by tweaking existing implicits?

       + A :: After having tried for a long time, I believe now that this is
              *impossible*.
         1. First, some of the problems are clearly syntactic and require different
            syntax to solve them.

         2. Second, there is the problem how to migrate. We cannot change the rules
            in mid-flight. At some stage of language evolution we need to
            accommodate both the new and the old rules. With a syntax change,
            this is easy: Introduce the new syntax with new rules, support the
            old syntax for a while to facilitate cross compilation, deprecate
            and phase out the old syntax at some later time. Keeping the same
            syntax does not offer this path, and in fact does not seem to offer
            any viable path for evolution

         3. Third, even if we would somehow succeed with migration, we still have
            the problem how to teach this. We cannot make existing tutorials go
            away. Almost all existing tutorials start with implicit conversions,
            which will go away; they use normal imports, which will go away, and
            they explain calls to methods with implicit parameters by expanding
            them to plain applications, which will also go away. This means that
            we'd have to add modifications and qualifications to all existing
            literature and courseware, likely causing more confusion with
            beginners instead of less. By contrast, with a new syntax there is a
            clear criterion: Any book or courseware that mentions implicit is
            outdated and should be updated.

*** DONE Given Instances
    CLOSED: [2020-03-08 Sun 23:12]
    /Given instances/ (or, simply, "givens") define "canonical" values of certain
    types that serve for /synthesizing arguments/ to /context parameters/.
    =from Jian= /context parameters/ describes a requirement to /given instances/.

    - Example:
      #+begin_src scala
        trait Ord[T] {
          def compare(x: T, y: T): Int

          def (x: T) < (y: T) = compare(x, y) < 0
          def (x: T) > (y: T) = compare(x, y) > 0
        }

        given intOrd as Ord[Int] {
          def compare(x: Int, y: Int) =
            if (x < y) -1 else if (x > y) +1 else 0
        }

        given listOrd[T](using ord: Ord[T]) as Ord[List[T]] {
          def compare(xs: List[T], ys: List[T]): Int = (xs, ys) match {
            case (Nil, Nil) => 0
            case (Nil, _)   => -1
            case (_, Nil)   => +1
            case (x :: xs1, y :: ys1) =>
              val fst = ord.compare(x, y)
              if (fst != 0) fst else compare(xs1, ys1)
          }
        }
      #+end_src
      This code defines a /trait/ ~Ord~ (type class) with two /given instances/.

**** DONE Anonymous Givens
     CLOSED: [2020-03-08 Sun 21:52]
     The name of a /given instance/ *can be left out*.
     #+begin_src scala
       given Ord[Int] { /* ... */ }
       given [T](using Ord[T]) as Ord[List[T]] { /* ... */ }
     #+end_src
     If the name of a given is missing,
     the compiler will _synthesize a name_ from the implemented type(s).
     =from Jian= The doc doesn't mention the rules of synthesizing this name, for
                 the users the rules is not important -- you define an anonymous
                 given means you plan not to use its name.

**** TODO Alias Givens
     An alias can be used to define a /given instance/ that is equal to some
     expression. E.g.:
     #+begin_src scala
       given global as ExecutioinContext = new ForkJoinPool()
     #+end_src
     When the first time ~global~ is accessed, the RHS is evaludated, which is then
     returned for this and all subsequent accesses to ~global~.
     =from Jian= A kind of /lazy evaluation/.
     =from Jian= More initialization rules in the "Given Instance Initialization"
                 below.

     - This operation is /thread-safe/.

     - /Alias givens/ can be _anonymous_ as well, e.g.
       #+begin_src scala
         given Position = enclosingTree.position
         given (using config: Config) as Factory = MemoizingFactory(config)
       #+end_src

     - An /alias given/ can have /type parameters/ and /context parameters/ just like
       any other /given/, _but it can ONLY implement a single type._
       =from Jian= Because it is an alias -- a name or concrete thing, not a
                   general instances.

**** TODO Given Macros
     Given aliases can have the ~inline~ and ~transparent~ modifiers.
     Example:
     #+begin_src scala
       transparent inline given mkAnnotations[A, T] as Annotations[A, T] = ${
         // code producing a value of a subtype of Annotations
       }
     #+end_src
     Since ~mkAnnotations~ is ~transparent~, the type of an application is the
     type of its right hand side, which can be a proper /subtype/ of the declared
     /result type/ ~Annotations[A, T]~.

**** DONE Given Instance Initialization
     CLOSED: [2020-03-08 Sun 23:11]
     - A /given instance/
       + without /type parameters/ or /context parameters/
         *is initialized on-demand, the first time it is accessed.*
         =from Jian= *FROM OLD Dotty Doc*
         * It is _NOT required to ENSURE_ /safe publication/, which means that
           DIFFERENT /threads/ might create DIFFERENT /instances/ for the SAME
           /given definition/.

       + has /type parameters/ or /context parameters/, a *FRESH* instance is
         created _for EACH reference_.

**** DONE Syntax
     CLOSED: [2020-03-08 Sun 23:11]

*** DONE Using Clauses
    CLOSED: [2020-03-09 Mon 00:56]
    - Functional programming tends to express most dependencies as simple function
      parameterization.
      + =from Jian=
        How does Functional programming express dependencies

    - This is clean and powerful, but it sometimes leads to functions that take
      many parameters where the same value is passed over and over again in long
      call chains to many functions.
      + =from Jian=
        The issue that following the way that Functional programming express
        dependencies

    - /Context parameters/ can help here since they enable the compiler to synthesize
      repetitive arguments instead of the programmer having to write them explicitly.
      + =from Jian=
        The way of Scala to resolve the issue mentioned in the last bullet.

    - Example:
      #+begin_src scala
        def max[T](x: T, y: T)(using ord: Ord[T]): T =
          if ord.compare(x, y) < 0 then y else x

        // The explicit way
        max(2, 3)(using intOrd)

        // The implicit way
        max(2, 3)
        max(List(1, 2, 3), Nil)
      #+end_src

**** DONE Anonymous Context Parameters
     CLOSED: [2020-03-09 Mon 00:20]
     - =from Jian=
       A functional /context parameter/ always co-exit with a /given instance/.
       Such as /given instances/, /context parameter/ can be anonymous, though the
       reason for /context parameter/ is different from the reason for /given
       instance/.
       + Anonymous /given instances/ (frequency: Almost Always):
         /given instances/ search is always match types.
         Name is not that important.

       + Anonymous /context parameters/ (frequency: Often):
         =from Doc=
         It is used only in synthesized arguments for OTHER /context parameters/.
         Example:
         #+begin_src scala
           def maximum[T](xs: List[T])(using Ord[T]): T =
             xs.reduceLeft(max)
         #+end_src
         Here the context parameter of type ~Ord[T]~ is synthesized for ~max~,
         not for explicit use as inside ~max~.

     - /Vararg parameters/ are not supported in /using clauses/.
       + =from Jian=
         In the example above,
         * ~Ord[T]~ is the /context parameter/.

         * ~using Ord[T]~ is the /using clause/.

**** DONE Inferring Complex Arguments
     CLOSED: [2020-03-09 Mon 00:49]
     #+begin_src scala
       def descending[T](using asc: Ord[T]): Ord[T] = new Ord[T] {
         def compare(x: T, y: T) = asc.compare(y, x)
       }

       def minimum[T](xs: List[T])(using Ord[T]) =
         maximum(xs)(using descending)

       // minimum(xs)
       // maximum(xs)(using descending)
       // maximum(xs)(using descending(using listOrd))
       // maximum(xs)(using descending(using listOrd(using intOrd)))
     #+end_src
     - =from Jian=
       The description of this section is NOT clear!!!
       Here is my understanding:
         If, in the example above, not ~using descending~ passed in, the ~maximum~
       function will find the maximum value. This why we must manually provide the
       ~using descending~ to make the code be functional as we expect. Or else, it
       is runnable (with a wrong synthesized ~Ord[T]~ instance) and returns a wrong
       result.

**** DONE Multiple Using Clauses
     CLOSED: [2020-03-09 Mon 00:52]
     There can be several using clauses in a definition and using clauses can be
     freely mixed with normal parameter clauses. Example:
     #+begin_src scala
       def f(u: Universe)(using ctx: u.Context)(using s: ctx.Symbol, k: ctx.Kind) = ...
     #+end_src

     - Multiple using clauses are matched left-to-right in applications. Example:
       #+begin_src scala
         object global extends Universe { type Context = ... }
         given ctx  as global.Context { type Symbol = ...; type Kind = ... }
         given sym  as ctx.Symbol
         given kind as ctx.Kind
       #+end_src

     - Then the following calls are all valid (and normalize to the last one)
       #+begin_src scala
         f(global)
         f(global)(using ctx)
         f(global)(using ctx)(using sym, kind)
       #+end_src

     - Invalid, for example:
       ~f(global)(using sym, kind)~

**** DONE Summoning Instances
     CLOSED: [2020-03-09 Mon 00:56]
     - =from Jian=
       ~sommon~ from ~Predef~ is a replacement of the ~implicitly~ in Scala 2.

     - The ~summon~ is simply defined as /the (*non-widening*) identity function/
       over a /context parameter/:
       #+begin_src scala
         def sommon[T](using x: T): x.type = x
       #+end_src

**** DONE Syntax
     CLOSED: [2020-03-09 Mon 00:56]

*** DONE Context Bounds
    CLOSED: [2019-11-12 Tue 02:20]
    A /context bound/ is a *SHORTHAND* for expressing the common pattern (a.k.a
    type class pattern) of an /context parameter/ that depends on *A* /type parameter/.
    #+begin_src scala
      def maximum[T: Ord](xs: List[T]): T = xs.reduceLeft(max)
    #+end_src

**** Context Bounds
     - The /context parameter(s)/ *generated from* /context bounds/ come *LAST*
       in the definition of the containing /method/ or /class/. E.g.
       #+begin_src scala
         def f[T: C1 : C2, U: C3](x: T)(using y: U, z: V): R

         // would expand to

         def f[T, U](x: T)(using y: U, z: V)(using C1[T], C2[T], C3[U]): R
       #+end_src

     - /Context bounds/ can be combined with /subtype bounds/.
       _If both are present, /subtype bounds/ *come first*,_ e.g.
       ~def g[T <: B : C](x: T):R = ...~

**** Migration
**** Syntax
     #+begin_src text
       TypeParamBounds ::= [SubtypeBounds] {ContextBound}
       ContextBound    ::= ':' Type
     #+end_src

*** DONE Given Imports
    # Importing Givens
    CLOSED: [2019-11-13 Wed 14:44]
    A _special form_ of /import wildcard selector/ is used to IMPORT /given
    instances/.
    - Example:
      #+begin_src scala
        object A {
          class TC
          given tc as TC
          def f(using TC) = ???
        }

        object B {
          import A._
          import A.{given _}
          // ...
        }
      #+end_src
      + In Dotty, ~import A._~ import all members of ~A~ *except* the /given instances/.

      + Merge the two import clauses: ~import A.{given _, _}~

    - There are _TWO_ main benefits arising from these rules:
      + It is made clearer where /givens/ in scope are coming from.

      + It enables importing all /givens/ without importing anything else.
        This is _particularly important since /givens/ can be ANONYMOUS_, so the
        usual recourse of using /named imports/ is NOT practical.

**** DONE Importing By Type
     CLOSED: [2019-11-13 Wed 14:37]
     Since /givens/ can be _anonymous_ it is _NOT always practical to import them
     by their name_, and /wildcard imports/ are typically used instead.
       /By-type imports/ provide a _MORE SPECIFIC alternative_ to /wildcard imports/,
     which makes it clearer what is imported.

     - Example:
       + ~import A.{given TC}~

       + ~import A.{given T1, given T2, ..., given Tn}~

       + ~import A.{given Ordering[?]}~ -- =IMPORTANT= easy to forget this usage

       + /By-type imports/ can be mixed with /by-name imports/.
         If BOTH are present in an import clause, *by-type imports come last*.
         ~import A.{im, given Ordering[?]}~

     - =from Jian= *EXIST BEFORE, but _DELETED_ from this page (ver 0.23.0)*
       /Bounded wildcard selectors/ *also work* for _normal imports and exports_.
       For instance,
       #+begin_src scala
         enum Color {
           case Red, Green, Blue, Megenta

           def isPrimary(c: Color): Boolean = ...
         }

         // Export all four `Color` values, but leaves the `isPrimary` method alone.
         export Color.{_: Color}
       #+end_src

**** DONE Migration
     CLOSED: [2019-11-13 Wed 14:42]
     TODO NOTE
**** DONE Syntax
     CLOSED: [2019-11-13 Wed 14:44]
     TODO NOTE

*** DONE Extension Methods
    CLOSED: [2020-03-10 Tue 00:59]
    /Extension methods/ allow one to add /methods/ to a /type/ after the /type/
    is defined.
    =from Jian= A way to extend a closed (not own, or better not change) system.

    - Example:
      + Definition:
        #+begin_src scala
          case class Circle(x: Double, y: Double, radius: Double)

          def (c: Circle).circumference: Double = c.radius * math.Pi * 2
        #+end_src

      + Invoke as regular methods:
        #+begin_src scala
          val circle = Circle(0, 0, 1)
          circle.circumference
        #+end_src

**** DONE Translation of Extension Methods
     CLOSED: [2020-03-09 Mon 23:15]
     - extension methods :: /methods/ that have a parameter clause in front of the
       defined identifier.

     - They translate to methods where the leading parameter section is moved to
       after the defined identifier.
         So, the definition of ~circumference~ above translates to the plain
       method, and can also be invoked as such:
       #+begin_src scala
         def circumference(c: Circle): Double = c.radius * math.Pi * 2

         assert(circle.circumference == circumference(circle))
       #+end_src

**** TODO Translation of Calls to Extension Methods
     - When is an /extension method/ applicable? There are two possibilities.
       An /extension method/ is applicable
       + if it is visible under a simple name,
         in a scope enclosing the application,
         by being
         * _defined_
           or
         * _inherited_
           or
         * _imported_

       + if it is a member of some /given instance/ at the point of the application.

     - Example:
       #+begin_src scala
         trait IntOps {
           def (i: Int).isZero: Boolean =
             i == 0

           def (i: Int).safeMod(x: Int): Option[Int] =
             // extension method defined in same scope IntOps
             if x.isZero then None
             else             Some(i % x)
         }

         object IntOpsEx extends IntOps {
           def (i: Int).safeDiv(x: Int): Option[Int] =
             // extension method brought into scope via inheritance from IntOps
             if x.isZero then None
             else             Some(i / x)

         }

         trait SafeDiv {
           import IntOpsEx._  // brings safeDiv and safeMod into scope

           def (i: Int) divide(d: Int): Option[(Int, Int)] =
             // extension methods imported and thus in scope
             (i.safeDiv(d), i.safeMod(d)) match {
               case (Some(d), Some(r)) => Some((d, r))
               case _                  => None
             }
         }
       #+end_src
       + =TODO=
       + =TODO=
       + =TODO=
       + =TODO=

     - The _PRECISE_ *rules for RESOLVING a selection to an extension method* are
       as follows:
         Assume a selection ~e.m[Ts]~ where ~m~ is not a member of ~e~, where
       the /type arguments/ ~[Ts]~ are _OPTIONAL_, and where ~T~ is the expected
       type. The following two rewritings *are tried in order*:

       1. The selection is rewritten to ~m[Ts](e)~.

       2. If the first rewriting does not typecheck with expected type ~T~, and
          there is a /given instance/ ~g~ in either the /current scope/ or in
          the /context scope/ of ~T~, and ~g~ defines an /extension method/
          named ~m~, then selection is expanded to ~g.m[Ts](e)~. This second
          rewriting is attempted at the time where the compiler also tries an
          /implicit conversion/ from ~T~ to a type containing ~m~.
            *If there is more than one way of rewriting, an ambiguity error
          results.*

     - So ~circle.circumference~ translates to ~CircleOps.circumference(circle)~,
       provided ~circle~ has type ~Circle~ and ~CircleOps~ is /given/ (i.e. it is
       visible at the point of call or it is defined in the /companion object/ of
       ~Circle~).

**** DONE Operators
     CLOSED: [2020-03-10 Tue 00:16]
     - Use /extension method syntax/ to define operators.
       + This case is indicated by *omitting the period* between the leading
         parameter list and the operator.

       + This syntax mirrors the way the operator is applied.

     - Examples:
       #+begin_src scala
         def (x: String) < (y: String) = ...
         def (x: Elem) +: (xs: Seq[Elem]) = ...
         def (x: Number) min (y: Number) = ...

         "ab" < "c"
         1 +: List(2, 3)
         x min 3
       #+end_src
       + For /alphanumeric extension operators/ like ~min~ an ~@infix~ annotation
         is *implied*.

       + The translations:
         #+begin_src scala
           def <(x: String)(y: String) = ...
           def +:(xs: Seq[Elem])(x: Elem) = ...
           def min(x: Number)(y: Number) = ...
         #+end_src
         * Remember that in Scala ~:~ suffixed operators are all /right associative/!!!
           This is why ~+:~ in the translation, the order of ~x~ and ~xs~ are swapped!

**** DONE Generic Extensions
     CLOSED: [2020-03-10 Tue 00:33]
     We already discussed ~StringSeqOps~, which extends a specific instance of
     generic type (~Seq[String]~).
       This section will discuss /extension method of generic type/.

     - Examples:
       #+begin_src scala
         def [T](xs: List[T]) second =
           xs.tail.head

         def [T](xs: List[List[T]]) flattened =
           xs.foldLeft[List[T]](Nil)(_ ++ _)

         def [T: Numeric](x: T) + (y: T): T =
           summon[Numeric[T]].plus(x, y)
       #+end_src

     - Usage:
       ~List(1, 2, 3).second[Int]~

**** DONE Extension Instances
     CLOSED: [2020-03-10 Tue 00:59]
     It is quite common to wrap one or more /extension methods/ in a /given
     instance/, _in order to make them available as methods without needing to be
     imported explicitly_. This pattern is supported by a special /extension
     syntax/.

     - Example:
       #+begin_src scala
         extension ops {
           def (xs: Seq[String]).longestStrings: Seq[String] = {
             val maxLength = xs.map(_.length).max
             xs.filter(_.length == maxLength)
           }

           def (xs: Seq[String]).longestString: String = xs.longestStrings.head

           def [T](xs: List[T]).second: T = xs.tail.head
         }
       #+end_src

     - *An /extension instance/ can _ONLY_ contain /extension methods/.*
       *Other definitions are not allowed.* The name ~ops~ of the ~extension~ is
       *optional*. It can be left out:
       #+begin_src scala
         extension {
           def (xs: Seq[String]).longestStrings: Seq[String] = ...
           def [T](xs: List[T]).second: T = ...
         }
       #+end_src
       + If no name is given explicitly for ~extension~, a name will be synthesized
         from the _name_ and _type_ of the *first* implemented /extension method/.

     - /Extension instances/ map DIRECTLY to /given instances/.
       The code above would expand to
       #+begin_src scala
         given ops as AnyRef {
           def (xs: Seq[String]).longestStrings: Seq[String] = ...
           def (xs: Seq[String]).longestString: String = ...
           def [T](xs: List[T]).second: T = ...
         }
       #+end_src

     - The type "implemented" by this /given instance/ is ~AnyRef~, which is _not
       a type one can summon by itself._ TODO TODO TODO TODO TODO TODO ??? TODO TODO
         This means that the instance can _ONLY_ be used for its /extension methods/.

**** DONE Collective Extensions
     CLOSED: [2020-03-10 Tue 00:47]
     Define several /extension methods/ that *SHARE the SAME left-hand parameter type.*
       In this case one can "pull out" the common parameters into the /extension
     instance/ itself. Examples:
     #+begin_src scala
       extension stringOps on (ss: Seq[String]) {
         def longestStrings: Seq[String] = {
           val maxLength = ss.map(_.length).max
           ss.filter(_.length == maxLength)
         }
         def longestString: String = longestStrings.head
       }

       extension listOps on [T](xs: List[T]) {
         def second: T = xs.tail.head
         def third: T = xs.tail.second
       }

       extension on [T](xs: List[T])(using Ordering[T]) {
         def largest(n: Int) = xs.sorted.takeRight(n)
       }
     #+end_src
     + The /collective extensions/ above expand to the following /extension instances/:
       #+begin_src scala
         extension stringOps {
           def (ss: Seq[String]).longestStrings: Seq[String] = {
             val maxLength = ss.map(_.length).max
             ss.filter(_.length == maxLength)
           }
           def (ss: Seq[String]).longestString: String =
             ss.longestStrings.head
         }

         extension listOps {
           def [T](xs: List[T]).second: T = xs.tail.head
           def [T](xs: List[T]).third: T = xs.tail.second
         }

         extension {
           def [T](xs: List[T]).largest(using Ordering[T])(n: Int) =
             xs.sorted.takeRight(n)
         }
       #+end_src
       * Illustrate the code transformation by inspecting
         ~def longestString: String = longestStrings.head~
         #+begin_src scala
           def (ss: Seq[String]).longestString: String =
             ss.longestString.head
         #+end_src

**** DONE Syntax
     CLOSED: [2020-03-10 Tue 00:47]
     - TODO

     - ~extension~ and ~on~ are /soft keywords/, recognized only when they appear
       at the start of a statement in one of the patterns
       #+begin_src scala
         extension on ...

         extension <ident> on ...

         extension { ...

         extension <ident> { ...
       #+end_src

*** DONE Implementing Type classes
    CLOSED: [2020-03-09 Mon 01:00]
    /Given instances/, /extension methods/ and /context bounds/ allow a concise and
    natural expression of /type classes/.

    - /Type classes/ are just /traits/ with canonical implementations defined by
      /given instances/.

    - Here are some examples of standard type classes:

**** Semigroups and monoids
     #+begin_src scala
       trait SemiGroup[T] {
         def (x: T) combine (y: T): T
       }

       trait Monoid[T] extends SemiGroup[T] {
         def unit: T
       }

       object Monoid {
         def apply[T](using m: Monoid[T]) = m
       }

       given Monoid[String] {
         def (x: String) combine (y: String): String = x.concat(y)
         def unit: String = ""
       }

       given Monoid[Int] {
         def (x: Int) combine (y: Int): Int = x + y
         def unit: Int = 0
       }

       def sum[T: Monoid](xs: List[T]): T =
         xs.foldLeft(Monoid[T].unit)(_ combine _)
     #+end_src

     - TODO

     - TODO

**** TODO Functors
     #+begin_src scala
       trait Functor[F[?]] {
         def [A, B](x: F[A]).map(mapper: A => B): F[B]
       }
     #+end_src

     - The instance of ~Functor~ for ~List~ now becomes:
       #+begin_src scala
         given Functor[List] {
           def [A, B](original: List[A]).map(mapper: A => B): List[B] =
             original.map(mapper)  // List already has a `map` method
         }
       #+end_src

**** TODO Monads
     #+begin_src scala
       // "A `Monad` for type `F[?]` is a `Functor[F]`" => thus has the `map` ability
       trait Monad[F[?]] extends Functor[F] {
         // `pure` can construct F[A] from a single value A
         def pure[A](x: A): F[A]

         // the flattening ability is named `flatMap`, using extension methods as previous exmaples
         def [A, B](x: F[A]).flatMap(f: A => F[B]): F[B]

         // the `map(f)` ability is simply a combination of applying `f` then
         // turning the result into an `F[A]` then applying `flatMap` to it
         def [A, B](x: F[A]).map(f: A => B) = x.flatMap(f `andThen` pure)
       }
     #+end_src

***** List
      #+begin_src scala
        given listMonad as Monad[List] {
          def pure[A](x: A): List[A] =
            List(x)

          def [A, B](xs: List[A]).flatMap(f: A => List[B]): List[B] =
            xs.flatMap(f)  // Let's rely on the existing `flatMap` method of `List`
        }
      #+end_src

***** Option
      #+begin_src scala
        given optionMonad as Monad[Option] {
          def pure[A](x: A): Option[A] =
            Option(x)

          def [A, B](xs: Option[A]).flatMap(f: A => Option[B]): Option[B] =
            xs.flatMap(f)  // Let's rely on the existing `flatMap` method of `Option`
        }
      #+end_src

***** TODO The Reader Monad

**** TODO Summary

*** TODO Type Class Derivation
    # Type Class Derivation
    /Type class derivation/ is a way to *automatically* GENERATE /given instances/
    for /type classes/ which satisfy some simple conditions.

    - A /type class/ in this sense is *ANY* /trait/ or /class/ with *one* /type
      parameter/ determining the type being operated on.

    - Common examples of /type class/ are ~Eq~, ~Ordering~, or ~Show~.

    - For example, given the following ~Tree~ algebraic data type (ADT) with a
      ~dervies~ clause,
      #+begin_src scala
        enum Tree[T] derives Eq, Ordering, Show {
          case Branch(left: Tree[T], right: Tree[T])
          case Left(elem: T)
        }
      #+end_src
      + _The ~derives~ clause_ *generates* the following /given instances/ for the
        ~Eq~, ~Ordering~ and ~Show~ /type classes/ in the /companion object/ of ~Tree~,
        #+begin_src scala
          given [T: Eq]       as Eq[Tree[T]]    = Eq.derived
          given [T: Ordering] as Ordering[Tree] = Ordering.derived
          given [T: Show]     as Show[Tree]     = Show.derived
        #+end_src

      + We say that
        * ~Tree~ is the /deriving type/
        * the ~Eq~, ~Ordering~ and ~Show~ /given instances/ are /derived instances/.

**** DONE Types supporting ~derives~ clauses - =TODO=
     CLOSED: [2020-07-08 Wed 16:20]
     *ALL* data types CAN HAVE _a ~derives~ clause_.

     - This document FOCUSES PRIMARILY on data types which also have a /given
       instance/ of the ~Mirror~ /type class/ available.

     - /Instances/ of the ~Mirror~ /type class/ are generated *AUTOMATICALLY* by
       the compiler for,
       + /enums/ and /enum cases/
       + /case classes/ and /case objects/
       + /sealed classes or traits/ that have *ONLY* /case classes/ and /case
         objects/ as children

     - ~Mirror~ /type class instances/ provide
       + information at the type level about the components and labelling of the /type/.
       + minimal term level infrastructure to allow higher level libraries to provide
         comprehensive derivation support.

     - ~Mirror~ /type class/ definition
       #+begin_src scala
         sealed trait Mirror {

           /** The mirrored *-type */
           type MirroredMonoType

           /** The name of the type */
           type MirroredLabel <: String

           /** The names of the elements of the type */
           type MirroredElemLabels <: Tuple
         }

         object Mirror {

           /** The Mirror for a product type */
           trait Product extends Mirror {
             /** Create a new instance of type `T` with elements taken from product `p`. */
             def fromProduct(p: scala.Product): MirroredMonoType
           }

           trait Sum extends Mirror { self =>
             /** The ordinal number of the case class of `x`. For enums, `ordinal(x) == x.ordinal` */
             def ordinal(x: MirroredMonoType): Int
           }

           trait Singleton extends Product {
             type MirroredMonoType = this.type
             type MirroredType = this.type
             type MirroredElemTypes = EmptyTuple
             type MirroredElemLabels = EmptyTuple
             def fromProduct(p: scala.Product) = this
           }

           type Of[T]        = Mirror { type MirroredType = T; type MirroredMonoType = T ; type MirroredElemTypes <: Tuple }
           type ProductOf[T] = Mirror.Product { type MirroredType = T; type MirroredMonoType = T ; type MirroredElemTypes <: Tuple }
           type SumOf[T]     = Mirror.Sum { type MirroredType = T; type MirroredMonoType = T; type MirroredElemTypes <: Tuple }
         }
       #+end_src
       + ~Product~ types (i.e. /case classes and objects/, and /enum cases/) have
         /mirrors/ which are *subtypes* of ~Mirror.Product~.

       + ~Sum~ types (i.e. /sealed class/ or /traits with product children/, and
         /enums/) have /mirrors/ which are *subtypes* of ~Mirror.Sum~.

     - For the ~Tree~ ADT from above the following ~Mirror~ instances will be *automatically*
       provided by the compiler,
       #+begin_src scala
         // Mirror for Tree
         Mirror.Sum {
           type MirroredType = Tree[_]
           type MirroredElemTypes = (Tree.Branch[_], Tree.Leaf[_])
           type MirroredMonoType = Tree[_]
           type MirroredLabels = "Tree"
           type MirroredElemLabels = ("Branch", "Leaf")

           def ordinal(x: MirroredMonoType): Int = x match {
             case _: Tree.Branch[_] => 0
             case _: Tree.Leaf[_]   => 1
           }
         }

         // Mirror for Branch
         Mirror.Product {
           type MirroredType = Tree.Branch[_]
           type MirroredElemTypes = (Tree[_], Tree[_])
           type MirroredMonoType = Tree.Branch[_]
           type MirroredLabels = "Branch"
           type MirroredElemLabels = ("left", "right")

           def fromProduct(p: Product): MirroredMonoType =
             new Tree.Branch(...)
         }

         // Mirror for Leaf
         Mirror.Product {
           type MirroredType = Tree.Leaf[_]
           type MirroredElemTypes = Tuple1[_]
           type MirroredMonoType = Tree.Leaf[_]
           type MirroredLabels = "Leaf"
           type MirroredElemLabels = Tuple1["elem"]

           def fromProduct(p: Product): MirroredMonoType =
             new Tree.Leaf(...)
         }
       #+end_src

     - Note the following properties of ~Mirror~ /types/,
       + Properties are encoded _using /types/ RATHER THAN /terms/._
         This means that
         * they have _no_ runtime footprint _unless_ used
         * they are a _compile time feature_ for use with Dotty's metaprogramming
           facilities.

       + The /kinds/ of ~MirroredType~ and ~MirroredElemTypes~ match the /kind/
         of the data type the /mirror/ is an instance for.
         * This allows ~Mirror~'s to support /ADTs/ of *all* /kinds/.

       + There is NO distinct representation type for /sums/ or /products/ (ie.
         there is no ~HList~ or ~Coproduct~ type as in Scala 2 versions of shapeless).
           Instead the collection of child types of a data type is represented by
         an ordinary, possibly parameterized, /tuple type/.
         * Dotty's metaprogramming facilities can be used to work with these /tuple
           types/ as-is, and _higher level libraries_ can be *built on top of them*.

       + For both /product/ and /sum/ types, the elements of ~MirroredElemTypes~
         are arranged in *definition order* (i.e. ~Branch[T]~ precedes ~Leaf[T]~ in
         ~MirroredElemTypes~ for ~Tree~ because ~Branch~ is defined _BEFORE_ ~Leaf~
         in the source file).
         * This means that ~Mirror.Sum~ *differs* in this respect from /shapeless's
           generic representation/ for ADTs in Scala 2, where the constructors
           are *ordered alphabetically by name*.

       + The methods ~ordinal~ and ~fromProduct~ are defined in terms of
         ~MirroredMonoType~ which is the type of /kind-*/ which is obtained from
         ~MirroredType~ by *wildcarding* its /type parameters/.

**** TODO Type classes supporting automatic deriving
     - A /trait/ or /class/ can appear in a /derives clause/ if its /companion
       object/ defines a /method/ named ~derived~.

     - The /signature/ and _implementation_ of a /DERIVED method/ for a /type
       class/ ~TC[_]~ are arbitrary but it is typically of the following form,
       #+begin_src scala
         def derived[T](using Mirror.Of[T]): TC[T] = ...
       #+end_src

     - That is, the ~derived~ method takes a /context parameter/ of (some /subtype/
       of) type ~Mirror~ which defines the shape of the /deriving type/ ~T~, and
       computes the /type class/ _implementation_ according to that shape.
         This is all that the provider of an ADT with a ~derives~ _clause_ has to
       know about the _derivation_ of a /type class instance/.

     - Note that ~derived~ methods may have context ~Mirror~ parameters indirectly
       (e.g. by having a context argument which in turn has a context ~Mirror~
       parameter, or not at all (e.g. they might use some completely different
       user-provided mechanism, for instance using Dotty macros or runtime
       reflection). We expect that (direct or indirect) ~Mirror~ based
       implementations will be the most common and that is what this document
       emphasises.

     - Type class authors will most likely use higher level derivation or generic
       programming libraries to implement ~derived~ methods. An example of how a
       derived method might be implemented using only the low level facilities
       described above and Dotty's general metaprogramming features is provided
       below. It is not anticipated that type class authors would normally
       implement a ~derived~ method in this way, however this walkthrough can be
       taken as a guide for authors of the higher level derivation libraries
       that we expect typical type class authors will use (for a fully worked
       out example of such a library, see shapeless 3).

***** TODO How to write a type class ~derived~ method using low level mechanisms
      - The low-level method we will use to implement a type class derived method
        in this example exploits three new type-level constructs in Dotty:
        inline methods, inline matches, and implicit searches via summonInline
        or summonFrom. Given this definition of the Eq type class,
        #+begin_src scala
          trait Eq[T] {
            def eqv(x: T, y: T): Boolean
          }
        #+end_src
        we need to implement a method Eq.derived on the companion object of Eq
        that produces a given instance for Eq[T] given a Mirror[T].

      - Here is a possible implementation,
        #+begin_src scala
          inline given derived[T](using m: Mirror.Of[T]) as Eq[T] = {
            val elemInstances = summonAll[m.MirroredElemType]          // (1)
            inline m match {                                           // (2)
              case s: Mirror.SumOf[T]     => eqSum(s, elemInstances)
              case p: Mirror.ProductOf[T] => eqProduct(p, elemInstances)
            }
          }
        #+end_src

      - Note that derived is defined as an inline given. This means that the method
        will be expanded at call sites (for instance the compiler generated
        instance definitions in the companion objects of ADTs which have a
        derived Eq clause), and also that it can be used recursively if
        necessary, to compute instances for children.

      - The body of this method (1) first materializes the Eq instances for all
        the child types of type the instance is being derived for. This is
        either all the branches of a sum type or all the fields of a product
        type. The implementation of summonAll is inline and uses Dotty's
        summonInline construct to collect the instances as a List,
        #+begin_src scala
          inline def summonAll[T <: Tuple]: List[Eq[_]] = inline erasedValue[T] match {
            case _: Unit      => Nil
            case _: (t *: ts) => summonInline[Eq[t]] :: summonAll[ts]
          }
        #+end_src
        with the instances for children in hand the derived method uses an
        inline match to dispatch to methods which can construct instances for
        either sums or products (2). Note that because derived is inline the
        match will be resolved at compile-time and only the left-hand side of
        the matching case will be inlined into the generated code with types
        refined as revealed by the match.

      - In the sum case, eqSum, we use the runtime ordinal values of the arguments
        to eqv to first check if the two values are of the same subtype of the
        ADT (3) and then, if they are, to further test for equality based on the
        Eq instance for the appropriate ADT subtype using the auxiliary method
        check (4).
        #+begin_src scala
          def eqSum[T](s: Mirror.SumOf[T], elems: List[Eq[_]]): Eq[T] =
            new Eq[T] {
              def eqv(x: T, y: T): Boolean = {
                val ordx = s.ordinal(x)                            // (3)
                                    (s.ordinal(y) == ordx) && check(elems(ordx))(x, y) // (4)
              }
            }
        #+end_src

      - In the product case, ~eqProduct~ we test the runtime values of the arguments
        to ~eqv~ for equality as products based on the ~Eq~ instances for the fields
        of the data type (5),
        #+begin_src scala
          def eqProduct[T](p: Mirror.ProductOf[T], elems: List[Eq[_]]): Eq[T] =
            new Eq[T] {
              def eqv(x: T, y: T): Boolean =
                iterator(x).zip(iterator(y)).zip(elems.iterator).forall {  // (5)
                  case ((x, y), elem) => check(elem)(x, y)
                }
            }
        #+end_src

      - Pulling this all together we have the following complete implementation,
        #+begin_src scala
          import scala.deriving._
          import scala.compiletime.{erasedValue, summonInline}

          inline def summonAll[T <: Tuple]: List[Eq[_]] = inline erasedValue[T] match {
            case _: Unit => Nil
            case _: (t *: ts) => summonInline[Eq[t]] :: summonAll[ts]
          }

          trait Eq[T] {
            def eqv(x: T, y: T): Boolean
          }

          object Eq {
            given Eq[Int] {
              def eqv(x: Int, y: Int) = x == y
            }

            def check(elem: Eq[_])(x: Any, y: Any): Boolean =
              elem.asInstanceOf[Eq[Any]].eqv(x, y)

            def iterator[T](p: T) = p.asInstanceOf[Product].productIterator

            def eqSum[T](s: Mirror.SumOf[T], elems: List[Eq[_]]): Eq[T] =
              new Eq[T] {
                def eqv(x: T, y: T): Boolean = {
                  val ordx = s.ordinal(x)
                  (s.ordinal(y) == ordx) && check(elems(ordx))(x, y)
                }
              }

            def eqProduct[T](p: Mirror.ProductOf[T], elems: List[Eq[_]]): Eq[T] =
              new Eq[T] {
                def eqv(x: T, y: T): Boolean =
                  iterator(x).zip(iterator(y)).zip(elems.iterator).forall {
                    case ((x, y), elem) => check(elem)(x, y)
                  }
              }

            inline given derived[T](using m: Mirror.Of[T]) as Eq[T] = {
              val elemInstances = summonAll[m.MirroredElemTypes]
              inline m match {
                case s: Mirror.SumOf[T]     => eqSum(s, elemInstances)
                case p: Mirror.ProductOf[T] => eqProduct(p, elemInstances)
              }
            }
          }
        #+end_src
        we can test this relative to a simple ADT like so,
        #+begin_src scala
          enum Opt[+T] derives Eq {
            case Sm(t: T)
                case Nn
          }

          object Test extends App {
            import Opt._
            val eqoi = summon[Eq[Opt[Int]]]
            assert(eqoi.eqv(Sm(23), Sm(23)))
            assert(!eqoi.eqv(Sm(23), Sm(13)))
            assert(!eqoi.eqv(Sm(23), Nn))
          }
        #+end_src

      - In this case the code that is generated by the inline expansion for the
        derived Eq instance for Opt looks like the following, after a little
        polishing,
        #+begin_src scala
          given derived$Eq[T](using eqT: Eq[T]) as Eq[Opt[T]] =
            eqSum(summon[Mirror[Opt[T]]],
                  List(
                    eqProduct(summon[Mirror[Sm[T]]], List(summon[Eq[T]]))
                      eqProduct(summon[Mirror[Nn.type]], Nil)
                  )
            )
        #+end_src

      - Alternative approaches can be taken to the way that ~derived~ methods can
        be defined. For example, more aggressively inlined variants using Dotty
        macros, whilst being more involved for type class authors to write than
        the example above, can produce code for type classes like Eq which
        eliminate all the abstraction artefacts (eg. the ~Lists~ of child
        instances in the above) and generate code which is indistinguishable
        from what a programmer might write by hand. As a third example, using a
        higher level library such as shapeless the type class author could
        define an equivalent ~derived~ method as,
        #+begin_src scala
          given eqSum[A](using inst: => K0.CoproductInstances[Eq, A]) as Eq[A] {
            def eqv(x: A, y: A): Boolean = inst.fold2(x, y)(false)(
              [t] => (eqt: Eq[t], t0: t, t1: t) => eqt.eqv(t0, t1)
            )
          }

          given eqProduct[A](using inst: K0.ProductInstances[Eq, A]) as Eq[A] {
            def eqv(x: A, y: A): Boolean = inst.foldLeft2(x, y)(true: Boolean)(
              [t] => (acc: Boolean, eqt: Eq[t], t0: t, t1: t) => Complete(!eqt.eqv(t0, t1))(false)(true)
            )
          }

          inline def derived[A](using gen: K0.Generic[A]) as Eq[A] = gen.derive(eqSum, eqProduct)
        #+end_src

      - The framework described here enables all three of these approaches without
        mandating any of them.

      - For a brief discussion on how to use macros to write a type class derived
        method please read more at How to write a type class derived method using
        macros.

**** DONE Deriving instances elsewhere
     CLOSED: [2020-07-07 Tue 21:58]
     - Sometimes one would like to *derive* a /type class instance/ for an ADT
       after the ADT is defined, WITHOUT being able to change the code of the ADT
       itself.
       + To do this, simply define an instance using the ~derived~ /method/ of
         the /type class/ as right-hand side.

       + E.g, to implement ~Ordering~ for ~Option~ define,
         #+begin_src scala
           given [T: Ordering] as Ordering[Option[T]] = Ordering.derived
         #+end_src

     - Assuming the ~Ordering.derived~ /method/ has a /context parameter/ of /type/
       ~Mirror[T]~ it will be satisfied by the compiler generated ~Mirror~ /instance/
       for ~Option~ and the /derivation/ of the /instance/ will be expanded on the
       right hand side of this definition in the same way as an instance defined
       in ADT /companion objects/.

**** TODO Syntax
**** TODO Discussion
     - This _/type class/ derivation framework_ is *INTENTIONALLY* very *small* and
       *low-level*.

     - There are essentially *TWO* pieces of infrastructure in *compiler-generated
       ~Mirror~ instances*,
       + /type members/ encoding properties of the /mirrored types/.

       + a MINIMAL value level mechanism for working generically with terms of the
         /mirrored types/.

     - The ~Mirror~ infrastructure can be seen as an extension of the existing
       ~Product~ infrastructure for /case classes/: typically ~Mirror~ types
       will be implemented by the ADTs /companion object/, hence the /type members/
       and the ~ordinal~ or ~fromProduct~ /methods/ will be members of that object.
       + The primary motivation for this design decision, and the decision to encode
         properties via types rather than terms was to keep the bytecode and
         runtime footprint of the feature small enough to make it possible to
         provide ~Mirror~ instances *unconditionally*.

     - Whilst ~Mirrors~ encode properties precisely via type members, the value
       level ~ordinal~ and ~fromProduct~ are somewhat weakly typed (because they
       are defined in terms of ~MirroredMonoType~) just like the members of ~Product~.
       This means that code for generic type classes has to ensure that type
       exploration and value selection proceed in lockstep and it has to assert
       this conformance in some places using casts. If generic type classes are
       correctly written these casts will never fail.

     - As mentioned, however, the compiler-provided mechanism is intentionally very
       low level and it is anticipated that higher level type class derivation
       and generic programming libraries will build on this and Dotty's other
       metaprogramming facilities to hide these low-level details from type
       class authors and general users.
         _/Type class/ derivation_ in the style of both shapeless and Magnolia are
       possible (a prototype of shapeless 3, which combines aspects of both
       shapeless 2 and Magnolia has been developed alongside this language
       feature) as is a more aggressively inlined style, supported by Dotty's
       new quote/splice macro and inlining facilities.

*** DONE Multiversal Equality - TODO =RE-READ=
    CLOSED: [2020-05-23 Sat 23:31]
    - /Universal equality/ is *convenient*.
      _BUT_ it is also dangerous since it *undermines* /type safety/.

    - /Multiversal equality/ is an _opt-in way_ to make /universal equality/ SAFER.
        It uses a /binary type class/ ~Eql~ to indicate that values of *two* given
      /types/ can be compared with each other.

    - If we want to disable /universal equality/ check for ~T~, we can do
      #+begin_src scala
        class T derives Eql

        val x = ...  // of type T
        val y = ...  // of type S, but should be T
        x == y       // can't typecheck because T drevies the type class Eql
      #+end_src

    - Alternatively, one can also provide an ~Eql~ /given instance/ directly,
      like this:
      #+begin_src scala
        given Eql[T, T] = Eql.derived
      #+end_src
      This definition effectively says that values of type ~T~ can (only) be compared
      to other values of type ~T~ when using ~==~ or ~!=~.
      + The definition
        * _affects_ /type checking/
        * BUT it has _no significance_ for /runtime/ behavior,
          since
          - ~==~ always maps to ~equals~
          - ~!=~ always maps to the negation of ~equals~

      + The right hand side ~Eql.derived~ of the definition is a value that has
        any ~Eql~ instance as its type.
          Here is the definition of /class/ ~Eql~ and its /companion object/:
        #+begin_src scala
          package scala
          import annotation.implicitNotFound

          @implicitNotFound("Values of types ${L} and ${R} cannot be compared with == or !=")
          sealed trait Eql[-L, -R]

          object Eql {
            object derived extends Eql[Any, Any]
          }
        #+end_src

    - One can have *several* ~Eql~ /given instances/ for one type.

    - The ~scala.Eql~ object defines a number of ~Eql~ /given instances/ that
      together define a rule book for what standard types can be compared
      (TODO: more details below).

    - There's also a *"fallback" instance* named ~eqlAny~ that allows comparisons
      over *ALL* /types/ that do not themselves have an ~Eql~ /given/. ~eqlAny~ is
      defined as follows:
      #+begin_src scala
        def eqlAny[L, R]: Eql[L, R] = Eql.derived
      #+end_src
      + Even though ~eqlAny~ is _NOT_ declared a ~given~,
        the compiler will still construct an ~eqlAny~ instance as answer to an
        /implicit search/ for the type ~Eql[L, R]~, _UNLESS_:
        * ~L~ or ~R~ have ~Eql~ instances defined on them,
          OR
        * the language feature ~strictEquality~ is _enabled_

      + The *primary motivation* for having ~eqlAny~ is _backwards compatibility_.

      + If no concern to _backwards compatibility_, we can disable ~ealAny~ in
        two ways:
        * ~import scala.language.strictEquality~
        * a command line option ~-language:strictEquality~

**** DONE Deriving ~Eql~ Instances
     CLOSED: [2020-05-23 Sat 22:31]
     ~class Box[T](x: T) derives Eql~
     - By the usual rules of /type class derivation/, this generates the following
       ~Eql~ instance in the companion object of ~Box~:
       #+begin_src scala
         given [T, U](using Eql[T, U]) as Eql[Box[T], Box[U]] = Eql.derived
       #+end_src

     - Examples:
       #+begin_src scala
         new Box(1) == new Box(1L)   // ok since there is an instance for `Eql[Int, Long]`
         new Box(1) == new Box("a")  // error: can't compare
         new Box(1) == 1             // error: can't compare
       #+end_src

**** DONE Precise Rules for Equality Checking - TODO
     CLOSED: [2020-05-23 Sat 23:30]
     - If the ~strictEquality~ feature is enabled then a comparison using
       ~x \equal{}\equal{} y~ or ~x != y~ between values ~x: T~ and ~y: U~ is _legal if there
       is a given of type ~Eql[T, U]~._

     - In the default case where the ~strictEquality~ feature is _NOT enabled_
       the comparison is also legal if
       1. ~T~ and ~U~ are the _same_
          OR
       2. one of ~T~, ~U~ is a /subtype/ of the /lifted version of the other type/,
          OR
       3. neither ~T~ nor ~U~ have a reflective ~Eql~ instance.

     - Explanations: TODO ??? TODO
       =from Jian= This sentence has something wrong for the /lifting/.
       + /lifting/ a type ~S~ means
         * *replacing* ALL _references to abstract types_ in /covariant positions/
           of ~S~ by their /upper bound/,

           and to

         * *replacing* ALL /refinement types/ in /covariant positions/ of ~S~ by
           _their parent_.

       + a type ~T~ has a _reflexive_ ~Eql~ instance if the _implicit search_ for
         ~Eql[T, T]~ succeeds.

**** DONE Predefined ~Eql~ Instances
     CLOSED: [2020-05-23 Sat 22:31]
     - The ~Eql~ object defines instances for comparing
       + the /primitive types/
         * ~Byte~
         * ~Short~
         * ~Char~
         * ~Int~
         * ~Long~
         * ~Float~
         * ~Double~
         * ~Boolean~
         * ~Unit~,

       + ~java.lang.Number~
       + ~java.lang.Boolean~
       + ~java.lang.Character~

       + ~scala.collection.Seq~
       + ~scala.collection.Set~

     - Instances are defined so that every one of the types mentioned above has
       /a *reflexive* ~Eql~ instance/, and the following holds:
       + /Primitive numeric types/ can be compared with _each other_.

       + /Primitive numeric types/ can be compared with *subtypes* of
         ~java.lang.Number~ (and _vice versa_).

       + ~Boolean~ can be compared with ~java.lang.Boolean~ (and _vice versa_).

       + ~Char~ can be compared with ~java.lang.Character~ (and _vice versa_).

       + Two /sequences/ (of *arbitrary subtypes* of ~scala.collection.Seq~) can
         be compared with _each other_ *if their element types can be compared.*
         The two sequence types need not be the same.

       + Two /sets/ (of *arbitrary subtypes* of ~scala.collection.Set~) can be
         compared with _each other_ *if their element types can be compared.*
         The two set types need not be the same.

       + Any /subtype/ of ~AnyRef~ can be compared with ~Null~ (and _vice versa_).

**** TODO Why Two Type Parameters?

*** TODO Context Functions - TODO 1
    - Context functions :: functions with (_ONLY_) /context parameters/.
      + Their types are /context function types/.
      + /Context functions/ are written using ~?=>~ as the "arrow" sign

    - Example:
      #+begin_src scala
        type Executable[T] = ExecutionContext ?=> T

        given ec as ExecutionContext = ...

        def f(x: Int): ExecutionContext ?=> Int = ...
        // could be written as follows with the type alias from above
        // def f(x: Int): Executable[Int] = ...

        f(2)(using ec)  // explicit argument
        f(2)            // argument is inferred
      #+end_src

    - Conversely,
      + IF ::
        * the *EXPECTED* type of an expression ~E~ is a /context function type/
          ~(T_1, ..., T_n) ?=> U~
          - =from Jian=
            What is the relation between ~E~ and ~U~ (of course, the simplest
            case is ~E~ =:= ~U~)??? From the example below, it seems the the
            only restriction is ~U~ can be converted to ~E~ with the help of
            /givens/.
          AND
        * ~E~ *is NOT ALREADY* an /context function literal/,

      + ~E~ *is converted to* a /context function literal/ by *rewriting it to*
        #+begin_src scala
          (using x_1: T1, ..., x_n: Tn) => E
        #+end_src
        where the names ~x_1, ..., x_n~ are ARBITRARY. This expansion is performed
        *before* the expression ~E~ is typechecked, which means _that ~x_1, ...,
        x_n~ are available as /givens/ in ~E~._

    - LIKE their /types/,
      /context function literals/ are written using ~?=>~ as the arrow between
      parameters and results.
        They *DIFFER from* /normal function literals/ in that their types are
      /context function types/.

    - For example, continuing with the previous definitions,
      #+begin_src scala
        def g(arg: Executable[Int]) =  // ...

        g(22)    // is expanded to g((using ev: ExecutionContext) => 22)
        g(f(2))  // is expanded to g((using ev: ExecutionContext) => f(2)(using ev))

        g(ExecutionContext ?=> f(3))  // is expanded to g((using ev: ExecutionContext) => f(3)(using ev))
        g((using ctx: ExecutionContext) => f(22)(using ctx))  // is left as it is
      #+end_src

**** Example: Builder Pattern
     #+begin_src scala

     #+end_src
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO

**** Example: Postconditions
     #+begin_src scala
       object PostConditions {
         opaque type WrappedResult[T] = T

         def result[T](using r: WrappedResult[T]): T = r

         def [T] (x: T).ensuring(condition: WrappedResult[T] ?=> Boolean): T = {
           assert(condition(using x))
           x
         }
       }

       import PostConditions.{ensuring, result}

       val s = List(1, 2, 3).sum.ensuring(result == 6)
     #+end_src
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO
     - TODO ??? TODO

**** Reference

*** DONE Implicit Conversions
    CLOSED: [2020-03-11 Wed 00:14]
    /Implicit conversions/ are defined by /given instances/ of the
    ~scala.Conversion~ class.

    - ~scala.Conversion~ class is defined in package scala as follows:
      #+begin_src scala
        abstract class Conversion[-T, +U] extends (T => U)
      #+end_src

    - Example:
      #+begin_src scala
        given Conversion[String, Token] {
          def apply(str: String): Token = new KeyWord(str)
        }
      #+end_src
      + Express more concisely as:
        #+begin_src scala
          given Conversion[String, Token] = new KeyWord(_)
        #+end_src

    - An /implicit conversion/ is applied automatically by the compiler in _THREE_
      situations:
      + _Type_ doesn't match, but an after an /implicit conversion/, type can match.

      + _Method Name_ doesn't match, but an after an /implicit conversion/, method
        can be found.

      + _Method Name matches, but Method Signature doesn't match_, but an after
        an /implicit conversion/, /method signature/ can match.

**** Examples
     1. In ~Predef~
        #+begin_src scala
          given int2Integer as Conversion[Int, java.lang.Integer] =
            java.lang.Integer.valueOf(_)
        #+end_src

     2. /Magnet pattern/ that use /implicit conversion/:
        #+begin_src scala
          object Completions {

            // The argument "magnet" type
            enum CompletionArg {
              case Error(s: String)
              case Response(f: Future[HttpResponse])
              case Status(code: Future[StatusCode])
            }

            object CompletionArg {

              // conversions defining the possible arguments to pass to `complete`
              // these always come with CompletionArg
              // They can be invoked explicitly, e.g.
              //
              //   CompletionArg.fromStatusCode(statusCode)

              given fromString     as Conversion[String, CompletionArg]               = Error(_)
              given fromFuture     as Conversion[Future[HttpResponse], CompletionArg] = Response(_)
              given fromStatusCode as Conversion[Future[StatusCode], CompletionArg]   = Status(_)
            }

            import CompletionArg._

            def complete[T](arg: CompletionArg) = arg match {
              case Error(s)     => ...
              case Response(f)  => ...
              case Status(code) => ...
            }
          }
        #+end_src
        + =from Jian= Why does ~complete~ have a /type parameter/ ~T~.

        + This setup is more complicated than simple overloading of ~complete~ (the
          traditional way of implementing the /magnet pattern/),
          BUT it can still be useful
          * *if normal /overloading/ is not available* (as in the case above, since
            we cannot have two overloaded methods that take ~Future[...]~ arguments),
            =from Jian= ??? /Type erasure/ ???
            _OR_
          * if normal overloading would lead to a _combinatorial explosion of variants_.

*** DONE By-Name Context Parameters - TODO =RE-READ= TODO
    CLOSED: [2020-05-23 Sat 00:01]
    =from Jian= This section discussion the /LAZY context parameters/.

    - /Context parameters/ can be DECLARED /by-name/ to *avoid* a /divergent inferred
      expansion/.

    - Example:
      #+begin_src scala
        trait Codec[T] {
          def write(x: T): Unit
        }

        given intCodec as Codec[Int] = ???

        given optionCodec[T](using ev: => Codec[T]) as Codec[Option[T]] {
          def write(xo: Option[T]) = xo match {
            case Some(x) => ev.while(x)
            case None    =>
          }

          // TODO: from Jian: can this work for "by-name context parameters"
          // def write(xo: Option[T]) =
          //  xo.map(ev.write)
        }

        val s = summon[Codec[Option[Int]]]

        s.write(Some(33))
        s.write(None)
      #+end_src
      + As is the case for a normal (non-context parameter) /by-name parameter/,
        the argument for the /context parameter/ ~ev~ is evaluated on demand.
          In the example above, if the ~xo~ is ~None~, it is *NOT* evaluated at all.

    - TODO ??? TODO -- =Try to understand this=
      The /synthesized argument/ for a /context parameter/
      is backed by a _LOCAL_ ~val~
      if this is necessary to prevent an otherwise /diverging expansion/.

    - The precise steps for /synthesizing an argument/ for a /by-name context
      parameter/ of type ~=> T~ are as follows: TODO ??? TODO
      1. Create a new /given/ of type ~T~:
         #+begin_src scala
           given lv as T = ???
         #+end_src
         where ~lv~ is an arbitrary fresh name.

      2. This /given/ is not immediately available as candidate for argument
         inference (making it immediately available could result in a loop in
         the synthesized computation). But it becomes available in all nested
         contexts that look again for an argument to a /by-name context parameter/.

      3. If this search succeeds with expression ~E~, and ~E~ contains references
         to ~lv~, replace ~E~ by
         #+begin_src scala
           { given lv as T = E; lv }
         #+end_src
         Otherwise, return ~E~ unchanged.

    - In the example above, the definition of s would be *EXPANDED* as follows.
      #+begin_src scala
        val s = summon[Test.Codec[Option[Int]]](
          optionCodec[Int](using intCodec)
        )
      #+end_src
      /No local given instance/ was generated because _the /synthesized argument/
      is *not* /recursive/._

**** TODO Reference
     For more info, see
     - Issue _#1998: Let by-name implicit parameters have lazy semantics_
       and the associated
     - _SIP-NN - BYNAME IMPLICIT ARGUMENTS_.

*** TODO Relationship with Scala 2 Implicits - TODO 3
    Many, but *NOT all*, of the _Scala 3's NEW /contextual abstraction/ features_
    can be mapped to _Scala 2's /implicits/._

    This page gives a rundown on the relationships between new and old features.

**** TODO Simulating Scala 3 Contextual Abstraction Concepts with Scala 2 Implicits
***** Given Intances
      - /Given instances/ can be mapped to _COMBINATIONS_ of /implicit objects/,
        /classes/ and /implicit methods/.
        1. /Given instances without parameters/ ---> /implicit objects/.
           #+begin_src scala
             // Dotty
             given intOrd as Ord[Int] { ... }

             // Scala 2
             implicit object IntOrd extends Ord[Int] { ... }
           #+end_src

        2. /Parameterized givens/ ---> COMBINATIONS of /classes/ and /implicit methods/.
           #+begin_src scala
             // Dotty
             given listOrd[T](using ord: Ord[T]) as Ord[List[T]] { ... }

             // Scala 2
             class ListOrd[T](implicit ord: Ord[T]) extends Ord[List[T]] { ... }
             final implicit def ListOrd[T](implicit ord: Ord[T]): ListOrd[T] = new ListOrd[T]
           #+end_src

        3. /Alias givens/ map to /implicit methods/ OR /implicit lazy vals/.
           #+begin_src scala
             given global as ExecutionContext = new ForkJoinContext()

             val ctx: Context
             given Context = ctx
           #+end_src

           would map to

           #+begin_src scala
             final implicit lazy val global: ExecutionContext = new ForkJoinContext()
             final implicit def given_Context = ctx
           #+end_src
           + If an alias has _NEITHER /type parameters/ NOR /context parameters/,_
             it is treated as a ~lazy val~,
             * unless the right hand side is a simple reference, in which case we
               can use a forwarder to that reference without caching it.

***** DONE Anonymous Given Intances
      CLOSED: [2020-05-24 Sun 01:18]
      /Anonymous given instances/ get *compiler synthesized* NAMES,
      which are generated _in a reproducible way FROM the implemented type(s)._
      - Examples:
        #+begin_src scala
          // given Ord[Int] { ... }
          given given_Ord_Int as Ord[Int] { ... }

          // given[T](using Ord[T]) as Ord[List[T]] { ... }
          given given_Ord_List_T[T](using ord: Ord[T]) as Ord[List[T]] { ... }
        #+end_src

      - The synthesized type names are formed from
        + the prefix ~given_~,
        + the simple name(s) of the implemented type(s), leaving out any prefixes,
        + the simple name(s) of the toplevel argument type constructors to these types.

      - /Tuples/ are treated _as transparent_,
        i.e. a type ~F[(X, Y)]~ would get the synthesized name ~F_X_Y~.

      - *Directly implemented* /function types/ ~A => B~ are represented as ~A_to_B~.

      - /Function types/ used as arguments to OTHER /type constructors/ are
        represented as ~Function~.
        TODO Example??? TODO

***** DONE Anonymous Collective Extensions
      CLOSED: [2020-05-24 Sun 01:23]
      - /Anonymous collective extensions/ also get compiler synthesized names,
        which are formed from
        1. the prefix ~extension_~

        2. the name of the *first* defined /extension method/

        3. the simple name of the *first* /parameter type/ of this (*first*)
          /extension method/

        4. the simple name(s) of the toplevel argument type constructors to this type.

      - For example, the extension
        #+begin_src scala
          extension on [T](xs: List[T]) {
            def second = ...
          }
        #+end_src
        gets the synthesized name ~extension_second_List_T~.

***** DONE Given Clauses
      CLOSED: [2020-05-24 Sun 01:35]
      =from Jian= Why not call it =Using Clauses=
      - /Given clauses/ correspond largely to Scala-2's /implicit parameter clauses/.
        E.g.
        #+begin_src scala
          // Dotty
          def max[T](x: T, y: T)(using ord: Ord[T]): T

          // Scala 2
          def max[T](x: T, y: T)(implicit ord: Ord[T]): T
        #+end_src

      - _The main difference concerns applications of such parameters._
        + Dotty:
          Explicit arguments to parameters of /using clauses/ must be written as
          ~(using ...)~, *mirroring the definition syntax*.
          E.g, ~max(2, 3)(using IntOrd)~.

        + Scala 2:
          uses normal applications ~max(2, 3)(IntOrd)~ instead.

        + SUMMARY:
          The /Scala 2 syntax/ has some _inherent ambiguities_ and _restrictions_
          which are *overcome by the NEW (Dotty) syntax*. For instance,
          * /multiple implicit parameter lists/ are _NOT available in the *old*
            syntax_, even though they can be TODO _simulated using /auxiliary
            objects/ in the "Aux" pattern -- check /Shapeless/._

      - The ~summon~ method corresponds to ~implicitly~ in Scala 2.
        *It is _PRECISELY_ the SAME as the the method in Shapeless.*
        The difference between ~summon~ (or ~the~) and ~implicitly~ is that
        ~summon~ can return a *MORE _PRECISE_ type* than the type that was asked for. TODO ???

***** DONE Context Bounds
      CLOSED: [2020-05-24 Sun 01:36]
      /Context bounds/ are the *same* in both language versions.
      They *expand* to the respective forms of /implicit parameters/.

***** Extension Methods
***** Type class Derivation
***** Implicit Function Types
***** Implicit By-Name Parameters

**** TODO Simulating Scala 2 Implicits in Scala 3
***** Implicit Conversions
***** Implicit Classes
***** Implicit Values
***** Abstract Implicits

**** TODO Implementation Status and Timeline

** TODO METAPROGRAMMING
*** DONE Overview - =TODO= =RE-READ=
    CLOSED: [2020-06-24 Wed 03:50]
    The following pages introduce the *redesign* of /metaprogramming/ in Scala.
    The following fundamental facilities:
    1. /Inline/
       ~inline~ is a new /soft modifier/ that *guarantees* that a definition will
       be inlined at the point of use.

       - The primary motivation:
         *reduce the overhead* behind
         + _function calls_
         + _access to values_.

       - The _expansion_ will be performed by the Scala compiler _during the *Typer*
         /compiler phase/._

       - ~inline~ is a *COMMAND* (*MUST DO*) to the *compiler*.
           This is _DIFFERENT_ from some other ecosystems, in which /inline/ is a
         request that _might be_ satisfied by the compiler.
         + The _REASON_:
           /inlining/ in Scala can drive other _compile-time operations_, like
           * /inline pattern matching/ (enabling /type-level programming/)

           * /macros/ (enabling /compile-time, generative, metaprogramming/)

           * /runtime code generation/ (/multi-stage programming/)
             - =from Jian=
               WHY this is considered as one kind of drive othe _compile-time
               operations_.

    2. /Macros/ construct code at /compile-time/
       - /Macros/ are built on _TWO_ well-known fundamental operations:
         + quotation :: *convert program code to data*, specifically, a (tree-like)
           representation of this code.
           * It is expressed as
             - ~'{...}~ for /expressions/
             - ~'[...]~ for /types/

         + splicing :: *convert a program's representation to program code*
           * expressed as ~${ ... }~.

       - Together with ~inline~, _these two abstractions_ allow to construct
         program code programmatically.

    3. =TODO=
       /Staging/ construct new code at /runtime/.
       That way, code generation can depend not only on static data but also on
       data available at runtime. This splits the evaluation of the program in
       two or more phases or ... /stages/.
         Consequently, this method generative programming is called /"Multi-Stage
       Programming"/. /Staging/ is built on the _SAME_ foundations as /macros/.
       It uses /quotes/ and /splices/, but _LEAVES OUT_ /inline/.

    4. =TODO=
       /TASTy Reflection/
       + /Quotations/ are a "black-box" representation of code.
         They can be parameterized and composed using /splices/ but their
         structure cannot be analyzed from the outside.
       + /Tasty reflection/ gives a way to analyze code structure by partly
         revealing the representation type of a piece of code in a standard API.
         TODO
         The _representation type_ is a form of /typed abstract syntax tree/,
         which gives rise to the "TASTy` moniker.

    5. =TODO=
       /TASTy Inspection/
       /Typed abstract syntax trees/ are serialized in a custom compressed
       binary format in =.tasty= files. /TASTy inspection/ allows to _load_
       these files and _analyze_ their content's tree structure.

*** DONE Inline
    CLOSED: [2020-05-26 Tue 04:23]
**** DONE Inline Definitions
     CLOSED: [2020-03-11 Wed 00:43]
     - ~inline~ :: a new /soft modifier/ that *guarantees* that a definition will
                   be inlined at the point of use.
     - Example:
       #+begin_src scala
         object Config {
           inline val logging = false
         }

         object Logger {
           private var indent = 0

           inline def log[T](msg: String, indentMargin: =>Int)(op: => T): T =
             if (Config.logging) {
               println(s"${"  " * indent}start $msg")
               indent += indentMargin
               val result = op
               indent -= indentMargin
               println(s"${"  " * indent}$msg = $result")
               result
             }
             else op
         }
       #+end_src
       + The ~Config~ object contains a definition of the /inline value/ ~logging~.
         This means that ~logging~ is treated as a _constant value_, equivalent to
         its RHS ~false~. The RHS of such an ~inline val~ must itself be a
         /constant expression/.
         * Used in this way, ~inline~ is *equivalent to* Java and Scala 2's ~final~.
           =IMPORTANT=
           Note that ~final~, meaning /inlined constant/,
           - is still supported in Dotty,
           - but *will be Phased Out*.

       + The ~Logger~ object contains a definition of the /inline method/ ~log~.
         This method will always _be inlined at the point of call_.

       + Usage and re-write:
         #+begin_src scala
           var indentSetting = 2

           def factorial(n: BigInt): BigInt = {
             log(s"factorial($n)", indentSetting) {
               if (n == 0) 1
               else        n * factorial(n - 1)
             }
           }
         #+end_src

         - With current definition ~inline val logging = false~,
           The usage code will be re-written as
           #+begin_src scala
             def factorial(n: BigInt): BigInt = {
               if (n == 0) 1
               else        n * factorial(n - 1)
             }
           #+end_src

         - If the example code define ~inline val logging = true~, then the
           usage code will be re-written as
           #+begin_src scala
             def factorial(n: BigInt): BigInt = {
               val msg = s"factorial($n)"
               println(s"${"  " * indent}start $msg")
               Logger.inline$indent_=(indent.+(indentSetting))
               val result =
                 if (n == 0) 1
                 else        n * factorial(n - 1)
               Logger.inline$indent_=(indent.-(indentSetting))
               println(s"${"  " * indent}$msg = $result")
               result
             }
           #+end_src
           NOTE:
           + The /by-value parameter/ ~msg~ is _evaluated only once_,
             per the usual Scala semantics, by binding the value and reusing the
             ~msg~ through the body of ~factorial~.

           + The special handling of the assignment to the ~private var indent~.
             It is achieved by *generating* a /setter method/ ~def
             inline$indent_=~ and calling it instead.

**** DONE Recursive Inline Methods
     CLOSED: [2020-05-25 Mon 18:22]
     /Inline methods/ can be *recursive*.
     - For instance, when called with a *constant* exponent ~n~, the following method
       for ~power~ will be implemented by straight inline code *WITHOUT ANY
       /loop/ or /recursion/.*
       #+begin_src scala
         inline def power(x: Double, n: Int): Double = {
           if (n == 0) 1.0
           else if (n == 1) x
           else {
             val y = power(x, n / 2)
             if (n % 2 == 0) y * y else y * y * x
           }
         }

         power(expr, 10)
         // translates to
         //
         //    val x = expr
         //    val y1 = x * x   // ^2
         //    val y2 = y1 * y1 // ^4
         //    val y3 = y2 * x  // ^5
         //    y3 * y3          // ^10
       #+end_src

     - There also can be /inline parameters/.
       - =from Jian=
         The /by-name parameters/ in the context of this whole document is actually
         /by-need parameters/. This is the common implementation in all the practical
         programming languages.

       - =from Jian=
         /Inline parameters/ have call semantics *equivalent* to /naive by-name parameters/
         -- no caching.
           It is usually useful when /constant values/ need to be propagated to
         allow further optimizations/reductions. TODO ??? TODO

     - The difference in translation between /by-value/, /by-name/, and ~inline~
       parameters:
       #+begin_src scala
         inline def funkyAssertEquals(actual: Double,
                                      expected: =>Double,
                                      inline delta: Double): Unit =
           if ((actual - expected).abs > delta)
             throw new AssertionError(s"difference between ${expected} and ${actual} was larger than ${delta}")

         funkyAssertEquals(computeActual(), computeExpected(), computeDelta())
         // translates to
         //
         //    val actual = computeActual()
         //    def expected = computeExpected()
         //    if (actual - expected).abs > computeDelta() then
         //      throw new AssertionError(s"difference between ${expected} and ${actual} was larger than ${computeDelta()}")
       #+end_src
       + You can see the ~inline~ parameter here is actually a /NAIVE by-name
         parameter/. The /by-name parameter/ here is a /non-naive by-name parameter/,
         and people often call it /by-need parameter/.
         =from Jian= this manual doesn't mention the term /by-name parameter/.

**** DONE Rules for Overriding
     CLOSED: [2020-05-25 Mon 18:41]
     /Inline methods/ can *override* other /non-inline methods/.
     The rules are as follows:
     1. If an /inline method/ ~f~ implements or *overrides* another, /non-inline
        method/, the /inline method/ *can also be invoked at /runtime/.*
        For instance, consider the scenario:
        #+begin_src scala
          abstract class A {
            def f: Int
            def g: Int = f
          }

          class B extends A {
            inline def f = 22
            override inline def g = f + 11
          }

          val b = B
          val a: A = b

          // inlined invocations
          assert(b.f() == 22)
          assert(b.g() == 33)

          // dynamic invocations
          assert(a.f() == 22)
          assert(a.g() == 33)
        #+end_src
        The /inlined invocations/ and the /dynamically dispatched invocations/
        give the _SAME_ results.

     2. /Inline methods/ are effectively ~final~.

     3. /Inline methods/ can also be ~abstract~.
          An /abstract inline method/ can be _implemented_ ONLY by other /inline
        methods/. *It cannot be invoked directly*:
        #+begin_src scala
          abstract class A {
            inline def f: Int
          }

          object B extends A {
            inline def f: Int = 22
          }

          B.f  // OK
          val a: A = B
          a.f  // error: cannot inline `f` in `A`.
        #+end_src

**** DONE Relationship to ~@inline~
     CLOSED: [2020-05-25 Mon 19:11]
     - Scala also defines a ~@inline~ annotation which is used as _a *hint* for the
       BACKEND to inline._

     - The ~inline~ modifier is a _MORE POWERFUL_ than the ~@inline~ annotation.
       + ~@inline~ annotation ::
         * A _hint_
           - _Hint_ here means _try with *BEST EFFORT*, *but NOTHING guaranteed*!_

         * The _hint_ is for the *backend*


       + ~inline~ /modifier/ ::
         * A _command_
           - _Command_ here means _GUARANTEED!_

         * The _command_ is for the *frontend*

         * it also applies to /recursive methods/.

       + Cross compilation between Dotty and Scala 2:
         + Introduce ~@forceInline~ in Dotty.
           * For dotc it is the same as ~inline~.
           * For scalac it will be ignored.

         + Usage:
           Always use ~@forceInline @inline~ if cross compilation between Dotty
           and Scala 2 is required. This can make
           * Scala 2 ignores the ~@forceInline~ annotation, so one must use both
             annotations o guarantee inlining for Dotty and at the same time hint
             inline for Scala 2 (i.e. ~@forceInline @inline~)
             - =from Jian=
               My understanding: TODO ??? TODO =re-read= this summary
               When the ~@forceInline~ show up in Dotty code, it is considered as
               ~inline~. However, this is not enough if we want use this code from
               Scala 2 with _inline_ applied -- Scala 2 ignores ~@forceInline~.
                 This means it's better to use ~@forceInline @inline~ in Dotty, if
               you want to use this code can be used in Scala 2.
                 Still with ~@forceInline @inline~, it is possbile that the code
               at the Scala 2 call sites may not be _inlined_.

***** The definition of constant expression
      Scala Language Specification 2.13 - _6.24 Constant Expressions_
      - An /inline value/ *must* have a /literal type/ such as ~1~ or ~true~.
        #+begin_src scala
          inline val four = 4

          // Equivalent to

          inline val four: 4 = 4
        #+end_src

      - It is also possible to have _inline vals_ of /types/ that do not have a
        syntax, such as ~Short(4)~.
        #+begin_src scala
          trait InlineConstant {
            inline val myShort: Short
          }

          object Constants extends InlineConstants {
            inline val myShort/*: Short(4)*/ = 4
          }
        #+end_src

**** DONE Transparent Inline Methods
     CLOSED: [2020-05-25 Mon 19:21]
     /Inline methods/ can additionally be declared ~transparent~.
       This means that the /return type/ of the /inline method/ can be
     *SPECIALIZED to a more precise type* upon expansion.

     - Example:
       #+begin_src scala
         class A

         class B extends A {
           def m() = true
         }

         transparent inline def choose(b: Boolean): A =
           if b then new A() else new B()

         val obj1 = choose(true)  // static type is A
         val obj2 = choose(false) // static type is B

         // obj1.m() // compile-time error: `m` is not defined on `A`
         obj2.m()    // OK
       #+end_src

     - A *non-transparent* /inline method/ is a *"blackbox"* in the sense that
       details of its implementation do *not leak out.*

     - /Transparent inline methods/ are *"whitebox"* in the sense that the type
       of an application of such a method can be _more specialized than its
       DECLARED /return type/,_ depending on how the method expands.

     - Example:
       we see how the return type of zero is *specialized* to the /singleton
       type/ ~0~ permitting the addition to be ascribed with the correct
       /singleton type/ ~1~.
       #+begin_src scala
         transparent inline def Zero: Int = 0
         val one: 1 = zero() + 1
       #+end_src

**** DONE Inline Conditionals
     CLOSED: [2020-05-26 Tue 00:44]
     #+begin_src scala
       inline def update(delta: Int) =
         inline if (delta >= 0) increaseBy(delta)
                else            decreaseBy(-delta)
     #+end_src
     - If the /condition/ of an /if-then-else expressions/ is a /constant expression/
       then it _simplifies to the selected branch._ -- *NOT guaranteed*.

     - Prefix an /if-then-else expression/ with ~inline~ *enforces* that the
       /condition/ has to be a /constant expression/, and thus *guarantees* that
       the conditional _will *always* simplify_.

     - Use ~inline~ means, for legal code, in the call site ~delta~ _MUST be_ a
       /compile-time constant/.

     - A call ~update(22)~ would re-write to ~increaseBy(22)~.

     - A call with a value of *not* /compile-time constant/ will trigger a
       /compile error/:
       #+begin_src text
            |  inline if (delta >= 0) ???
            |  ^
            |  cannot reduce inline if
            |   its condition
            |     delta >= 0
            |   is not a constant value
            | This location is in code that was inlined at ...
       #+end_src

**** DONE Inline Matches
     CLOSED: [2020-05-26 Tue 02:06]
     - A /match expression/ _in the body_ of an /inline method definition/ _may be_
       prefixed by the ~inline~ modifier.
       + If there is *ENOUGH* _STATIC information_ to _unambiguously take a branch_,
         the expression is *reduced* to that branch and the type of the result
         is taken.

       + If not, a /compile-time error/ is raised that reports that the match cannot
         be reduced.

     - The example below defines an /inline method/ with a single /inline match
       expression/ that picks a case based on its /static type/:
       #+begin_src scala
         transparent inline def g(x: Any): Any = inline x match {
           case x: String => (x, x)  // Tuple2[String, String](x, x)
           case x: Double => x
         }

         g(1.0d)    // Has type `1.0d` which is a subtype of `Double`
         g("test")  // Has type `(String, String)`
       #+end_src

     - The scrutinee ~x~ is *examined statically* and the /inline match/ is
       *reduced* accordingly returning the corresponding value (with the /type
       specialized/ because ~g~ is declared ~transparent~).

     - The /type/ can have a _richer_ structure like the _simple_ /ADT/ below.
       ~toInt~
       1. _matches_ the structure of a number in /Church-encoding/
          AND
       2. _computes_ the corresponding integer.
       #+begin_src scala
         enum Nat {
           case Zero
           case Succ[N <: Nat](n: N)
         }

         transparent inline def toInt(n: Nat): Int = inline n match {
           case Nat.Zero     => 0
           case Nat.Succ(n1) => toInt(n1) + 1
         }

         inline val natTwo = toInt(Nat.Succ(Nat.Succ(Nat.Zero)))
         val intTwo: 2 = natTwo
       #+end_src
       ~natTwo~ is inferred to have the /singleton type/ ~2~
       (=from Jian= since here we have the ~transparent~)

**** DONE The ~scala.compiletime~ Package
     CLOSED: [2020-05-26 Tue 02:27]
     The ~scala.compiletime~ package contains _helper definitions_ that provide
     support for /compile time/ OPERATIONS over _values_.
     They are described in the following.
***** ~constValue~, ~constValueOpt~, and the ~S~ combinator
      - ~constValue[T]~ generate a _constant value_ of the /singleton type/ ~T~
        #+begin_src scala
          import scala.compiletime.{constValue, S}

          transparent inline def toIntC[N]: Int =
            inline constValue[N] match {
              case 0        => 0
              case _: S[n1] => 1 + toIntC[n1]
            }

          inline val ctwo = toIntC[2]
        #+end_src

      - ~constValueOpt[T]~ is similar to ~constValue[T]~, and it generates a
        _constant value_ of type ~Option[T]~.

      - ~S~ is the type of the *successor* of some /singleton type/.
        For example, ~S[1]~ is the /singleton type/ ~2~.
        + =from Jian=
          How can we make a type of values can have /successor/, and how do
          these successors generate???

***** ~erasedValue~
      - The ~erasedValue[T]~ function in ~scala.comiletime.erasedValue~ is not
        implemented -- it would always raise a ~NotImplementedError~ exception
        when called.
          _However, it can in fact never be called, since it is declared ~erased~ --
        it is *ONLY* used at /compile-time/ during type checking._

      - Example:
        #+begin_src scala
          import scala.comiletime.erasedValue
          // erased def erasedValue[T]: T = ???

          inline def defaultValue[T] = inline erasedValue[T] match {
            case _: Byte    => Some(0: Byte)
            case _: Char    => Some(0: Char)
            case _: Short   => Some(0: Short)
            case _: Int     => Some(0)
            case _: Long    => Some(0L)
            case _: Float   => Some(0.0f)
            case _: Double  => Some(0.0d)
            case _: Boolean => Some(false)
            case _: Unit    => Some(())
            case _          => None
          }

          val dInt:     Some[Int]     = defaultValue[Int]
          val dDouble:  Some[Double]  = defaultValue[Double]
          val dBoolean: Some[Boolean] = defaultValue[Boolean]
          val dAny:     Any.type      = defaultValue[Any]
        #+end_src

      - Another example:
        #+begin_src scala
          inline def toIntT[N <: Nat] <: Int = inline erasedValue[N] match {
            case _: Zero.type => 0
            case _: Succ[n]   => toIntT[n] + 1
          }

          final val two = toIntT[Succ[Succ[Zero.type]]]
        #+end_src
        + =from Jian= I think the ~final~ here is not the best practice!!!
          #+begin_quote
          Used in this way, inline is equivalent to Java and Scala 2's final.
          Note that ~final~, meaning /inlined constant/,
          is still supported in Dotty, BUT *will be phased out*.
                              -- from "Inline Definitions" subsection in this doc
          #+end_quote

        + =from Jian=
          Better implementation:
          #+begin_src scala
            enum Nat {
              case Zero
              case Succ[N <: Nat](n: N)
            }

            import Nat._

            transparent inline def toIntT[N <: Nat]: Int =
              inline scala.compiletime.erasedValue[N] match {
                case _: Zero.type => 0
                case _: Succ[n]   => toIntT[n] + 1
              }

            inline val two = toIntT[Succ[Succ[Zero.type]]]
          #+end_src

      - ~erasedValue~ is /an ~erased~ method/ so *it _CANNOT be used_ and _has NO_
        /runtime behavior/.*
          Since ~toIntT~ performs /static checks/ over the /static type/ of ~N~
        we can safely use it to scrutinize its return type (~S[S[Z]]~ in this case).

***** ~error~
      The ~error~ /method/ is used to produce _user-defined_ /compile errors/
      *DURING /inline expansion/.* It has the following signature:
      #+begin_src scala
        inline def error(inline msg: String): Nothing
      #+end_src

      - If an /inline expansion/ results in a call ~error(msgStr)~ the compiler
        produces an _error message_ containing the given ~msgStr~.
        + Example 1
          #+begin_src scala
            inline def fail() = {
              error("failed for a reason")
            }

            fail()  // error: failed for a reason
          #+end_src

          OR

        + Example 2
          #+begin_src scala
            inline def fail(p1: => Any) = {
              error(code"failed on: $p1")
            }

            fail(indentity("foo"))  // error: failed on: indentity("foo")
          #+end_src

***** The ~scala.compiletime.ops~ package
      - The ~scala.compiletime.ops~ package contains types that provide support for
        *primitive operations on /singleton types/.*

      - When all arguments to a type in ~scala.compiletime.ops~ are /singleton types/,
        the compiler can *evaluate* the result of the operation.

      - For example,
        #+begin_src scala
          import scala.compiletime.ops.int._
          import scala.compiletime.ops.boolean._

          val conjunction: true && true = true
          val multiplication: 3 * 5 = 15
        #+end_src
        + ~scala.compiletime.ops.int.*~ provides support for _multiplying TWO
          /singleton ~Int~ types/,_

        + ~scala.compiletime.ops.boolean.&&~ for the _conjunction of TWO ~Boolean~
          types._

      - Many of these /singleton operation types/ are meant to be used _infix_
        (as in SLS § 3.2.8), and are annotated with ~@infix~ accordingly.

      - Since /type aliases/ have the *SAME* /precedence/ rules as their term-level
        equivalents, the operations _COMPOSE with the *EXPECTED* /precedence/ rules_:
        #+begin_src scala
          import scala.compiletime.ops.int._
          val x: 1 + 2 * 3 = 7
        #+end_src

      - The /operation types/ are *located in* /packages/ named after the /type/
        of the *left-hand side* parameter.
        + ~scala.compiletime.ops.int.+~ represents _addition of two numbers_,
        + ~scala.compiletime.ops.string.+~ represents _string concatenation_.

      - To _use both_ and _distinguish the two types from each other_,
        a /match type/ can dispatch to the correct implementation:
        #+begin_src scala
          import scala.compiletime.ops._
          import scala.annotation.infix

          @infix type +[X <: Int | String, Y <: Int | String] = (X, Y) match {
            case (Int, Int)       => int.+[X, Y]
            case (String, String) => string.+[X, Y]
          }

          val concat: "a" + "b" = "ab"
          val addition: 1 + 1 = 2
        #+end_src

**** DONE Summoning Implicits Selectively - =TODO= =RE-READ=
     CLOSED: [2020-05-26 Tue 04:23]
     - It is foreseen that *many areas* of /typelevel programming/ *can be* done
       with _REWRITE_ methods *instead of* /implicits/.
       *BUT* _sometimes /implicits/ are *UNAVOIDABLE*._

     - The problem so far was that the /Prolog-like programming style/ of /implicit
       search/ becomes _viral_:
       *Once some construct depends on implicit search it has to be written as a
       logic program itself.* TODO ??? TODO

     - Consider for instance the problem of creating a ~TreeSet[T]~ or a ~HashSet[T]~
       depending on whether ~T~ _has an ~Ordering~ or not._
       We can create a set of /given definitions/ like this:
       #+begin_src scala
         trait SetFor[T, S <: Set[T]]

         class LowPriority {
           implicit def hashSetFor[T]: SetFor[T, HashSet[T]] = { ... }
         }

         object SetFor extends LowPriority {
           implicit def treeSetFor[T: Ordering]: SetFor[T, TreeSet[T]] = { ... }
         }
       #+end_src
       + =from Jian=
         I don't know the complete form of this example.
         I try to complete it:
         #+begin_src scala
           trait SetFor[T, S <: Set[T]] {
             val set: S
           }

           class LowPriority {
             given hashSetFor[T] as SetFor[T, HashSet[T]] {
               val set =  new HashSet
             }
           }

           object SetFor extends LowPriority {
             given def treeSetFor[T: Ordering] as SetFor[T, TreeSet[T]] {
               val set =  new TreeSet
             }
           }

           case class Person(name: String)

           println(summon[SetFor[Person, _]].set)  //  HashSet()
           println(summon[SetFor[String, _]].set)  //  TreeSet()
         #+end_src
         * =from Jian=
           TODO Can I find a conciser way to eliminate the ~.set~ part???

       + *Clearly, this is _NOT_ pretty.*
         * Besides all the usual indirection of /implicit search/,

         * we face the problem of rule *prioritization* where we have to
           _ensure that ~treeSetFor~ takes /priority/ over ~hashSetFor~ if the
           element type has an ordering._
             This is solved (clumsily) by putting ~hashSetFor~ in a /superclass/
           ~LowPriority~ of the object ~SetsFor~ where ~treeSetFor~ is defined.

         * Maybe the boilerplate would still be acceptable if the crufty code
           could be contained.
           _However_, this is not the case.

           TODO ??? TODO
           Every user of the abstraction *has to be PARAMETERIZED itself with a
           ~SetFor~ implicit.* Considering the simple task "I want a ~TreeSet[T]~
           if ~T~ has an /ordering/ and a ~HashSet[T]~ otherwise", this seems
           like a lot of ceremony.

       + There are some proposals to improve the situation _in specific areas,_
         for instance by allowing _MORE ELABORATE schemes to SPECIFY /priorities/._
           But they all keep the viral nature of /implicit search/ programs based
         on logic programming. -- =from Jian= _and they are NOT adopted._

     - _By contrast_,
       the NEW ~scala.compiletime.summonFrom~ construct makes /implicit search/ available
       _in a functional context_ -- =from Jian= rather than a logic programming cotext. TODO ??? TODO
       #+begin_src scala
         import scala.compiletime.summonFrom

         inline def setFor[T]: Set[T] = summonFrom {
           case given ord: Ordering[T] => new TreeSet[T]
           case _                      => new HashSet[T]
         }
       #+end_src
       + A ~summonFrom~ /call/ takes a /pattern matching closure/ as argument.
           All patterns in the /closure/ are /type ascriptions/ of the form
         ~identifier : Type~.

       + Patterns are tried *in sequence* (=from Jian= This help us avoiding using
         inheritance to solve the _implicit search priority issue_).
         * The first case with a pattern ~x: T~ such that an /given value/ of type
           ~T~ can be *summoned* is chosen. TODO ??? TODO

         * If the pattern is _PREFIXED_ with ~given~, the variable ~x~ is bound to
           the /given value/ *for the remainder of the case.* -- =from Jian= natural
           and reasonable, just like the other existing pattern boundings.

       + ~summonFrom~ application *must be reduced at /compile time/.*

     - Example:
       #+begin_src scala
         summon[Ordering[String]]

         println(setFor[String].getClass)  // prints class scala.collection.immutable.TreeSet
       #+end_src

     - Of course, when there is /contextual abstractions/, /ambiguity errors/ can
       happen:
       #+begin_src scala
         class A
         implicit val a1: A = new A
         implicit val a2: A = new A

         inline def f: Any = summonFrom {
           case given _: A => ???  // error: ambiguous implicits
         }
       #+end_src

***** DONE ~summonInline~
      CLOSED: [2020-05-26 Tue 03:21]
      The shorthand ~summonInline~ provides a _simple way_ to write a ~summon~ that is
      *delayed* _until the call is inlined_.
      #+begin_src scala
        transparent inline def summonInline[T]: T = summonFrom {
          case t: T => t
        }
      #+end_src
      - =from Jian=
        Need example and use case.

**** DONE Reference
     CLOSED: [2020-05-26 Tue 02:28]
     For more info, see
     - =PR #4768=, which explains how ~summonFrom~'s predecessor (/implicit matches/)
       can be used for /typelevel programming/ and /code specialization/

     - =PR #7201= which explains the _NEW ~summonFrom~ syntax._

*** TODO Macros
**** DONE Macros: Quotes and Splices
     CLOSED: [2020-06-21 Sun 22:43]
     - Macros are built on _TWO_ well-known fundamental operations:
       + quotation :: ~'{...}~ for /expressions/;
                      ~'[...]~ for /types/.

       + splicing :: ~${ ... }~

     - Additionally, *within* a /quote/ or a /splice/
       we can /quote/ or /splice/ _identifiers_ *directly* (i.e. ~'e~ and ~$e~).

     - Readers may notice the _RESEMBLANCE_ of the two aforementioned syntactic
       schemes with the familiar /string interpolation syntax/. /Quotes/ and
       /splices/ in this section allow us to treat code in a similar way,
       effectively supporting /macros/.
       #+begin_src scala
         println(s"Hello, $name, here is the result of 1 + 1 = ${1 + 1}")
       #+end_src
       In string interpolation we /quoted/ a string and then we /spliced/ into it,
       two others.
       1. ~name~, is a reference to a value of type string,
       2. an _arithmetic expression_ that will be evaluated followed by the /splicing/
          of its string representation.

     - The *entry point* for /macros/: an /inline method/ with a *top-level* /splice/.
       + We call it a *top-level*
         because it is the *ONLY* OCCASION where we encounter a /splice/ *outside*
         a /quote/ (consider as a /quote/ the compilation-unit at the call-site).

     - For example, the code below presents an ~inline~ /method/ ~assert~ which
       calls at compile-time a method ~assertImpl~ with a /boolean expression tree/
       as argument. ~assertImpl~ evaluates the expression and prints it again in
       an error message if it evaluates to ~false~.
       #+begin_src scala
         import sala.quoted._

         inline def assert(inline expr: Boolean): Unit =
           ${ assertImpl('expr) }

         def assertImpl(expr: Expr[Boolean])(using QuoteContext) = '{
           if (!$expr)
             throw new AssertionError(s"failed assertion: ${${ showExpr(expr) }}")
         }

         def showExpr(expr: Expr[Boolean])(using QuoteContext): Expr[String] =
           '{ "<some source code>" }  // Better implementation later in this document
       #+end_src
       + =IMPORTANT= =IMPORTANT= =IMPORTANT=
         =from Jian=
         The ~inline~ method with /top level splice/
         can provide a /given ~QuoteContext~ instance/, which, in syntax, is NOT
         be written out explicitly! This is why the signature of the above ~asset~
         does *NOT* have a ~(using QuoteContext)~ parameter list.

     - /Quotations/ can have _spliced_ parts in them; in this case the embedded /splices/
       _are evaluated and embedded as part of_ the formation of the /quotation/.

       - /Quotes/ and /splices/ can also be applied *DIRECTLY* to _identifiers_.
         + An /identifier/ ~$x~ starting with a ~$~ that appears _INSIDE_ a /quoted
           expression or type/ is _treated as_ a /splice/ ~${x}~.

         + Analogously, an /quoted identifier/ ~'x~ that appears _INSIDE_ a /splice/
           is _treated as_ a /quote/ ~'{x}~.

     - /Quotes/ and /splices/ are *DUALS of each other*.
       For arbitrary /expressions/ ~e~ and /types/ ~T~ we have:
       #+begin_src scala
         ${'{e}} = e
         '{${e}} = e
         ${'[T]} = T
         '{$[T]} = T
       #+end_src

**** DONE Types for Quotations
     CLOSED: [2020-05-30 Sat 15:39]
     - The /type signatures/ of /quotes/ and /splices/ can be described using
       _TWO_ _FUNDAMENTAL /types/:_
       + ~Expr[T]~: /abstract syntax trees/ representing /expressions/ of /type/ ~T~

       + ~Type[T]~: /type structures/ representing /type/ ~T~.

     - /Quoting/ and /splicing/ are dual to each other
       + /Quoting/
         * /expressions/ of /type/ ~T~ ---> /expressions/ of /type/ ~Expr[T]~
         * /types/ ~T~ ---> /expressions/ of /type/ ~Type[T]~.

       + /Splicing/
         - expressions of /type/ ~Expr[T]~ ---> /expressions/ of /type/ ~T~
         - expressions of /type/ ~Type[T]~ ---> /types/ ~T~.

     - The two types can be defined in package ~scala.quoted~ as follows:
       #+begin_src scala
         package scala.quoted

         sealed abstract calss Expr[+T]
         sealed abstract calss Type[T]
       #+end_src
       Both ~Expr~ and ~Type~ are ~abstract~ and ~sealed~, so _ALL /constructors/
       for these types are PROVIDED BY THE SYSTEM._

     - *TWO* ways to construct values of type ~Expr[T]~ or ~Type[T]~:
       + by /quoting/,
       + =TODO= by /type-specific lifting operations/ that will be discussed later on.

**** DONE The Phase Consistency Principle
     CLOSED: [2020-05-30 Sat 15:40]
     - A fundamental /phase consistency principle (PCP)/ regulates accesses to
       /free variables/ in /quoted/ and /spliced/ code:
       #+begin_quote
       For any /free variable reference/ ~x~,
       the _number_ of /quoted scopes/ and the _number_ of /spliced scopes/
       between the reference to ~x~ and the definition of ~x~ *must be equal*.
       #+end_quote
       + ~this~-reference count as /free variables/.

       + We assume
         * ALL _imports_ are fully expanded
         * ~_root_~ is *NOT* a /free variable/.
         So /references/ to /global definitions/ are allowed everywhere.

     - The /phase consistency principle/ can _be motivated as follows_:
       1. Suppose the result of a program _P_ is some /quoted text/ ~'{ ... x ... }~
          that refers to a /free variable/ ~x~ in _P_. This can be represented only
          by referring to the original variable ~x~.

       2. Hence, the result of the program will need to persist the program state
          itself as one of its parts. We don't want to do this, hence this situation
          should be made illegal.

          Dually, suppose a top-level part of a program is a /spliced text/
          ~${ ... x ... }~ that refers to a /free variable/ ~x~ in _P_. This would
          mean that we refer during construction of _P_ to a value that is
          _available ONLY during execution of P._
          *This is of course impossible and therefore needs to be ruled out.*

       Now, the small-step evaluation of a program will reduce /quotes/ and
       /splices/ in equal measure using the cancellation rules above. But it will
       neither create nor remove /quotes/ or /splices/ individually. So the PCP
       ensures that program elaboration will lead to neither of the two unwanted
       situations described above.

     - In what concerns the range of features it covers, this form of macros (Scala 3
       macro) introduces a principled metaprogramming framework that is quite
       close to the /MetaML family of languages/.
       + One difference is that MetaML does NOT have an equivalent of the PCP.
           quoted code in MetaML can access variables in its immediately
         enclosing environment, with some restrictions and caveats since such
         accesses involve serialization. _However, this does not constitute a
         fundamental gain in expressiveness._

**** DONE From ~Expr~'s to Functions and Back
     CLOSED: [2020-06-22 Mon 01:49]
     It is possible to
     CONVERT _back and forth_ any ~Expr[T => R]~ into ~Expr[T] => Expr[R]~!

     - The conversions can be implemented as follows:
       #+begin_src scala
         def to[T: Type, R: Type](f: Expr[T] => Expr[R])(using QuoteContext): Expr[T => R] =
           '{ (x: T) => ${ f('x) } }

         def from[T: Type, R: Type](f: Expr[T => R])(using QuoteContext): Expr[T] => Expr[R] =
           (x: Expr[T]) => '{ $f($x) }
       #+end_src
       - This decorator gives ~Expr~ the ~apply~ operation of an /applicative functor/.

       - Note how the fundamental /phase consistency principle/ works in two different
         directions here for ~f~ and ~x~.
         + For example,
           in the method ~to~,
           * the reference to ~f~ is legal because it is /quoted/, then /spliced/,
           * the reference to ~x~ is legal because it is /spliced/, then /quoted/.

     - Example:
       =from Jian= =TODO= Need to create a /given instance/ of ~QuoteContext~
       #+begin_src scala
         // '{ (x: Int) => x.toString }
         val f1: Expr[Int => String] = to((x: Expr[Int]) => '{ $x.toString })

         // (x: Expr[Int]) => '{ ((x: Int) => x.toString)($x) }
         val f2: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
         f2('{2})  // '{ ((x: Int) => x.toString)(2) }
       #+end_src
       + =from Jian=
         To make the code above runnable, they must be used in a scope with a
         given ~QuoteContext~ instance. To satisfy this, there are two ways:
         * Compile Time Macro:
           #+begin_src scala
             import scala.quoted._

             inline def runf1: Int => String = ${ mcrImpl1 }
             def mcrImpl1(using QuoteContext): Expr[Int => String] =
               to((x: Expr[Int]) => '{ $x.toString })

             inline def runf2: String = ${ mcrImpl2 }
             def mcrImpl2(using QuoteContext): Expr[String] = {
               val f2: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
               f2('{2})
             }
           #+end_src

         * Multi-Stage Programming (inlucdes /runtime/ evaluation, see next section
           for details):
           1. Include dependency (this was inside dotty before, and they are now
              separated) ~"ch.epfl.lamp" %% "dotty-staging" % scalaVersion.value~.

           2. Then,
              #+begin_src scala
                import scala.quoted._
                import scala.quoted.staging._

                given Toolbox = Toolbox.make(getClass.getClassLoader)

                //// '{ (x: Int) => x.toString }
                val runf1: Int => String = run {
                  to((x: Expr[Int]) => '{ $x.toString })
                }

                //// (x: Expr[Int]) => '{ ((x: Int) => x.toString)($x) }
                val runf2: String = run {
                  val f2: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
                  f2('{2})
                }
              #+end_src

     - *LIMITATION* of ~from~ ::
       it does _NOT_ \beta{}-reduce when a lambda is called immediately
       #+begin_src scala
         inline def resultOfFrom: String = ${ resultOfFromImpl }
         def resultOfFromImpl(using QuoteContext): Expr[String] = {
           val f: Expr[Int] => Expr[String] = from('{ (x: Int) => x.toString })
           Expr(f('{2}).show)
         }
         // ((x: scala.Int) => x.toString()).apply(2)
       #+end_src

       + In some cases we _want to *REMOVE* the lambda from the code_,
         for this we provide the method ~Expr.betaReduce~ that turns a /TREE
         describing a function/ into a /FUNCTION mapping trees to trees/.
         #+begin_src scala
           inline def forBetaReduceExample: String = ${ forBetaReduceExampleImpl }

           def forBetaReduceExampleImpl(using QuoteContext): Expr[String] = {
             val afterBetaReduction = Expr.betaReduce('{ (x: Int) => x.toString })('{2})
             Expr(afterBetaReduction.show)
           }
           // 2.toString()
         #+end_src

       + ~Expr.betaReduce~ _IMPLEMENTATION_:
         The definition of ~Expr.betaReduce(f)(x)~ is *assumed* to be functionally the
         same as ~'{($f)($x)}~, however _it SHOULD *optimize* this call by returning
         the result of beta-reducing ~f(x)~ if ~f~ is a *KNOWN* lambda expression._
         ~Expr.betaReduce~ DISTRIBUTES applications of ~Expr~ over function arrows:
         #+begin_src scala
           Expr.betaReduce(_): Expr[(T1, ..., Tn) => R] => ((Expr[T1], ..., Expr[Tn]) => Expr[R])
         #+end_src

**** DONE Lifting Types
     CLOSED: [2020-06-09 Tue 03:04]
     - */Types/ are _NOT_ directly affected by the /phase consistency principle/.*
       + *It is possible to use /types/ defined at any level in any other level.*
         *But*, if a type is used in a SUBSEQUENT /stage/ it will need to be _lifted_
         to a ~Type~.

         * The resulting value of ~Type~ will be subject to /PCP/.
           Indeed, the definition of ~to~ above uses ~T~ in the NEXT /stage/,
           there is a /quote/ but NO /splice/ between the parameter binding of
           ~T~ and its usage. But the code can be rewritten by adding a binding
           of a ~Type[T]~ tag:
           #+begin_src scala
             def to[T, R: Type](f: Expr[T] => Expr[R])(using t: Type[T])(using QuoteContext): Expr[T => R] =
               '{ (x: $t) => ${ f('x) } }
           #+end_src
           - In this version of ~to~, the type of ~x~ is now the result of /splicing/
             the ~Type~ value ~t~.

           - This operation is /splice/ CORRECT -- there is one /quote/ and one
             /splice/ BETWEEN the _use_ of ~t~ AND its _definition_.

      - *To _AVOID_ clutter* (=MOTIVATION= of /lifting types/),
       the Scala implementation tries to _CONVERT *ANY* /type reference/ to a type
       ~T~ *in subsequent phases* to a /type-splice/,_ by *rewriting* ~T~ to
        (automatically) ~${summon[Type[T]] }~.
       + For instance, the user-level definition of ~to~:
         #+begin_src scala
           def to[T: Type, R: Type](f: Expr[T] => Expr[R])(using QuoteContext): Expr[T => R] =
             '{ (x: T) => ${ f('x) } }
         #+end_src

         would be *rewritten* to

         #+begin_src scala
           def to[T: Type, R: Type](f: Expr[T] => Expr[R])(using QuoteContext): Expr[T => R] =
             '{ (x: ${ summon[Type[T]] }) => ${ f('x) } }
         #+end_src
         * The summon query succeeds because
           - there is a /given instance/ of type ~Type[T]~ available
           - _the reference to that value is phase-correct._

         * If that was NOT the case,
           the phase inconsistency for ~T~ would be _reported_ as an error.

**** DONE Lifting Expressions
     CLOSED: [2020-06-24 Wed 00:52]
     - Consider the following implementation of a /staged interpreter/ that implements
       a compiler through staging.
       #+begin_src scala
         import scala.quoted._

         enum Exp {
           case Num(n: Int)
           case Plus(e1: Exp, e2: Exp)
           case Var(x: String)
           case Let(x: String, e: Exp, in: Exp)
         }
       #+end_src
       + The interpreted language consists of numbers ~Num~, addition ~Plus~, and
         variables ~Var~ which are bound by ~Let~.

     - Here are two sample expressions in the language:
       #+begin_src scala
         val exp    = Plus(Plus(Num(2), Var("x")), Num(4))
         val letExp = Let("x", Num(3), exp)
       #+end_src

     - Here's a compiler that maps an expression given in the interpreted language
       to /quoted/ Scala code of type ~Expr[Int]~.
       #+begin_src scala
         import scala.quoted._

         def compile(e: Exp, env: Map[String, Expr[Int]])(using QuoteContext): Expr[Int] = e match {
           case Num(n)          => Expr(n)
           case Plus(e1, e2)    => '{ ${ compile(e1, env) } + ${ compile(e2, env) } }
           case Var(x)          => env(x)
           case Let(x, e, body) => '{ val y = ${ compile(e, env) }; ${ compile(body, env + (x -> 'y)) } }
         }
       #+end_src

     - Running ~compile(letExp, Map.empty)~ would yield the following Scala code:
       #+begin_src scala
         '{ val y = 3; (2 + y) + 4 }
       #+end_src
       =from Jian=
       You can check this representation with the help of ~showExpr~ mentioned below.

     - The body of the first clause, ~case Num(n) => Expr(n)~, *looks SUSPICIOUS*.
       ~n~ is declared as an ~Int~, yet it is converted to an ~Expr[Int]~ with
       ~Expr.apply~.
       + Q :: Shouldn't ~n~ be /quoted/ (=from Jian= Use ~'n~ instead of ~Expr(n)~)?

       + A :: In fact this would _NOT_ work since replacing ~n~ by ~'n~ in the
               clause would *NOT* be /phase correct/ (=from Jian= violate PCP).

     - =from Jian=
       From the Q&A above we know it's better to find a easy way to _lift a value
       of ~T~ to ~Expr[T]~ with enough information hiding_. A good API for this is
       already hinted above -- use ~Expr.apply[T: Liftable](v: T)~ to do this.
       We'll talk about the knowledge about ~Expr.apply~ below.

     - The ~Expr.apply~ method is defined in package ~quoted~:
       #+begin_src scala
         package quoted

         object Expr {
           /** Lift a value into an expression containing the construction of that value */
           def apply[T: Liftable](x: T)(using QuoteContext): Expr[T] =
             summon[Liftable[T]].toExpr(x)

           // ...
         }
       #+end_src
       + This method says that values of types implementing the ~Liftable~ /type
         class/ can be converted ("lifted") to ~Expr~ values using ~Expr.apply~.

     - Dotty comes with /given instances/ of ~Liftable~ for several types including
       ~Boolean~, ~String~, and /ALL primitive number types/.
       + For example,
         ~Int~ values can be converted to ~Expr[Int]~ values by wrapping the
         value in a ~Literal~ /tree node/ (=from Jian= actually ~Literal(Constant(n))~).
           This makes use of the underlying /tree representation/ in the compiler
         *for efficiency*.
         * _BUT_ the ~Liftable~ instances are nevertheless NOT magic in the sense
           that they could all be defined in a user program *without knowing
           anything about the representation of ~Expr~ trees* (=from Jian= this
           can be done is because the fundamental types /given ~Liftable~ instances/
           are provided by Scala).
           - For instance, here is a possible instance of ~Liftable[Boolean]~:
             #+begin_src scala
               given Liftable[Boolean] {
                 def toExpr(b: Boolean) =
                   if (b) '{ true } else '{ false }
               }
             #+end_src

     - Once we can lift bits, we can work our way up.
       For instance, here is a possible implementation (=from Jian= of course,
       not the best way!) of ~Liftable[Int]~ that _does *NOT* use the underlying
       tree machinery_:
       #+begin_src scala
         given Liftable[Int] {
           def toExpr(n: Int): Expr[Int] = n match {
             case Int.MinValue    => '{ Int.MinValue }
             case _ if n < 0      => '{ - ${ toExpr(-n) } }
             case 0               => '{ 0 }
             case _ if n % 2 == 0 => '{ ${ toExpr(n / 2) } * 2 }
             case _               => '{ ${ toExpr(n / 2) } * 2 + 1 }
           }
         }
       #+end_src
       + =from Jian=
         Since the PCP is only for /free variables/, and ~'{ Int.MinValue }~ and
         ~'{ 0 }~ don't include any /free variables/, they are legal and no
         violation to PCP. We can see they other 3 branches includes /free
         variables/ and follow PCP!

     - Since ~Liftable~ is a /type class/, its instances can be conditional.
       For example, a ~List~ is /liftable/ _if its element type is_:
       #+begin_src scala
         given [T: Liftable : Type] as Liftable[List[T]] {
           def toExpr(xs: List[T]) = xs match {
             case head :: tail => '{ ${ Expr(head) } :: ${ Expr(tail) } }
             case Nil          => '{ Nil: List[T] }
           }
         }
       #+end_src

     - *In the end, ~Liftable~ _RESEMBLES_ very much a serialization framework.*
       Like the latter it can be derived systematically for all /collections/,
       /case classes/ and /enums/.

     - =TODO= =???= =TODO=
       Note also that the synthesis of type-tag values of type ~Type[T]~ is
       essentially the type-level analogue of /lifting/.

     - Using /lifting/, we can now give the missing definition of ~showExpr~ in
       the introductory example:
       #+begin_src scala
         def showExpr[T](expr: Expr[T])(using QuoteContext): Expr[String] = {
           val code: String = expr.show
           Expr(code)
         }
       #+end_src
       + That is, the ~showExpr~ /method/ _converts_ its ~Expr~ argument to a
         string (~code~), and *lifts* the result back to an ~Expr[String]~ using
         ~Expr.apply~.

**** TODO Lifting Types - =from Jian= _MECHANISM_
**** TODO Relationship with ~inline~ _Rationale of Design_
     - First Impression (=from Jian= I add this title):
       Seen by itself, principled metaprogramming in Dotty looks
       _MORE like_ a framework for /runtime metaprogramming/
       _THAN_ one for /compile-time metaprogramming/ with /macros/.

     - But combined with Dotty's ~inline~ feature it can be _turned into_ a
       compile-time system.
         The idea is that /macro elaboration/ can be understood as a *combination*
       of a /macro library/ and a /quoted program/.

     - Example used to illustrate the above discussion,
       here's the ~assert~ /macro/ again together with a program that CALLS
       ~assert~.
       #+begin_src scala
         object Macros {

           inline def assert(inline expr: Boolean): Unit =
             ${ assertImpl('expr) }

           def assertImpl(expr: Expr[Boolean])(using QuoteContext) =
             val failMsg: Expr[String] = Expr(s"failed assertion: ${expr.show}")
             '{ if !($expr) then throw new AssertionError($failMsg) }
         }

         object App {
           val program = {
             val x = 1
             Macros.assert(x != 0)
           }
         }
       #+end_src
       + The example is only /phase correct/ because ~Macros~ is a /global value/
         and as such *NOT subject to* _phase consistency checking_.
         * *Conceptually that's a bit unsatisfactory.*
           - If the PCP is so fundamental,
             it should be applicable without the /global value/ *exception*.

           - _BUT_ in the example as given this does not hold since both ~assert~
             and program call ~assertImpl~ *with a* /splice/ but *no* /quote/.

       + However, one could argue that the example is really missing an important
         aspect:
         The /macro library/ has to be compiled in a phase *prior to* the program
         using it, _BUT_ in the code above, /macro/ and /program/ are _defined
         together_.
           A more accurate view of /macros/ would be to have the _user program_ be
         in a /phase/ *after* the /macro definitions/, reflecting the fact that
         /macros/ have to be defined and compiled before they are used.
           Hence, conceptually the program part should be treated by the compiler
         *as if* (=from Jian= not real legal code?) it was quoted:
         #+begin_src scala
           val program = '{
             val x = 1
             ${ Macros.assertImpl('{ x != 0 }) }
           }
         #+end_src

     - If program is treated as a /quoted expression/, the call to ~Macro.assertImpl~
       becomes /phase correct/ even if _macro library_ and _program_ are
       conceptualized as local definitions.

     - Q :: But what about the call from ~assert~ to ~assertImpl~?
     - A :: Here, *we need a _tweak_ of the /typing rules/.*
            An ~inline~ function such as ~assert~ that contains a /splice/ operation
            *outside* an ENCLOSING /quote/ is called a /macro/.
              /Macros/ are supposed to be expanded in a SUBSEQUENT /phase/, i.e. in
            a /quoted context/. Therefore, they are also type checked *as if*
            they were in a /quoted context/.
       + For instance, the definition of ~assert~ is typechecked *as if* it
         appeared INSIDE /quotes/.
           _This makes the call from ~assert~ to ~assertImpl~ phase-correct,_
         even if we assume that both definitions are *local*.

     - The ~inline~ modifier is used to declare a ~val~ that is either a constant or
       is a parameter that will be a constant when instantiated.
         This aspect is also important for /macro expansion/.
         =from Jian= More details about this "important"?!?!?!

     - To get values out of expressions containing constants ~Expr~ provides the
       /methods/
       + ~unlift[T]~: return a value of ~Option[T]~
       + ~unliftOrError[T]~: return a value of ~T~

     - Wanted: avoid having incidental ~val~ bindings generated by the /inlining/
               of the ~def~
       Solution: it is *RECOMMENDED* to use /an ~inline~ parameter/.
       + To illustrate this, consider an implementation of the ~power~ function that
         makes use of a statically known exponent:
         #+begin_src scala
           inline def power(x: Double, inline n: Int) =
             ${ powerCode('x, 'n) }

           private def powerCode(x: Expr[Double], n: Expr[Int])(using QuoteContext): Expr[Double] =
             n.unlift match {
               case Some(m) => powerCode(x, m)
               case None    => '{ Math.pow($x, $y) }
             }

           private def powerCode(x: Expr[Double], n: Int)(using QuoteContext): Expr[Double] =
             if      (n == 0)     '{ 1.0 }
             else if (n == 1)     x
             else if (n % 2 == 0) '{ val y = $x * $x; ${ powerCode('y, n / 2) } }
             else                 '{ $x * ${ powerCode(x, n - 1) } }
         #+end_src

**** DONE Scope Extrusion
     CLOSED: [2020-06-24 Wed 02:43]
     - /Quotes/ and /splices/ are duals _as far as_ the PCP is concerned.

     - _But_ there is an *additional RESTRICTION* that needs to be imposed on
       /splices/ to guarantee /soundness/:
       code in /splices/ *must be _FREE_ of /side effects/.*
       + The restriction prevents code like this:
         #+begin_src scala
           var x: Expr[T] = ...
             '{ (y: T) => ${ x = 'y; 1 } }
         #+end_src
         This code, IF it was accepted, would *extrude* a reference to a /quoted
         variable/ ~y~ from its /scope/.
           This would subsequently allow access to a variable outside the scope
         where it is defined, which is LIKELY (=TODO= =???=) problematic.
         1. The code is clearly /phase consistent/, so we CANNOT use PCP to rule
           it out.

         2. Instead we postulate a FUTURE /effect system/ that can guarantee that
            /splices/ are pure.
            - In the absence of such a system we simply demand that /spliced
              expressions/ are pure *by convention*, and allow for *undefined
              compiler behavior* if they are not.

            - This is analogous to the status of pattern guards in Scala, which
              are also required, but NOT VERIFIED, to be pure.

     - /Multi-Stage Programming/ (=from Jian= next section) introduces one
       additional /method/ where you can *expand code at runtime* with a
       /method/ ~scala.quoted.staging.run~.
       + =from Jian=
         /Staging/ is *not* a part of the standard libary. Need to includes the
         dependency: ~"ch.epfl.lamp" %% "dotty-staging" % scalaVersion.value~

     - Call ~scala.quoted.staging.run~ in /splices/ is forbidden!
       This is a little bit tricky.
       + Use this example code to illustrate this trickiness:
         #+begin_src scala
           '{ (x: Int) => ${ run('x); 1 } }  // Not legal code
         #+end_src
         * This is /phase correct/, _BUT_ WILL lead us into *TROUBLE*.

         * Evaluate the /splice/ will reduce the expression ~run('x)~ to ~x~.
           But then the result is *no longer* /phase correct/.
           #+begin_src scala
             '{ (x: Int) => ${ x; 1 } }
           #+end_src

       + To *prevent* this /soundness hole/ it seems easiest to classify ~run~ as
         a /side-effecting operation/. It would thus be *prevented from appearing
         in /splices/.*
           In a base language with /side effects/ we would have to do this anyway:
         Since ~run~ runs _ARBITRARY_ code it can ALWAYS produce a /side effect/
         if the code it runs produces one.
         =TODO= =TODO= =TODO=

**** TODO Example Expansion
     - Assume we have two methods, one map that takes an ~Expr[Array[T]]~ and a
       function ~f~ and one ~sum~ that performs a sum by delegating to ~map~.
       #+begin_src scala
         object Macros {
           def map[T](arr: Expr[Array[T]], f: Expr[T] => Expr[Unit])
                     (using t: Type[T], qctx: QuoteContext): Expr[Unit] = '{
             var i: Int = 0
             while (i < ($arr).length) {
               val element: $t = ($arr)(i)
               ${f('element)}
               i += 1
             }
           }

           def sum(arr: Expr[Array[Int]])(using QuoteContext): Expr[Int] = '{
             var sum = 0
             ${ map(arr, x => '{sum += $x}) }
             sum
           }

           inline def sum_m(arr: Array[Int]): Int = ${sum('arr)}
         }
       #+end_src

**** DONE Find implicits within a macro
     CLOSED: [2020-06-24 Wed 02:45]
     Make implicit search available in a /quote context/ with
     ~scala.quoted.Expr.summon~:
     #+begin_src scala
       import scala.quoted._
       inline def setFor[T]: Set[T] = ${ setForExpr[T] }

       def setForExpr[T: Type](using QuoteContext): Expr[Set[T]] = {
         Expr.summon[Ordering[T]] match {
           case Some(ord) => '{ new TreeSet[T]()($ord) }
           case _         => '{ new HashSet[T] }
         }
       }
     #+end_src

**** TODO Relationship with Whitebox ~Inline~
     =from Jian= *I don't quite understand!!!*
     ~Inline~ documents inlining.
     The code below introduces a /whitebox inline method/ that can calculate
     either a value of /type/ ~Int~ or a value of /type/ ~String~.
     #+begin_src scala
       transparent inline def defaultOf(inline str: String) =
         ${ defaultOfImpl('str) }

       def defaultOfImpl(strExpr: Expr[String])(using QuoteContext): Expr[Any] =
         strExpr.unliftOrError match {
           case "int"    => '{1}
           case "string" => '{"a"}
         }

       // in a separate file
       val a: Int    = defaultOf("int")
       val b: String = defaultOf("string")
     #+end_src

**** DONE Defining a macro and using it in a single project
     CLOSED: [2020-06-24 Wed 03:50]
     - =from Jian=
       Of course, if the /macros/ project is *different* from the project use
       /macros/, the compilation is much simpler, and this doc does discuss.

     - It is possible to define /macros/ and use them in the *same project* as
       long as the implementation of the /macros/ does NOT have /runtime
       dependencies/ on code in the file where it is used.
       + It might still have /compile-time dependencies/ on
         /types/ and /quoted code/ that refers to the use-site file.

     - To provide the functionality of a project inlcudes both /macros/ and the
       code use them, Dotty provides a /transparent compilation mode/ where
       1. Files that try to expand a /macro/ but fail because the /macro/ has NOT
          been compiled yet are *suspended*.

       2. If there are any suspended files when the compilation ends,
          the compiler will *AUTOMATICALLY* RESTART compilation of the suspended
          files using the output of the previous (partial) compilation as /macro/
          classpath.

       3. In case *ALL* files are *suspended* due to /cyclic dependencies/ the
          compilation will *FAIL* with an error.

**** TODO Pattern matching on quoted expressions
***** TODO Quoted patterns
***** TODO Recovering precise types using patterns

**** TODO More details

*** TODO Staging
    # *Multi-Stage Programming*
**** API
**** Create a new Dotty project with staging enabled
**** Example

*** TODO TASTy Reflection
    # *TASTy Reflect*
**** API: From quotes and splices to TASTy reflect trees and back
***** Extractors
***** Obtaining and underlying argument
***** Positions
***** Tree Utilities
****** Let

**** More Examples

*** TODO TASTy Inspection
**** Inspecting TASTy files
**** Template project

** TODO OTHER NEW FEATURES
*** TODO Trait Parameters
**** Reference

*** DONE Super Traits
    CLOSED: [2020-06-10 Wed 23:46]
    - /Traits/ are used in _TWO_ roles:
      + As *mixins* for other /classes/ and /traits/
      + As *types* of ~vals~, ~defs~, or ~parameters~

    - /Super traits/ is designed to address the topic:
      Some /traits/ are used primarily in the _first role_,
      and we usually do *NOT* want to see them in /inferred types/.
      + Example:
        #+begin_src scala
          trait Kind
          case object Var extends Kind
          case object Val extends Kind
          val x = Set(if condition then Val else Var)
        #+end_src
        The inferred type of ~x~ in Scala 2 is ~Set[Kind & Product & Serializable]~
        whereas one would have hoped it to be ~Set[Kind]~.
        * The reasoning for this particular type to be inferred is as follows:
          1. The /type/ of the conditional above is the /union type/ ~Val | Var~
             (in concept -- we don't actually have the union type syntax in Scala 2).

          2. A /union type/ is widened in /type inference/ to the *least supertype*
             that is _NOT_ a /union type/.
               In the example, this type is ~Kind & Product & Serializable~
             since all THREE /traits/ are /supertraits/ of both ~Val~ and ~Var~.
             So that type becomes the inferred element type of the set.

    - Scala 3 allows one to mark a /trait/ as a ~super~ /trait/, which means that
      it can be suppressed in /type inference/.
      #+begin_src scala
        // In Scala 3
        super trait S
        trait Kind
        case object Var extends Kind
        case object Val extends Kind
        val x = Set(if condition then Val else Var)
      #+end_src
      Now ~x~ has /inferred type/ ~Set[Kind]~ -- the common /super trait/ ~S~ does
      _NOT_ appear in the /inferred type/.

**** Super Traits
     - The traits ~scala.Product~, ~java.lang.Serializable~ and ~java.lang.Comparable~
       are *treated _AUTOMATICALLY_ as /super traits/.*
         Other /traits/ can _be turned into_ /super traits/, by adding the keyword
       ~super~ in front of /trait/, as shown above.

     - Every /trait/ *can be* declared as a /super trait/.

     - Typically /super traits/ are /traits/ that influence the implementation of
       inheriting /classes/ and /traits/ and that are _NOT usually used as types by
       themselves._
       + Two examples from the standard collection library:
         * ~IterableOps~,
           which provides method implementations for an ~Iterable~

         * ~StrictOptimizedSeqOps~,
           which optimises some of these implementations for sequences with
           efficient indexing.

     - =IMPORTANT=
       Generally, any /trait/ that is _extended recursively_ is a good candidate
       to be declared a /super trait/.

**** Retro-Fitting Scala 2 Libraries
     - To allow cross-building between Scala 2 and 3,
       ~super~ /traits/ can also be introduced by adding the ~@superTrait~
       annotation, which is _defined in package ~scala.annotation~._

     - Example:
       #+begin_src scala
         import scala.annotation.superTrait

         @superTrait trait StrictOptimizedSeqOps[+A, +CC[_], +C] ...
       #+end_src

     - The ~@superTrait~ annotation *will be deprecated and removed in some later
       version* of Scala _when cross-building with Scala 2 will NO LONGER be a
       concern._

**** TODO Rules for Inference
     - /Super traits/ *can be* given as /explicit types/ as usual.
       But they are often elided when types are inferred.
         Roughly, the rules for /type inference/ say that /super traits/ _are
       DROPPED from intersections WHERE POSSIBLE._

     - The precise rules are NOT follows:
       + When inferring a type of a type variable, or the type of a ~val~, or the
         /return type/ of a ~def~,

       + where that type is not higher-kinded,

       + and where ~B~ is its known /upper bound/ or ~Any~ if none exists:

       + If the /type inferred/ so far is of the form ~T1 & ... & Tn~ where n >= 1,
         replace the maximal number of ~Ti~'s by ~Any~, while ensuring that the
         resulting type is still a subtype of the bound ~B~.

       + However, do NOT perform this /widening/ if all types ~Ti~ can get replaced
         in that way.

     - The _last clause_ *ensures* that
       a single /super trait/ instance such as ~Product~ is not widened to
       ~Any~.
       + =IMPORTANT= =SUMMARY=
         /Super trait/ instances are _ONLY dropped_ when they appear _in conjunction
         with some other type._

**** Syntax

*** DONE Creator Applications
         CLOSED: [2019-12-28 Sat 17:32]
         - creator applications :: use simple _function call syntax_ to *create* /instances/
           of a /class/, even if there is no ~apply~ /method/ implemented.

    - Example:
      #+begin_src scala
        class StringBuilder(s: String) {
          def this() = this("")
        }

        StringBuilder("abc")  // same as `new StringBuilder("abc")`
        StringBuilder()       // same as `new StringBuilder()`
      #+end_src

    - There was _THREE_ rules for the function call syntax ~f(args)~, and
      a forth rule (fallback rule) for the _function call syntax_ can be added:
      1. if is a /method/ applicable to ~args~, typecheck ~f(args)~ unchanged,

      2. if ~f~ has an ~apply~ /method/ applicable to ~args~ as a member, continue
         with ~f.apply(args)~,

      3. if ~f~ is of the form ~p.m~ and there is an /implicit conversion/ ~c~
         applicable to ~p~ so that ~c(p).m~ is applicable to ~args~, continue
         with ~c(p).m(args)~

      4. if ~f~ is syntactically a /stable identifier/, and ~new f~ where ~f~ is
         interpreted as a /type identifier/ is applicable to ~args~, continue
         with ~new f(args)~.

    - Similarly, the possible interpretations of a /function call with type arguments
      ~f[targs]~ syntax/ are augmented with the following interpretation as a _FINAL
      fallback_:
      + if ~f~ is syntactically a /stable identifier/, and ~new f[targs]~ where ~f~
        is interpreted as a /type identifier/ is _well-typed_, continue with ~new
        f[targs]~.

**** DONE Motivation
     CLOSED: [2019-12-28 Sat 17:18]
     - This doc mentions _TWO_ motivation:
       1. Leave out ~new~ *hides* an implementation detail
       2. makes code more pleasant to *read*

     - =from Jian= I think 1 is objective, and 2 is subjective.

     - Q :: What's the cose of this change?

     - A :: _Add a new rule_ (a fallback rule) to the interpretation of the /function
            call syntax/. =from Jian= All the rules are listed above before this
            "Motivation" section.

     - Q :: Why this cost is valuable?

     - A :: It increase the perceived regularity of the language, since /case classes/
            already provide /function call creation syntax/ (and are often defined for
            this reason alone).

**** DONE Discussion
     CLOSED: [2019-12-28 Sat 17:24]
     An alternative design would auto-generate ~apply~ /methods/ for _non /case
     classes/._
     - =from Jian= From the first glance, this alternative design has one good
       point -- NO need to add new (fallback) rule for the interpretation of
       /function call syntax/.

     - However, this alternative design can *cause numerous problems*:
       + overloading ambiguities TODO ???
       + overriding errors TODO ???
       + shadowing of user-defined ~apply~ /methods/ by more specific auto-generated ones.
         TODO ???

*** DONE Export Clauses -- =TODO= _Elaboration of Export Clauses_
    CLOSED: [2020-05-18 Mon 02:46]
    *An ~export~ clause defines aliases for selected members of an object.*
    - NOTE:
      Unless otherwise stated, _the term "class"_ in this discussion also
      _includes_ /object/ and /trait/ definitions.

    - Example:
      #+begin_src scala
        class BitMap
        class InkJet

        class Printer {
          type PrinterType
          def print(bits: BitMap): Unit = ???
          def status: List[String] = ???
        }

        class Scanner {
          def scan(): BitMap = ???
          def status: List[String] = ???
        }

        class Copier {
          private val printUnit = new Printer { type PrinterType = InkJet }
          private val scanUnit = new Scanner

          export scanUnit.scan
          export printUnit.{status => _, _}

          def status: List[String] = printUnit.status ++ scanUnit.status
        }
      #+end_src
      - Here the two ~export~ clauses define the following /export aliases/ in
        class ~Copier~:
        #+begin_src scala
          final def scan(): BitMap            = scanUnit.scan()
          final def print(bits: BitMap): Unit = printUnit.print(bits)
          final type PrinterType              = printUnit.PrinterType
        #+end_src

      - The exported members can be accessed inside ~Copier~ as well as from
        outside:
        #+begin_src scala
          val copier = new Copier
          copier.print(copier.scan())
        #+end_src

      - Syntax (similar to ~import~):
        #+begin_src scala
          export path . { sel_1, ..., sel_n }
          export given path . { sel_1, ..., sel_n }
        #+end_src
        + ~path~ here must be a /stable identifier/.

        + ~export~ is like ~import~.
          Synthetic members generated by compiler can't be exported.

      - A member is *eligible for being exported* if all of the following holds:
        + The _owner of the being exported member_ is *NOT* the /base class/ of
          /class/ (includes /object) that conttains the /export clause/.

        + The member does *NOT* /override a concrete definition/ that has as owner
          a /base class/ of the /class/ containing the /export clause/.

        + it is _accessible_ at the /export clause/ -- =from Jian= with proper
          modifier,

        + it is
          * *NOT* a /constructor/,
          * *NOT* the (*synthetic*) class part of an object,

        + it is a /given instance/ (or an old-style /implicit value/)
          iff the ~export~ is tagged with ~given~.

      - It is a /compile-time error/ if a simple or renaming selector does *not*
        identify any _eligible members_.

      - _Code generation_ triggered by ~export~'s:
        + /Type members/ are aliased by _type definitions_;
        + /Term members/ are aliased by _method definitions_;
        + Export aliases _copy_ the /type and value parameters/ of the members
          they refer to.
        + /Export aliases/ are always ~final~.
        + Aliases of /given instances/ are again defined as /givens/.
        + Aliases of /inline methods/ or values are again defined ~inline~.
        + There are *NO* OTHER /modifiers/ that can be given to an alias.

      - The _Code generation_ rule above has the following *CONSEQUENCES* for
        /overriding/:
        + Export aliases *cannot* be overridden, since they are ~final~.

        + Export aliases *cannot* override /concrete members/ in /base classes/,
          since they are not marked ~override~.

        + However, export aliases *can* _IMPLEMENT_ /deferred members/ (=from Jian=
          I think this term is the same as /abstract members/) of /base classes/.

      - TODO =RE-READ= TODO
        /Export aliases/ for /public value/ definitions that are accessed *WITHOUT
        referring to* /private values/ in the qualifier path are marked by the
        compiler as "stable" and their result types are the /singleton types/ of
        the aliased definitions.
          This means that they can be used as parts of /stable identifier paths/,
        even though they are _technically_ /methods/. For instance, the
        following is OK (_technically_, the consequence of ~export O.c~ generate
        a ~c~ /method/ -- when this is not a /export alias/, it can't be marked
        as stable):
        #+begin_src scala
          class C { type T }
          object O { val c: C = ... }
          export O.c
          def f: c.T = ...
        #+end_src

      - /Export clauses/ *can* appear in /classes/
        /Export clauses/ *can* appear _at the /top-level/._
        /Export clauses/ *CANNOT* appear _as a statement IN A BLOCK_.

      - =from Jian=
        A real world example:
        Sometimes we know something should be /static/, but make it /static/ can
        make the code looks WIERD! Before adding ~export~, we don't have a perfect
        solution. After adding the ~export~ feature, we can get a solution, though
        it is limited, can apply to most of the real world cases with this
        requirement.

        + In Scala 2, if we want to keep /static/ things /static/, we need to
          write like
          #+begin_src scala
            trait Calculator {
              val calculatorName: String
            }

            class AbcCalculator extends Calculator {
              override val calculatorName = AbcCalculator.calculatorName
            }

            object AbcCalculator {
              val calculatorName = "Abc"
            }
          #+end_src

        + In Scala 3, we still keep /static/ things /static/, but we can write
          #+begin_src scala
            trait Calculator {
              val calculatorName: String
            }

            final class AbcCalculator extends Calculator {
              export AbcCalculator.calculatorName
            }

            object AbcCalculator {
              val calculatorName = "Abc"
            }
          #+end_src
          * Of course, for providing a perfect solution like this with ~export~,
            One requirement is satisfied:
            - The being overridden field is /abstract/.

          * Another limitation is that we can't do similar thing to the /subclasses/
            of ~AbcCalculator~ -- the compiler will synthesize /final members/ for
            ~export~ clauses! However, this is not a real limitation -- a good design
            should avoid creating a long inheritance chain. Mostly, none level is
            enough.
            - However, if in future this limitation can be removed or not that strict,
              it is of course better for using. The only thing I doubt is that if this
              will be limited in theory and remove the limitation can create an unsound
              system.

**** DONE Motivation
     CLOSED: [2020-05-18 Mon 02:35]
     - It is a standard recommendation to *prefer composition over inheritance*.
       + This is really an application of /the principle of least power/:
         * /Composition/ treats components as _BLACKBOXES_
           _WHEREAS_
         * /Inheritance/ can _AFFECT the internal workings_ of components through
           /overriding/

       + Sometimes the _close coupling_ implied by /inheritance/ is the best solution
         for a problem, but where this is not necessary the looser coupling of composition
         is better.

     - So far, OO Language including Scala made it much easier to use /inheritance/
       than /composition/, which pushing programmers to a solution that is often
       too powerful (=from Jian= "too powerful" is not a good word in /the principle
       of least power/) as well as complicated (=from Jian= hard to verify in the
       concept of math).
       + For example, in Scala,
         * /inheritance/: Use ~extends~ clause

         * /composition/: Require a verbose elaboration of a sequence of forwarders.
           - =from Jian=
             Introduce ~export~ can mostly reduce one level of forwarders --
             + before: ~def mth = c.mth~
             + now: ~export c.mth~

       + ~export~ clauses redress the balance, and
         make /composition relationships/ *as CONCISE and EASY to* express as
         /inheritance relationships/.
         * Actually, ~export~ clauses is MORE FLEXIBLE than ~extends~ clauses --
           members can be _renamed_ or _ommited_.

         * =from Jian=
           ~export~ has some limitations.
           I'm not sure if the limitations must be there for soundness, but one of
           the reason of their existence that I can guess is with them, the system
           eliminate most of the potential interference between composition (~export~)
           and inheritance (~extends~).

     - /Export clauses/ also fill a gap opened by _the shift from /package objects/
       (DEPRECATED in Scala 3) to /toplevel definitions/._
       + In Scala 2, sometimes /package objects/ is created also with ~extends~ clauses.

       + /Toplevel definitions/ doesn't reside in semantics in a user-defined object,
         so they _can't inherit anyting_. However, ~export~ can be applied in
         toplevel, and make a similar result to the /package object/ _inheritance_ way.

**** DONE Syntax changes
     CLOSED: [2020-05-18 Mon 02:35]
**** TODO Elaboration of Export Clauses
     - Q :: How does the order of elaboration affect type checking?

     - Example:
       #+begin_src scala
         class B { val c: Int }
         object a { val b = new B }
         export a._
         export b._
       #+end_src
       + Q :: Is the ~export b._~ clause legal?
       + Q :: If yes, what does it export?
       + Q :: Is it equivalent to export ~a.b._~?
       + Q :: What about if we swap the last two clauses?
              #+begin_src scala
                export b._
                export a._
              #+end_src

     - A :: To avoid tricky questions like these,
            we _FIX the elaboration order of exports_ as follows.

     - Export clauses are processed when the type information of the enclosing
       object or class is completed. Completion *SO FAR* consisted of the
       following steps: TODO TODO TODO TODO TODO TODO
       1. Elaborate any annotations of the class.

       2. Elaborate the parameters of the class.

       3. Elaborate the self type of the class, if one is given.

       4. Enter all definitions of the class as class members, with types to be
          completed on demand.

       5. Determine the types of all parents of the class.

          *With export clauses, the following steps are added*

       6. Compute the types of all paths in export clauses in a context logically
          inside the class but not considering any imports or exports in that class.

       7. Enter export aliases for the eligible members of all paths in export clauses.

     - Conclusion :: a path of an /export clause/ *cannot* _refer to_ an alias
                     made available by _ANOTHER_ /export clause/ of the _SAME_
                     /class/.

*** DONE Opaque Type Alias
    CLOSED: [2019-09-13 Fri 02:50]
    /Opaque types aliases/ provide type abstraction without any runtime overhead.

    - Example:
      #+begin_src scala
        object Logarithms {

          opaque type Logarithm = Double

          object Logarithm {
            // These are the ways to lift to the Logarithm type

            def apply(d: Double): Logarithm = math.log(d)

            def safe(d: Double): Option[Logarithm] =
              if (d > 0.0) Some(math.log(d)) else None
          }

          // Extension methods define opaque type aliases' public APIs
          extension LogarithmOps on (x: Logarithm) {
            def toDouble: Double = math.exp(x)
            def + (y: Logarithm): Logarithm = Logarithm(math.exp(x) + math.exp(y))
            def * (y: Logarithm): Logarithm = Logarithm(x + y)
          }
        }
      #+end_src
      + ~Logarithm~ is the same as ~Double~ is *only known in the scope where
        ~Logarithm~ is defined* which in this case is object ~Logarithms~.
        * This in scope knowledge of their equivalence is very important!
            Without this knowledge, type-check will say functions ~apply~, ~safe~,
          ~toDouble~, ~+~, and ~*~ have wrong type signature, there there will
          be no simple way to override it.

      + Outside ~Logarithms~, ~Logarithm~ is treated as a _NEW abstract type_.
        * Legal operations example:
          #+begin_src scala
            import Logarithms.Logarithm

            val l = Logarithm(1.0)
            val l2 = Logarithm(2.0)
            val l3 = l1 * l2
            val l4 = l1 + l2
          #+end_src
          - =IMPORTANT=
            The ~import Predef.{any2stringadd => _}~ is necessary!!!
              Without this import clause, the universal ~+~ in ~Predef~ would
            take precedence over the ~+~ extension method in ~LogarithmOps~.
            + Solution: eliminate ~any2stringadd~ -- this is already in DEPRECATED
                        status.

        * Illegal operations example:
          #+begin_src scala
            val d: Double = l        // error: found: Logarithm, required: Double
            val l2: Logarithm = 1.0  // error: found: Double, required: Logarithm
            l * 2                    // error: found: Int(2), required: Logarithm
            l / l2                   // error: `/` is not a member fo Logarithm
          #+end_src

**** Bounds For Opaque Type Alias
     /Opaque type aliases/ can also come with /bounds/.
     Example:
     #+begin_src scala
       object Access {

         opaque type Permissions = Int
         opaque type PermissionChoice = Int
         opaque type Permission <: Permissions & PermissionChoice = Int

         def (x: Permissions) & (y: Permissions): Permissions = x | y
         def (x: PermissionChoice) | (y: PermissionChoice): PermissionChoice = x | y
         def (granted: Permissions).is(required: Permissions): Boolean = (granted & required) == required
         def (granted: Permissions).isOneOf(required: PermissionChoice): Boolean = (granted & required) != 0

         val NoPermission: Permission = 0
         val Read: Permission = 1
         val Write: Permission = 2
         val ReadWrite: Permissions = Read | Write
         val ReadOrWrite: PermissionChoice = Read | Write
       }
     #+end_src
     - The ~Access~ object defines THREE /opaque type aliases/:
       + ~Permission~,       representing a single permission,
       + ~Permissions~,      representing a conjunction (logical "and") of permissions,
       + ~PermissionChoice~, representing a disjunction (logical "or") of permissions.

     - /Type bound/ of ~Permission~ makes it known outside the ~Access~ object that
       ~Permission~ is a /subtype/ of the other two types. Hence, the following
       usage scenario type-checks:
       #+begin_src scala
         object User {
           import Access._

           case class Item(rights: Permissions)

           val roItem = Item(Read)  // OK, since Permission <: Permissions
           val rwItem = Item(ReadWrite)
           val noItem = Item(NoPermission)

           assert(!roItem.rights.is(ReadWrite))
           assert(roItem.rights.isOneOf(ReadOrWrite))

           assert(rwItem.rights.is(ReadWrite))
           assert(rwItem.rights.isOneOf(ReadOrWrite))

           assert(!noItem.rights.is(ReadWrite))
           assert(!noItem.rights.isOneOf(ReadOrWrite))
         }
       #+end_src
       + On the other hand, ~roItem.rights.isOneOf(ReadWrite)~ can't pass the type check.

**** TODO More details
***** Syntax
***** Type Checking
***** Realtionship to SIP 35

*** DONE Open Classes
    CLOSED: [2020-05-14 Thu 01:29]
    An ~open~ /modifier/ on a class signals that the class _is planned for
    extensions_.
    - Example:
      #+begin_src scala
        // File Writer.scala
        package p

        open class Writer[T] {

          /** Sends to stdout, can be overridden */
          def send(x: T) = println(x)

          /** Sends all arguments using `send` */
          def sendAll(xs: T*) = xs.foreach(send)
        }

        // File EncryptedWriter.scala
        package p

        class EncryptedWriter[T: Encryptable] extends Writer[T] {
          override def send(x: T) = super.send(encrypt(x))
        }
      #+end_src

    - An /open class/ typically comes with
      *some documentation that describes the internal calling patterns between
      methods of the class as well as hooks that can be overridden.*
      + We call this the /extension contract/ of the /class/.
        It is DIFFERENT FROM the /external contract/ between a /class/ and its
        users.

    - /Classes/ that are _not open_ *can still be extended*, *but only if* at least
      one of two alternative conditions is met:
      + The /extending class/ is in the *same source file as* the /extended class/.
        In this case, the extension is usually an _internal implementation matter_.

      + The language feature ~adhocExtensions~ is enabled for the extending class.
        If not enabled, the compiler will issue a "feature" warning when it see an
        extension with no ~open~ and not in the same source file.
        * ~import scala.language.adhocExtensions~
        * command line option ~-language:adhocExtensions~

**** DONE Motivation
     CLOSED: [2020-05-14 Thu 01:28]
     - When writing a class, there are _THREE possible expectations_ of
       /extensibility/:
       1. The class is intended to allow extensions.
          This means one should expect
          + a *carefully* worked out (=from Jian= this kind of class is like a public API)
          + *documented* /extension contract/ for the class. (=IMPORTANT=)

       2. Extensions of the class are _forbidden_,
          for instance to make correctness or security guarantees.

       3. There is no firm decision either way.
          The class is not a priori intended for extensions, but if others find
          it useful to extend on an ad-hoc basis, let them go ahead. However,
          they are on their own in this case.
          + Possible issue:
            There is _NO documented /extension contract/,_ and future versions of
            the class might break the extensions (by rearranging internal call
            patterns, for instance =from Jian= this happens in my everyday work).

     - The three cases are clearly distinguished by using
       + ~open~ for 1
       + ~final~ for 2
       + _no modifier_ for 3

     - _It is GOOD PRACTICE to *avoid* ad-hoc extensions in a code base,_
       since they tend to lead to fragile systems that are hard to evolve.

     - But there are _still some situations_ where these extensions are *USEFUL*.
         That's why /ad-hoc extensions/ are permitted, but only if there is an
       explicit opt-in via a language feature import.
       + for instance,
         * to _mock_ classes in tests,
         * to _apply temporary patches_ that add features or fix bugs in library classes.

**** DONE Details
     CLOSED: [2020-05-14 Thu 01:14]
     - ~open~ is a /soft modifier/.
       It is treated as a normal identifier _unless it is in modifier position._

     - An ~open~ /class/ *CANNOT BE* ~final~ or ~sealed~.

     - /Traits/ or /abstract classes/ are *always ~open~,* so ~open~ is redundant
       for them.

**** DONE Relationship with ~sealed~
     CLOSED: [2020-05-14 Thu 01:20]
     - A class that is _NEITHER abstract NOR open_ is SIMILAR TO a /sealed class/:
       it can still be extended, but ONLY _in the same compilation unit_.

     - The _DIFFERENCE_ is what happens
       if an extension of the class is attempted _in another compilation unit_.
       + For a /sealed class/, this is an *error*

       + for a /simple non-open class/, this is still permitted provided
         * the ~adhocExtensions~ feature is enabled
         * otherwise, it gives a *warning*.

**** DONE Migration
     CLOSED: [2020-05-14 Thu 01:16]
     - ~open~ is a NEW modifier in Scala 3.

     - _To allow /cross compilation/ between Scala 2.13 and Scala 3.0 WITHOUT /warnings/,_
       the /feature warning/ for /ad-hoc extensions/ is produced only under ~-strict~.
       + It will be produced by default from Scala 3.1 on.

*** DONE Parameter Untupling
    CLOSED: [2019-12-31 Tue 00:56]
    For data like ~val xs: List[(Int, Int)]~,
    - In Scala 2.x,
      use _EXPLICIT_ /pattern matching/ (partial function) decomposition:
      #+BEGIN_SRC scala
        xs map {
          case (x, y) => x + y
        }
      #+END_SRC

    - Dotty allows the syntax:
      #+BEGIN_SRC scala
        xs map {
          (x, y) => x + y
        }

        // OR, EQUIVALENTLY:
        xs.map(_ + _)
      #+END_SRC

    - Generally, a /function value/ with *n > 1 parameters* is _converted to_ a
      /pattern-matching closure/ using ~case~ if the expected type is a /unary
      function type/ of the form ~((T_1, ..., T_n)) => U~.

**** Reference

*** TODO Kind Polymorphism
*** TODO Tupled Function
**** Tupled Function
**** Examples

*** DONE ~threadUnsafe~ Annotation
    CLOSED: [2019-12-31 Tue 04:24]
    When the compiler see a ~@threadUnsafe lazy val~, it can pick a faster
    mechanism to do the initialization.

    - =from Jian= TODO TODO TODO
      Does this mean before introducing the ~threadUnsafe~ annotation, we only
      have one mechanism that initialize all ~lazy val~ in a /thread safe/
      way???

**** Examples
     #+begin_src scala
       import scala.annotation.threadUnsafe

       class ThreadUnsafeExample {
         @threadUnsafe lazy val x: Int = 1
       }
     #+end_src

*** DONE New Control Syntax
    CLOSED: [2019-12-28 Sat 17:53]
    #+begin_src scala
      if x < 0 then
        "negative"
      else if x == 0
        "zero"
      else
        "positive"

      if x < 0 then -x else x

      while x >= 0 do x = f(x)

      for x <- xs if x > 0
      yield x * x

      for
        x <- xs
        y <- ys
      do
        println(x + y)
    #+end_src
    - The rules in details:
      TODO
      + Two choices for new ~if~ syntax:
        * with a ~then~ that FOLLOWS the ~if~-condition
        * with proper INDENTATION

      + ~while~-loop with ~do~ following the ~while~-condition
        =from Jian=
        Remember:
        ~do ... while~ syntax is removed from Scala 3.
        In Scala 3, ~do~ will only show up in the _new control syntax_.

      + For the enumerators of ~for~-expression,
        * /comprehensions/ still use ~yield~
        * /side effect loops/ use ~do~

**** Rewrites
     The Dotty compiler _can rewrite_ source code bidirectionally
     - old to new: option =-rewrite -new-syntax=
     - new to old: option =-rewrite -old-syntax=

*** TODO Optional Braces
    *As an /experimental feature/,*
    Scala 3 _enforces some rules on indentation_ and _allows some occurrences of
    braces {...} to be optional_.
    1. Some badly indented programs are ruled out, which means they are flagged
       with warnings.

    2. Some occurrences of braces ~{...}~ are made optional.
       Generally, the rule is that adding a pair of optional braces will NOT
       change the meaning of a well-indented program.

**** DONE Indentation Rules
     CLOSED: [2019-12-29 Sun 03:37]
     - The compiler enforces *TWO* rules for well-indented programs, _flagging
       violations as warnings_. =from Jian= WHY NOT Error???
       1. In a brace-delimited region, no statement is allowed to start to the left
          of the first statement after the opening brace that starts a new line.
          This rule is helpful for finding missing closing braces. It prevents
          errors like:
          #+begin_src scala
            if (x < 0) {
              println(1)
              println(2)

              println("done")  // error: indented too far to the left
          #+end_src

       2. If significant indentation is turned off (i.e. under Scala-2 mode or
          under ~-noindent~) and we are at the start of an indented sub-part of an
          expression, and the indented part ends in a newline, the next statement
          must start at an indentation width less than the sub-part. This prevents
          errors where an opening brace was forgotten, as in
          #+begin_src scala
            if (x < 0)
              println(1)
            println(2)   // error: missing `{`
          #+end_src

     - These rules still leave a lot of leeway how programs should be indented.
       For instance, they do *NOT impose* any restrictions on
       + indentation within expressions,
       + all statements of an indentation block line up exactly. TODO =???=
         =???= =???= =???=

     - The rules are _generally helpful in pinpointing_ the root cause of errors
       related to _missing opening or closing braces_.

**** TODO Optinal Braces
**** TODO Optinal Braces Around Template Bodies
**** DONE Spaces vs Tabs
     CLOSED: [2019-12-29 Sun 03:29]
     - _Mix SPACES and TABS is legal._
       However, there is no rule defined about how many SPACES equals to a TAB, or
       vice versa. This means
       + "2 tabs, fllowed by 4 spaces" is strictly less than "2 tabs, followed by
         5 spaces",

       + BUT "2 tabs, followed by 4 spaces" is *incomparable*
         * to "6 tabs"
           or
         * to "4 spaces, followed by 2 tabs".

     - *CAUTION*:
       NOT all the legal ways are recommended!!!
       *Do NOT MIX Spaces and Tabs!!!*

**** TODO Indentation and Braces
**** DONE Special Treatment of Case Clauses - TODO
     CLOSED: [2019-12-29 Sun 03:34]
     - NOTE NOTE NOTE
       Rules for ~match~ and ~catch~

     - Legal form (the ~println~ in example do not belong to ~match~ block)
       + Next leval indentation:
         #+begin_src scala
           x match
             case 1 => print("I")
             case 2 => print("II")
             case 3 => print("III")
             case 4 => print("IV")
             case 5 => print("V")

           println(".")
         #+end_src

       + Same level indentation:
         #+begin_src scala
           x match
           case 1 => print("I")
           case 2 => print("II")
           case 3 => print("III")
           case 4 => print("IV")
           case 5 => print("V")

           println(".")
         #+end_src

**** TODO The End Marker
***** TODO When to Use End Markers
***** TODO Syntax

**** TODO Example
**** TODO Settings and Rewrites
**** TODO Variant: Indentation Marker ~:~
     NOT STABLE -- Learn when this feature is stable!!!

*** TODO Explicit Nulls
    Explicit nulls is an /opt-in feature/ that _modifies the Scala type system_,
    which *makes /reference types/ (anything that extends ~AnyRef~) non-nullable.*

    - opt-in feature :: A feature need to enabled via a flag.
      + For this /explicit nulls/ feature, the flag is ~-Yexplicit-nulls~.

    - After introducing this feature, some old style code will no longer typecheck:
      #+begin_src scala
        val x: String = null  // error: found `Null`, but required `String`
      #+end_src

      Instead, if consider the code above is a piece of Scala 2 code which can
      typecheck, translate it into Scala 3 form:
      #+begin_src scala
        val x: String | Null = null
      #+end_src

**** DONE New Type Hierarchy
     CLOSED: [2019-12-31 Tue 04:05]
     - NEW - Without /explicit nulls/:
       ~Null~ is the subtype of all ~AnyRef~ subtypes.
       The only subtype of ~Null~ is the /bottom type/ ~Noting~.

     - OLD - With /explicit nulls/:
       ~Null~ is a subtype of ~Any~.
       Its only subtype doesn't change, still ~Noting~.

     - Of course, the /NEW type hierarchy/ descried above is the one for typechecker
       -- before /type erasure/.
         After /type erasure/, ~Null~, as JVM enforced, remains a /subtype/ of
       all /reference types/

**** DONE Unsoundness
     CLOSED: [2020-03-21 Sat 02:26]
     The new type system is unsound with respect to ~null~.
     Enforcing /sound initialization/, which is can be done, is a non-goal of
     this proposal.

     - The /unsoundness/ happens because uninitialized fields in a class start out
       as ~null~:
       #+begin_src scala
         // -Yexplicit-nulls
         class C with
           val f: String = foo(f)
           def foo(f2: String): String = f2

         val c = new C
         // c.f == "field is null"
       #+end_src

**** DONE Equality
     CLOSED: [2019-12-31 Tue 02:43]
     - NOT Allowed:
       Compare a value of ~AnyRef~ /subtypes/ with ~null~ is not allowed!!!
       The related operators are ~==~, ~!=~, ~eq~, and ~ne~.

     - ~null~ can _only_ be compared with values of type
       + ~Null~
       + nullable union ~(T | Null)~
       + ~Any~ type.

     - For some reason, if we really want to compare ~null~ with non-null values,
       we can use /cast/. For example,
       #+begin_src scala
         val x: String = ???
         val y: String | Null = ???

         x == null        // error: Values of types String and Null cannot be compared with == or !=
         x eq null        // error
         "hello" == null  // erro

         y == null  // ok
         y == x     // ok

         (x: String | Null) == null  // ok
         (x: Any) == null            // ok
       #+end_src

**** DONE Working with ~Null~
     CLOSED: [2019-12-31 Tue 04:01]
     To make working with nullable values easier, we *propose* adding a few
     utilities to the standard library. So far, we have found the following
     useful:
     - An extension method ~.nn~ to "cast away" nullability
       #+begin_src scala
         def[T] (x: T|Null) nn: x.type & T =
           if (x == null) throw new NullPointerException("tried to cast away nullability, but value is null")
           else           x.asInstanceOf[x.type & T]
       #+end_src
       This means that given ~x: String|Null~, ~x.nn~ has type ~String~, so we
       can call all the usual methods on it. Of course, ~x.nn~ will _throw a
       NPE_ if ~x~ is ~null~.
         *Don't use ~.nn~ on /mutable variables/ DIRECTLY*, which may introduce
       unknown value into the type. TODO TODO TODO ???

**** TODO Java Interop
***** ~UncheckedNull~

**** TODO Flow Typing
***** Logical Operators
***** Inside Conditions
***** Match Case
***** Mutable Variable
***** Unsupported Idioms

**** TODO Binary Compatibility

*** TODO Safe Initialization
    Dotty implements experimental safe initialization check, which can be
    enabled by the compiler option ~-Ycheck-init~.

**** A Quick Glance
***** Parent-Child Interaction
***** Inner-Outer Interaction
***** Functions

**** Design Goals
**** Principles and Rules
**** Modularity
**** Theory
**** Back Doors
**** Caveats
**** References

** TODO OTHER CHANGED FEATURES
*** TODO Numeric Literals
**** Meaning of Numeric Literals
**** The ~FromDigits~ Class
**** Error Handling
**** Example
**** Compile-Time Errors

*** DONE Structural Types
    CLOSED: [2020-01-18 Sat 14:23]
    # *Programmatic Structural Types*
    - Some usecases are more awkward in statically typed languages than in
      dynamically typed languages

    - Example: modelling database access
      1. With dynamically typed languages, it's quite natural to _model a /row/ as
         a /record/ or /object/_, and to select entries with simple dot notation
         (e.g. ~row.columnName~).

      2. Achieving the same experience in /statically typed language/ requires
         + defining a class for every possible row arising from database manipulation
           (including rows arising from joins and projections)
         + setting up a scheme to map between a row and the class representing it.

      3. This requires a large amount of boilerplate, which leads developers
         to trade the advantages of static typing for simpler schemes where
         colum names are represented as strings and passed to other operators
         (e.g. ~row.select("columnName")~). _This approach is unatural in both
         sides_
         + forgoes the advantages of static typing,
         + is still not as natural as the dynamically typed version.

    - Structural types help in situations where we would like to support simple
      dot notation in dynamic contexts without losing the advantages of static
      typing.
        They allow developers to use dot notation and configure how fields and
      methods should be resolved.

**** Example
     #+begin_src scala
       object StructuralTypeExample {
         case class Record(elems: (String, Any)*) extends Selectable {
           def selectDynamic(name: String): Any = elems.find(_._1 == name).get._2
         }

         type Person = Record {
           val name: String
           val age: Int
         }

         def main(args: Array[String]): Unit = {
           val person = Record("name" -> "Emma", "age" -> 42).asInstanceOf[Person]
           println(s"${person.name} is ${person.age} years old.")
           // Prints: Emma is 42 years old.
         }
       }
     #+end_src

**** Extensibility
     New instances of ~Selectable~ can be defined to *support means of access*
     _othr than_ /Java reflection/, which would enable usages such as the
     database access example given at the beginning of this document.

**** TODO Relation with ~scala.Dynamic~
     TODO =from Jian= I need to learn more about ~scala.Dynamic~

*** DONE Operators
    CLOSED: [2020-01-18 Sat 16:07]
    *Rules for Operators*
**** DONE The ~@alpha~ Annotation
     CLOSED: [2020-01-18 Sat 14:52]
     - ~@alpha~ annotation :: it is applied on a /method definition/ defines an
       _alternate name_ for the implementation of that method.

     - Example:
       #+begin_src scala
         object VecOps {
           @alpha("append") def (xs: Vec[T]) ++= [T] (ys: Vec[T]): Vec[T] = // ...
         }
       #+end_src
       + The ~++=~ operation is implemented (in bytecode or native code) under
         the name ~append~.

     - The /implementation name/
       + affects the code that is generated
       + is the name under which code _from OTHER languages_ can call the method.
         *ONLY from OTHER languages! You can't use the name in Scala.*
         For instance, ~++=~ could be invoked from Java like this:
         #+begin_src java
           VecOps.append(vec1, vec2)
         #+end_src

     - An ~@alpha~ /annotation/ will be *MANDATORY*
       _if the /method name/ is symbolic_!!!
       + Symbolic name methods without ~@alpha~ annotation are *DEPRECATED*.

***** Motivation
      The ~@alpha~ annotation serves a dual purpose:
      + It helps *interoperability* between Scala and other languages.
      + It serves _as a documentation tool_ by providing an alternative regular
        name as an alias of a symbolic operator.

***** Details
      1. Syntax:
         ~@scala.annotation.alpha(externalName)~.
         ~externalName~ is a string.

      2. An ~@alpha~ annotation can be given for all kinds of definitions.
         _NOT ONLY for symbolic method._

      3. ~externalName~ must be a legal name on the host platform.

      4. Lack of an ~@alpha~ annotation will raise a _deprecation warning_.

      5. Definitions with names in backticks that are not legal host platform
         names should have an ~@alpha~ annotation. Lack of such an annotation
         will raise a deprecation warning.
         =from Jian= TODO EXAMPLE???

      6. ~@alpha~ annotations must agree:
         *There must be a one-to-one relationship between external and internal
         names*

**** DONE The ~@infix~ Annotation
     CLOSED: [2020-01-18 Sat 15:23]
     - ~@infix~ annotation :: it is applied on a /method definition/ allows using
       the method as an _infix operation_.

     - Example:
       #+begin_src scala
         trait MultiSet[T] {
           @infix
           def union(other: MultiSet[T]): MultiSet[T]

           def difference(other: MultiSet[T]): MultiSet[T]

           @alpha("intersection")
           def *(other: MultiSet[T]): MultiSet[T]
         }

         val s1, s2: MultiSet[Int]

         s1 union s2   // OK
         s1.union(s2)  // also OK

         s1.difference(s2)   // OK
         s1 `difference` s2  // OK
         s1 difference s2    // gives a deprecation warning

         s1 * s2   // OK
         s1.*(s2)  // also OK, but unusual
       #+end_src
       + *Infix operations involving alphanumeric operators are deprecated*,
         unless one of the following conditions holds:
         * the operator definition carries an ~@infix~ annotation, or
         * the operator was compiled with Scala 2, or
         * the operator is followed by an opening brace. TODO ??? TODO

     - alphanumeric operator :: an operator *consisting ENTIRELY* of
       + letters
       + digits
       + ~$~
       + ~_~
       + any unicode character for which ~java.lang.Character.isIdentifierPart(c)~
         returns ~true~.

     - /Infix operations/ involving /symbolic operators/ are *ALWAYS* allowed, so
       ~@infix~ is redundant for methods with _symbolic names_.

     - The ~@infix~ annotation can also _be given to a /type/:_
       #+begin_src scala
         @infix type or[X, Y]
         val x: String or Int
       #+end_src

***** Motivation
      The purpose of the @infix annotation is to achieve consistency across a
      code base in how a method or type is applied. The idea is that the author
      of a method decides whether that method should be applied as an infix
      operator or in a regular application. Use sites then implement that
      decision consistently.

***** Details
      1. ~@scala.annotation.infix~

      2. ~@infix~ annotations must agree when overriding.

      3. The first non-receiver parameter list of an ~@infix~ method must define
         exactly one parameter. For example,
         #+begin_src scala
           @infix def op(x: S): R                  // OK
           @infix def op[T](x: T)(y: S): R         // OK
           @infix def op[T](x: T, y: S): R         // error: two parameters

           @infix def (x: A) op (y: B): R          // OK
           @infix def (x: A) op (y1: B, y2: B): R  // error: two parameters
         #+end_src

      4. ~@infix~ annotations can also be given to /type/, /trait/ or /class/
         definitions that have exactly _two type parameters_. An /infix type/
         like
         #+begin_src scala
           @infix type op[X, Y]
         #+end_src
         can be applied using infix syntax, i.e. ~A op B~

      5. To smooth migration to Scala 3.0, alphanumeric operations will only be
         deprecated from Scala 3.1 onwards, or if the ~-strict~ option is given
         in Dotty/Scala 3.

**** DONE Syntax Change
     CLOSED: [2020-01-18 Sat 16:07]
     Infix operators can now appear at the start of lines in a multi-line expression.
     Thanks to the change of semicolon inference.

     - Illustrate by examples:
       + The leading infix operator should be followed by at least one space
         character (=from Jian= and then another operand).
         #+begin_src scala
           freezing
           | boiling
         #+end_src

       + No space, no infix operation
         #+begin_src scala
           freezing
           !boiling
         #+end_src

       + No following legal operand
         #+begin_src scala
           println("hello")
           ???
           ??? match { case 0 => 1 }
         #+end_src
         * The second line ~???~ doesn't have a following operand.
         * The thrid line ~???~ doesn't have a legal following operand -- ~match~
           is not a token that can start an expression.

*** DONE Wildcard Types - =RE-READ=
    CLOSED: [2020-05-25 Mon 12:50]
    # Wildcard Arguments in Types
    - The syntax of /wildcard arguments in types/ has *changed* FROM ~_~ TO ~?~.

    - Examples:
      + ~List[?]~
      + ~Map[? <: AnyRef, ? >: Null]~

**** Motivation
     =from Jian=
     Give ~_~ syntax another semantics, and make semantics more consistent and
     flexible. One of the reason that Scala want to do this is that there exists
     a better synbol can convey the current ~_~ semantics -- ~?~. After doing this
     ~?~ in both Java and Scala has the same semantics.

     - We would like to use the underscore syntax ~_~ to stand for an /anonymous
       type parameter/, *aligning* it with its meaning in value parameter lists.
       So, just as ~f(_)~ is a shorthand for the lambda ~x => f(x)~ (we current
       have this in Scala 2), _in the future_ ~C[_]~ will be _a shorthand for the
       /type lambda/ ~[X] =>> C[X]~._
       + TODO This makes higher-kinded types easier to use. TODO

     - The new ~_~ semantics also *removes the wart* that,
       + used AS a /type parameter/, ~F[_]~ means ~F~ is a /type constructor/

       + WHEREAS used AS a /type/, ~F[_]~ means it is a /wildcard (i.e. existential)
         type/.
         =from Jian= this will become ~F[?]~ TODO ??? TODO

     - In the future, ~F[_]~ will mean the same thing, no matter where it is used.

     - We pick ~?~ as a _REPLACEMENT syntax_ for /wildcard types/, since it
       _ALIGNS WITH Java's syntax._

**** Migration Strategy
     - The migration to the new scheme is *complicated*,
       in particular since the /kind projector compiler plugin/ still uses the
       _reverse convention_, with ~?~ meaning /parameter placeholder/ _INSTEAD
       OF_ /wildcard/.
       + Fortunately, kind projector has added ~*~ as an *ALTERNATIVE syntax* for
         ~?~.

     - A step-by-step migration is made possible with the following measures:
       * _In Scala 3.0_,
         both ~_~ and ~?~ are legal names for /wildcards/.

       * _In Scala 3.1_,
         ~_~ is deprecated in favor of ~?~ as a name for a /wildcard/.
         A ~-rewrite~ option is available to rewrite one to the other.

       * _In Scala 3.2_,
         the meaning of ~_~ changes _FROM_ /wildcard/ _TO_ /placeholder for type
         parameter/.

       * The _Scala 3.1_ behavior is already available today under the ~-strict~
         setting.

     - To smooth the transition for codebases that use *kind-projector*, we adopt
       the following measures under the command line option ~-Ykind-projector~:
       + In Scala 3.0,
         ~*~ is _available_ as a /type parameter placeholder/.

       + In Scala 3.2,
         ~*~ is *DEPRECATED* in favor of ~_~.
         A ~-rewrite~ option is available to rewrite one to the other.

       + In Scala 3.3,
         ~*~ is *REMOVED* again, and all /type parameter placeholders/ will be
         expressed with ~_~.

     - These rules make it possible to cross build between Scala 2 using the
       /kind projector/ plugin and Scala 3.0 - 3.2 using option ~-Ykind-projector~.

*** TODO Type Checking - =No Doc till now=
    *Type Checking*
    - [//]:# todo: fill in

*** TODO Type Inference - =No Doc till now=
    *Changes in Type Inference*
    - [//]:# todo: fill in

*** TODO Implicit Resolution
    # Changes in Implicit Resolution

*** TODO Implicit Conversions
**** Examples

*** TODO Overload Resolution - TODO =READING=
    # Changes in Overload Resolution
    /Overload resolution/ in Dotty *improves* on Scala 2 in _TWO_ ways.
    - it takes *ALL* /argument lists/ into account
      _instead of_
      just the *first* /argument list/.

    - it can *infer* /parameter types/ of /function values/ *even if they are in
      the _FIRST_ /argument list/.*

**** Looking Beyond the First Argument List
     - Example:
       Code legal in Dotty, while it results in an ambiguous overload error in Scala 2:
       + Example 1:
         #+begin_src scala
           def f(x: Int)(y: String): Int = 0
           def f(x: Int)(y: Int): Int = 0

           f(3)("")
         #+end_src

       + Example 2:
         #+begin_src scala
           def g(x: Int)(y: Int)(z: Int): Int = 0
           def g(x: Int)(y: Int)(z: String): Int = 0

           g(2)(3)(4)     // ok
           g(2)(3)("")    // ok
         #+end_src

     -

**** Parameter Types of Function Values

*** DONE Match Expressions
    CLOSED: [2020-05-24 Sun 22:53]
    The /syntactical precedence/ of /match/ expressions has been *changed*.

    - ~match~ is still a keyword,
      but it is used like an /alphabetical operator/.

    - This has several consequences:
      1. ~match~ expressions can be chained:
         #+begin_src scala
           xs match {
             case Nil    => "empty"
             case h :: t => "nonempty"
           } match {
             case "empty"    => 0
             case "nonempty" => 1
           }
         #+end_src

      2. ~match~ may follow a /period/: =TODO= check the concept of /period/
         #+begin_src scala
           if xs.match {
             case Nil => false
             case _   => true
           }
           then "nonempty"
           else "empty"
         #+end_src

      3. The scrutinee of a ~match~ expression must be an ~InfixExpr~.
         + Previously the scrutinee could be _followed by_ a type ascription ~: T~,
           but this is *no longer supported*.

         + So ~x : T match { ... }~ in Scala 3 now has to be written
           ~(x: T) match { ... }~.

**** Syntax

*** DONE Vararg Patterns
    CLOSED: [2020-05-24 Sun 23:01]
    The syntax of /vararg patterns/ has changed.
    - In the _NEW syntax_ one writes /varargs/ in patterns _EXACTLY LIKE_ one writes
      them in expressions, using ~a : _*~ type annotation:
      + NEW:
        #+begin_src scala
          xs match {
            case List(1, 2, xs: _*) => println(xs)  // binds xs
            case List(1, _: _*)     =>              // wildcard pattern
          }
        #+end_src

      + OLD:
        it is shorter but _less regular_, and it no longer supported.
        #+begin_src scala
          /*!*/  case List(1, 2, xs @ _*) =>  // syntax error
          /*!*/  case List(1, _ @ _*)     =>  // syntax error
        #+end_src

**** Compatibility considerations
     - To enable smooth cross compilation between Scala 2 and Scala 3, Dotty will
       accept both the old and the new syntax.

     - Under the ~-strict~ setting,
       an error will be emitted when the old syntax is encountered.

     - The ~-strict~ setting will be _enabled by default in version 3.1 of the
       language._

*** DONE Pattern Bindings
    CLOSED: [2020-05-25 Mon 11:03]
    - In Scala 2, /pattern bindings/ in ~val~ definitions and ~for~ expressions are
      *LOOSELY typed*.
      + Potentially failing matches are still _ACCEPTED at /compile-time/,_
        but may influence the program's /runtime/ behavior.

    - From Scala 3.1 on, /type checking/ rules will be tightened so that _errors
      are *REPORTED* at /compile-time/ instead._

**** Bindings in Pattern Definitions
     - Exmaple 1:
       _Code that can pass Scala 2 /type checking/ but fail at /runtime/_
       #+begin_src scala
         val xs: List[Any] = List(1, 2, 3)
         val (x: String) :: _ = xs
       #+end_src
       + This code gives a compile-time error in Scala 3.0 with the ~-strict~
         setting or Scala 3.1 by default.

       + It will fail at runtime with a ~ClassCastException~ in Scala 2.

     - In Scala 3.1, a /pattern binding/ is *ONLY allowed* if the pattern is
       /irrefutable/, that is, if the right-hand side's type CONFORMS TO the
       pattern's type.
       + For instance, the following is OK:
         #+begin_src scala
           val pair = (1, true)
           val (x, y) = pair
         #+end_src

     - Exmaple 2:
       Sometimes one wants to decompose data anyway, even though the pattern is
       /refutable/.

       For instance, if at some point one knows that a list elems is non-empty
       one might want to decompose it like this:
       #+begin_src scala
         val first :: rest = elems  // error in Scala 3.1; work in Scala 2
       #+end_src
       + Use ~@unchecked~ to avoid the error:
         ~val first :: rest : @unchecked = elems~

**** Pattern Bindings in For Expressions
     - In Scala 2, /pattern bindings/ in ~for~ expressions do _implicit filtering_,
       and filter out data that are not matched.
       + In Scala 3, apply this _implicit filtering_ *ONLY when* a ~case~ shows up
         before the pattern -- this is a new syntax! Scala 2 syntax no longer has
         the implicit filtering semantics.

     - Example (in Scala 3.1):
       + Usage in Scala 2 can fail becuase of the semantics change.
         #+begin_src scala
           val elems: List[Any] = List((1, 2), "hello", (3, 4))
           for ((x, y) <- elems) yield (y, x) // error: pattern's type (Any, Any) is more specialized
                                              // than the right hand side expression's type Any
         #+end_src

       + Make implicit filtering available by using the ~case~:
         #+begin_src scala
           for (case (x, y) <- elems) yield (y, x)  // returns List((2, 1), (4, 3))
         #+end_src

**** Syntax Changes
     There are *TWO syntax CHANGES* relative to Scala 2:
     - /pattern definitions/ can carry ascriptions such as ~: @unchecked~.
     - /generators/ in ~for~ expressions may be prefixed with ~case~.

**** Migration
     - The new syntax is supported in Dotty and Scala 3.0.

     - However, to enable smooth cross compilation between Scala 2 and Scala 3,
       + In Scala 3.0, the changed behavior and additional type checks are *only
         enabled under the ~-strict~ setting*.

       + In Scala 3.1+, they will be enabled by default.

*** TODO Pattern Matching - =Further simplification will come, no need to read now=
    # Option-less pattern matching
    - CAUTION:
      *There are plans for further simplification*,
      in particular to factor out /product match/ and /name-based match/ into a
      SINGLE type of /extractor/.

**** Extractors
***** Fixed-Arity Extractors
***** Variadic Extractors

**** Boolean Match
**** Product Match
**** Single Match
**** Name-based Match
**** Sequence Match
**** Product-Sequence Match

*** DONE Eta Expansion
    CLOSED: [2020-05-25 Mon 10:20]
    # Automatic Eta Expansion
    The _conversion of METHODS into FUNCTIONS_ has been improved and happens
    *automatically* for /methods/ with one or more parameters.
    - Example:
      #+begin_src scala
        def m(x: Boolean, y: String)(z: Int): List[Int]
        // automatically create a function value of type
        // `(Boolean, String) => Int => List[Int]`
        // without explicit type annotation.
        val f1 = m

        // automatically create a function value of type
        // `Int => List[Int]`
        // without explicit type annotation.
        val f2 = m(true, "abc")
      #+end_src

    - The syntax ~m \under{}~ *is _NO LONGER_ needed* and *will be _DEPRECATED_ in the future.*

**** Automatic eta-expansion and nullary methods
     /Automatic eta expansion/ does *NOT apply* to /"nullary" methods/ that take
     an empty parameter list.
     - Given a simple reference to ~next~ does *NOT auto-convert* to a function.
       One has to write explicitly ~() => next()~ to achieve that
       + Once again since the ~_~ _is going to be DEPRECATED_ it's better to write
         it this way rather than ~next _~.

     - The _REASON_ for *excluding* /nullary methods/ from /automatic eta expansion/:
       that Scala implicitly inserts the ~()~ argument, which would *conflict* with
       /eta expansion/.
       + _Automatic ~()~ insertion_ is _limited_ (see "Dropped: Auto-Application)
         in Dotty, but the fundamental ambiguity remains.

*** TODO Compiler Plugins
    # Changes in Compiler Plugins

**** Using Compiler Plugins
**** Writing a Standard Compiler Plugin
**** Writing a Research Compiler Plugin

*** TODO Lazy Vals initialization
**** Motivation
**** Implementation
**** Note on recursive lazy vals
**** Reference
     - SIP-20

*** DONE Main Functions
    CLOSED: [2020-05-24 Sun 22:31]
    Scala 3 offers a new way to define programs that can be invoked from the command line:
    _A ~@main~ /annotation/ on a /method/ turns this /method/ into an executable program._

    - Example:
      #+begin_src scala
        @main def happyBirthday(age: Int, name: String, others: String*): Unit = {
          val suffix =
            (age % 100) match {
              case 11 | 12 | 13 => "th"
              case _ =>
                (age % 10) match {
                  case 1 => "st"
                  case 2 => "nd"
                  case 3 => "rd"
                  case _ => "th"
                }
            }

          val bldr = new StringBuilder(s"Happy $age$suffix birthday, $name")
          for other <- others do bldr.append(" and ").append(other)
          bldr.toString
        }
      #+end_src
      This would generate a main program ~happyBirthday~ that could be called like this
      #+begin_src bash
        scala happyBirthday 23 Lisa Peter
        # Happy 23rd Birthday, Lisa and Peter!
      #+end_src

    - A ~@main~ annotated method can be written either
      + at the top-level
        OR
      + in a statically accessible object.

    - Parameters of the ~@main~ method:
      + the ~@main~ method can have an _ARBITRARY number_ of parameters.

      + For each parameter type there *must be* an instance of the
        ~scala.util.FromString~ /type class/ that is used to
        _convert_ an *argument string* _to_ the *required parameter type*.

      + The _parameter list_ of a ~@main~ method can end in a repeated parameter
        that then takes all remaining arguments given on the command line.

    - The program implemented from a @main method checks that there are enough
      arguments on the command line to fill in all parameters, and that argument
      strings are convertible to the required types. If a check fails, the
      program is terminated with an error message.
      + Examples:
        #+begin_src bash
          scala happyBirthday 22
          # Illegal command line after first argument: more arguments expected

          scala happyBirthday sixty Fred
          # Illegal command line: java.lang.NumberFormatException: For input string: "sixty"
        #+end_src

    - Code generation:
      The Scala compiler generates a program from a ~@main~ method ~f~ as follows:
      1. It creates a /class/
         * name ~f~
         * in the package where the ~@main~ method was found

      2. The generated /class/ has a /static method/ ~main~ with the *usual*
         /signature/: it takes an ~Array[String]~ as argument and returns ~Unit~.

      3. The generated ~main~ /method/
         * calls /method/ ~f~ with arguments converted using methods in the
           ~scala.util.CommandLineParser~ object.

    - Code generation example:
      #+begin_src scala
        final class happyBirthday {
          import scala.util.{CommandLineParser => CLP}
          <static> def main(args: Array[String]): Unit =
            try
              happyBirthday(
                CLP.parseArgument[Int](args, 0),
                CLP.parseArgument[String](args, 1),
                CLP.parseRemainingArguments[String](args, 2))
            catch {
              case error: CLP.ParseError => CLP.showError(error)
            }
        }
      #+end_src
      NOTE:
      The ~<static>~ modifier above expresses that the main method is
      generated as a /static method/ of /class/ ~happyBirthDay~.
        It is *NOT* available for user programs in Scala. Regular "static"
      members are generated in Scala using objects instead.

    - ~@main~ methods are the recommended scheme to generate programs that can be
      invoked from the command line in Scala 3.

    - They replace the previous scheme to write program as objects with a special
      ~App~ parent class. In Scala 2, ~happyBirthday~ could be written also like this:
      #+begin_src scala
        object happyBirthday extends App {
          // needs by-hand parsing of arguments vector
          // ...
        }
      #+end_src
      + The previous functionality of ~App~, which relied on the "magic"
        ~DelayedInit~ trait, is *no longer available*.

      + ~App~ still exists in limited form for now,
        but
        * it does *not support* /command line arguments/
        * it will be *deprecated* in the future.

      + If programs need to *cross-build* between Scala 2 and Scala 3,
        it is *RECOMMENDED* to use an _EXPLICIT_ ~main~ method with an
        ~Array[String]~ argument instead.

** TODO DROPPED FEATURES
*** DelayedInit
    # *Dropped: DelayedInit*

*** Macros
    # *Dropped: Scala 2 Macros*

*** Existential Types
    # *Dropped: Existential Types*

*** Type Projection
    # *Dropped: General Type Projection*

*** Do-While
    # *Dropped: Do-While*

*** Procedure Syntax
    # *Dropped: Procedure Syntax*

*** Package Objects
    # *Dropped: Package Objects*

*** Early Initializers
    # *Dropped: Early Initializers*

*** Class Shadowing
    # *Dropped: Class Shadowing*

*** TODO Limit 22
    # *Dropped: Class Shadowing*

*** XML Literals
    # *Dropped: XML Literals*

*** TODO Symbol Literals
    # *Dropped: Symbol Literals*

*** Auto-Application
    # *Dropped: Auto-Application*
**** Migrating code
**** Reference

*** Weak Conformance
    # *Dropped: Weak Conformance*

*** Nonlocal Returns
    # *Deprecated: Nonlocal Returns*

*** DONE ~[this]~ Quanlifier
    CLOSED: [2020-04-30 Thu 12:49]
    # *Dropped: ~private[this]~ and ~protected[this]~*
    The ~private[this]~ and ~protected[this]~ /access modifiers/ are *deprecated*
    and will be phased out.

    - Previously, these /modifier/ were needed
      + for *avoiding the generation* of /getters/ and /setters/ (~private[this]~
        ONLY).

      + for *excluding from variance checks* (~private[this]~ ONLY).
        * Scala 2 also excludes ~protected[this]~ but this was found to be unsound
          and was therefore removed.
          TODO More details and examples about the unsoundness!!! TODO

    - _REASON_ of Dropped:
      + The compiler now *can infers for ~private~ members the fact that they are ONLY
        accessed via ~this~.* Such members are treated as if they had been declared
        ~private[this]~ -- the previous requirements can be satisfied without manually
        write ~[this]~ out.

      + ~protected[this]~ is dropped without a replacement.
        =from Jian=
        The only requirement for ~protected[this]~ is to tell the compiler NOT
        do /variance checks/, which is already been pointed out that it is unsound!
        Therefore, the requirement is not real.

    - TODO
      =from Jian=
      Learn more about this. There are more discussion about this topic.

* CONTRIBUTING
** Contribute Knowledge
*** Contribute Internals-related Knowledge

** Getting Started
*** Requirements
*** Compiling and Running
*** Starting a REPL
*** Generating Documentation

** Workflow
*** Compiling files with dotc
*** Inspecting Trees with Type Stealer
*** Pretty-printing
*** SBT Commands Cheat Sheet

** Testing
*** Unit tests
**** Testing with checkfiles

*** Integration tests
**** Bootstrapped-only tests
**** From TASTy tests

** Debugging
*** Setting up the playground
*** Show for human readable output
*** How to disable color
*** Reporting as a non-intrusive println
*** Printing out trees after phases
*** Printing out stack traces of compile time errors
*** Configuring the printer output
*** Figuring out an object creation site
**** Via ID
**** Via tracer

*** Built-in Logging Architecture
**** Printers
**** Tracing
**** Reporter

** IDEs and Tools
*** Mill
*** Scalafix

** Procedures
*** Release Model
**** Model
**** Example
***** At the Dotty Repo
***** At the CI
****** Canceling CI builds

***** Documentation
****** Release Procedure Checklist
****** GitHub Releases and Blog Post

***** Ecosystem

**** Procedure in Bash Scripts

*** Modifying the Test framework
    *Test Vulpix Framework*

* INTERNALS
** Backend
*** Data Flow
*** Architecture
**** (a) The queue subsystem
**** (b) Bytecode-level types, ~BType~
**** (c) Utilities offering a more "high-level" API to bytecode emission
**** (d) Mapping between type-checker types and ~BType~'s
**** (e) More "high-level" utilities for bytecode emission
**** (f) Building an ASM ~ClassNode~ given an AST ~TypeDef~

** Classpaths
** Core Data Structrues
*** Symbols and SymDenotations
*** Why is this important?
*** Are We Done Yet?
*** What Are the Next Steps?

** Contexts
*** Contexts in the typer
*** In other phases
*** Using contexts

** Dotc vs Scalac
   # Differences between Dotc and Scalac
*** Denotation
**** Denotation vs. SymDenotation
**** Implicit Conversion

*** Symbol
*** Flags
*** Tree
*** Type

** Higher-Kinded Types
   *This page is out of date and preserved for posterity. Please see
   Implementing Higher-Kinded Types in Dotty for a more up to date version*

*** Higher-Kinded Types in Dotty V2
**** The duality
**** Named type parameters
**** Wildcards
**** Type parameters in the encodings
**** Partial applications
**** Modelling polymorphic type declarations
**** Modelling polymorphic type aliases: simple case
**** Modelling polymorphic type aliases: general case
**** Modelling higher-kinded types
**** Full example
**** Status of ~#~

** Overall Structure
   # Dotty Overall Structure
*** Package Structure
*** Contexts
*** Compiler Phases

** Periods
   # Dotc's concept of time*

** Syntax
   # Scala Syntax Summary
*** Lexical Syntax
*** Keywords
**** Regular keywords
**** Soft keywords

*** Context-free Syntax
**** Literals and Paths
**** Types
**** Expressions
**** Type and Value Parameters
**** Bindings and Imports
**** Declarations and Definitions

** Type System
*** Class diagram
*** Proxy types and ground types
*** Representations of types
**** Representation of methods

*** Subtyping checks
**** Type rebasing

*** Type caching
    # TODO

*** Type inference via constraint solving
    # TODO

** Dotty Internals 1: Trees & Symbols (Meeting Notes)
*** Entry point
*** Phases
*** Trees
**** Untyped trees
**** Typed trees
**** Notes on some tree types
***** ThisTree

**** Creating trees
**** Meaning of trees
**** Errors
**** Assignment

*** Symbols
**** ~ClassSymbol~
**** ~SymDenotation~

** Debug Macros
*** position not set
*** unresolved symbols in pickling

* RESOURCES
*** Talks
**** Talks on Dotty
**** Deep Dive with Dotty
     :PROPERTIES:
     :ID:       b5b2ba1a-6e8d-4f0c-a3c4-14f0e17ee56a
     :END:
* TODO API
** dotty
*** (O) ~DottyPredef~

*** dotty.internal
**** (O) ~CompileTimeMacros~
**** (O) ~StringContextMacro~

*** dotty.runtime
**** (O) ~Arrays~
**** (O) ~LazyVals~

** scala
*** (C) ~*:~
*** (C) ~Conversion~
*** (O) ~EmptyTuple~
*** (T) ~Enum~
*** (T) ~Eql~
*** (T) ~FunctionXXL~
*** (T) ~NonEmptyTuple~
*** (T) ~PolyFunction~
*** (T) ~Product0~
*** (T) ~Selectable~
*** (T) ~Tuple~
*** (T) ~TupledFunction~
*** (O) ~deriving~
*** (C) ~main~
*** (O) ~opaques~

*** scala.annotation
**** (T) ~RefiningAnnotation~
**** (C) ~alpha~
**** (C) ~constructorOnly~
**** (C) ~infix~
**** (C) ~static~
**** (C) ~superTrait~
**** (C) ~threadUnsafe~

*** scala.annotation.internal
**** (C) ~Alias~
**** (C) ~AnnotationDefault~
**** (C) ~Body~
**** (C) ~Child~
**** (C) ~ContextResultCount~
**** (C) ~InlineParam~
**** (C) ~Repeated~
**** (C) ~SourceFile~
**** (C) ~WithBounds~
**** (C) ~sharable~
**** (C) ~unshared~

*** scala.compiletime.ops
**** (O) ~any~
**** (O) ~boolean~
**** (O) ~int~
**** (O) ~string~

*** scala.compiletime.testing
**** (C) ~Error~
**** (T) ~ErrorKind~

*** scala.implicits
**** (T) ~LowPriorityNot~
**** (C) ~Not~

*** scala.internal
**** (O) ~Chars~
**** (C) ~MatchCase~
**** (O) ~TupledFunction~
**** (C) ~TypeBox~
**** scala.internal.quoted
***** (O) ~CompileTime~
***** (C) ~Expr~
***** (O) ~Matcher~
***** (C) ~Type~
***** (O) ~Unpickler~
***** (C) ~showName~

*** scala.quoted
**** (O) ~Const~
**** (O) ~Consts~
**** (C) ~Expr~
**** (O) ~Lambda~
**** (T) ~Liftable~
**** (T) ~QuoteContext~
**** (O) ~Reporting~
**** (C) ~ScopeException~
**** (C) ~Type~
**** (T) ~Unliftable~
**** (O) ~Unlifted~
**** (O) ~Varargs~
**** scala.quoted.show
***** (T) ~SyntaxHighlight~

**** scala.quoted.unsafe
***** (O) UnsafeExpr

**** scala.quoted.util
***** ~ExprMap~
***** ~Var~

*** scala.reflect
**** ~Selectable~

*** scala.runtime
**** ~EnumValue~
**** ~EnumValues~
**** ~Tuple~
**** ~TupleXXL~

*** scala.tasty
**** (C) ~Reflection~
**** scala.tasty.reflect
***** (T) ~CompilerInterface~
***** (C) ~ExprCastError~
***** (C) ~ExtractorsPrinter~
***** (T) ~Printer~
***** (C) ~SourceCodePrinter~
***** (T) ~TreeAccumulator~
***** (T) ~TreeMap~
***** (T) ~TreeTraverser~

*** scala.util
**** (O) ~CommandLineParser~
**** (T) ~FromDigits~
**** (T) ~FromString~
**** scala.util.control
***** (O) ~NonLocalReturns~

** scalaShadowing
*** (O) ~language~
