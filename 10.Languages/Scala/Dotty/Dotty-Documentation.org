#+TITLE: Dotty Documentation
#+VERSION: 0.20.0-bin-SNAPSHOT -> 0.21.0-bin-SNAPSHOT
#+AUTHOR:
#+STARTUP: entitiespretty

* BLOG
* DONE USAGE
  CLOSED: [2019-11-04 Mon 16:17]
** Getting Started
   *Getting Started: Users*
*** Trying out Dotty
**** In your web browser
**** sbt
**** IDE support
**** Standalone installation

** sbt-projects
** IDE support for Dotty
*** Prerequisites
*** Usage
*** Status
**** Fully supported features
**** Partial working features
**** Unimplemented features
**** Current limitations, to be fixed

*** Feedback

** Worksheet mode in Dotty IDE
*** How to use the worksheets
*** Implementation details

** cbt-projects
   *Using Dotty with cbt*

** Dottydoc
*** Using existing Templates and Layouts
*** Blog
*** Includes
*** Sidebar
*** Dottydoc Specific Tags and Behavior
**** Linking to API
**** Rendering Docstrings
**** Other extensions

*** Default Layouts
**** =main.html=
***** Variables

**** =sidebar.html=
***** Variables

**** =doc-page.html=
**** =api-page.html=
**** =blog-page.html=

*** Default Includes

* REFERENCE
** Overview
*** Goals
*** Essential Foundations
*** Simplifications
*** Restrictions
*** Dropped Constructs
*** Changes
*** New Constructs
*** Meta Programming
*** See Also

** TODO NEW TYPES
*** DONE Intersection types
    CLOSED: [2019-11-10 Sun 17:47]
    The ~&~ operator creates an /intersection type/.

**** Type Checking
     The type ~S & T~ represents values that are of the type ~S~ and ~T~ _at the
     same time_.

     - Example:
       #+begin_src scala
         trait Resettable {
           def reset(): Unit
         }

         trait Growable[T] {
           def add(x: T): this.type
         }

         def f(x: Resettable & Growable[String]) = {
           x.reset()
           x.add("first")
         }
       #+end_src

     - If a /member/ appears in both ~A~ and ~B~, its type in ~A & B~ is the
       /intersection of its type/ in ~A~ and its type in ~B~.
         For instance, assume the definitions:
       #+begin_src scala
         trait A {
           def children: List[A]
         }

         trait B {
           def children: List[B]
         }

         val x: A & B = new C
         val ys: List[A & B] = x.children
       #+end_src
       ~ys~ is of type ~List[A] & List[B]~, _which can be FURTHER SIMPLIFIED
       to_ ~List[A & B]~ _because_ ~List~ is /convariant/.

     - Q :: (One might wonder)
            How the compiler could come up with a definition for ~children~ of
            type ~List[A & B]~ since all its is given are ~children~ definitions
            of type ~List[A]~ and ~List[B]~.

     - A :: The answer is it *does not need to*. TODO ??? ??? ??? TODO
              ~A & B~ is just a type that represents a set of requirements for
            values of the type.
              At the point where a value is constructed, one must make sure that
            all inherited members are correctly defined. So if one _defines a class
             ~C~ that inherits ~A~ and ~B~,_ one needs to give at that point a
            definition of a ~children~ method with the required type.
       #+begin_src scala
         class C extends A with B {
           def children: List[A & B] = ???
         }
       #+end_src

**** More Details
***** Syntax
      Syntactically, an /intersection type/ ~S & T~ is similar to an /infix
      type/, where the _infix operator_ is ~&~.
      - ~&~ is treated as a /soft keyword/.
        + it is a _NORMAL identifier_ with the usual precedence.

        + *BUT*
          a type of the form ~A & B~
          _is *ALWAYS* recognized as_ an /intersection type/,
          _WITHOUT_ trying to resolve ~&~.

      - Syntax:
        #+begin_src text
          Type      ::=  ...| InfixType
          InfixType ::=  RefinedType {id [nl] RefinedType}
        #+end_src

***** Subtyping Rules
      - Subtyping rules
        TODO

      - It is can be proved that ~&~ is *commutative*.

      - Derived:
        Given type constructor ~C~,
        + If ~C~ is /covariant/, ~C[A] & C[B] ~> C[A & B]~
        + If ~C~ is /contravariant/, ~C[A] & C[B] ~> C[A | B]~

***** TODO Erasure
      TODO TODO TODO

***** Relationship with Compound Type (~with~)
      - =from Jian=
        ~A & B~ is different from the ~A with B~ in Scala 2.
        The latter is not commutative!

      - /Intersection types/ ~A & B~ *replace* /compound types/ ~A with B~ in
        Scala 2.
          For the moment, the syntax ~A with B~ is _still allowed_ and
        *interpreted as* ~A & B~, _but its usage as a type (as opposed to in a
        ~new~ or ~extends~ clause) will be *deprecated* and *removed* in the future._

*** DONE Union types
    CLOSED: [2019-07-01 Mon 15:49]
    A ~A | B~ value can be _any value_ of type ~A~ _and_ also _any value_ of
    type ~B~.

    - Example:
      #+begin_src scala
        final case class UserName(name: String)
        final case class Password(hash: Hash)

        def help(id: UserName | Password) = {
          val user = id match {
            case UserName(name) => lookupName(name)
            case Password(hash) => lookupPassword(hash)
          }
          // ...
        }
      #+end_src

    - /Union types/ are _DUALS of /intersection types/.

    - ~|~ is *commutative*: ~A | B~ is the _SAME type_ as ~B | A~.

    - The compiler will assign a /union type/ to an expression *only if such a
      type is _EXPLICITLY given_.*
      #+begin_src scala
        val password = Password(123)
        // val password: Password = Password(123)

        val name = UserName("Eve")
        // val name: UserName = UserName(Eve)

        if (true) name else password
        // val res2: Object & Product = UserName(Eve)

        val either: Password | UserName = if (true) name else password
          // val res2: Password | UserName = UserName(Eve)
      #+end_src
      + ~Object & Product~ is a /supertype/ of ~UserName~ and ~Password~,
        BUT NOT the /least supertype/ ~Password | UserName~
        * =from Jian= In the document, there is is a typo (not wrong, but not very
          meaningful): _Object & Product is a supertype of UserName and ~Product~._
          TODO Create a PR to correct this!

**** TODO More Details
***** Syntax
      Syntactically, /union types/ follow the same rules as /intersection types/,
      BUT have a _LOWER precedence_.

****** Intersection with pattern matching syntax - =IMPORTANT=
       ~|~ is also used in /pattern matching/ to _SEPARATE_ /pattern alternatives/ and
       *has _LOWER PRECEDENCE than_ ~:~ as used in /typed patterns/,* this means that:
       #+begin_src scala
         case _: A | B => ...

         // is still equivalent to:
         case (_: A) | B => ...

         // and NOT to:
         case _: (A | B) => ...
       #+end_src

***** Subtyping Rules
      - ~A~ is always a subtype of ~A | B~ for all ~A~, ~B~.

      - If ~A <: C~ and ~B <: C~ then ~A | B <: C~.

      - Like ~&~, ~|~ is /commutative/ and /associative/:
        #+begin_src text
          A | B       =:= B | A
          A | (B | C) =:= (A | B) | C
        #+end_src

      - ~&~ _is distributive over ~|~:_
        #+begin_src text
          A & (B | C) =:= A & B | A & C
        #+end_src

      - From these rules it follows that: TODO TODO TODO
        *the /least upper bound (lub)/ of a set of type is the union of these
        types.*

        + This *replaces* the definition of /least upper bound/ in the Scala 2
          specification. TODO

***** TODO Motivation - TODO NOTE, TODO Re-READ
***** TODO Join of a union type - TODO ???
****** Example

***** TODO Type inference
****** Example

***** TODO Members
****** Example

***** Exhaustivity checking
***** TODO Erasure

*** DONE Type lambdas
    CLOSED: [2019-07-01 Mon 15:55]
    A /type lambda/ lets one express a /higher-kinded type/ directly, *WITHOUT*
    a /type definition/.

    - =from Jian=
      Scala 2 can do this with /type definition/ and /type projection/.

    - Example:
      ~[+X, Y] =>> Map[Y, X]~

    - /Type parameters/ of /type lambdas/ can have /variances/ and /bounds/.

    - A /parameterized type definition or declaration/ such as ~type T[X] = (X, X)~
      is a shorthand for a PLAIN /type definition/ with a /type lambda/ as its RHS:
      ~type T = [X] =>> (X, X)~

    - TODO
      _More details_ link

*** TODO Match types
    - A /match type/ reduces to one of a number of right hand sides, depending on
      a /scrutinee type/. Example:
      #+begin_src scala
        type Elem[X] = X match {
          case String      => Char
          case Array[t]    => t
          case Iterable[t] => t
        }
      #+end_src
      + An ~Elem~ with /CONCRETE type parameter/ ~X~ can be reduced _as_ (NOT legal
        code you want to write out explicitly):
        #+begin_src scala
          Elem[String]      =:= Char
          Elem[Array[Int]]  =:= Int
          Elem[List[Float]] =:= Float
          Elem[Nil.type]    =:= Nothing
        #+end_src
        Here ~=:=~ is understood to mean that left and right hand sides are
        *mutually subtypes* of each other.

    - Syntax in general: ~S match { P1 => T1 .... Pn => Tn }~, where
      + ~S~, ~T1~, ..., ~Tn~ are types.
      + ~P1~, ..., ~Pn~ are patterns.
        * /Type variables/ in patterns start as usual with a lower case letter.

    - Match types can form part of recursive type definitions. Example:
      #+begin_src scala
        type LeafElem[X] = X match {
          case String      => Char
          case Array[t]    => LeafElem[t]
          case Iterable[t] => LeafElem[t]
          case AnyVal      => X
        }
      #+end_src

    - _Recursive match type definitions_ can also be given an /upper bound/, like this:
      #+begin_src scala
        type Concat[+Xs <: Tuple, +Ys <: Tuple] <: Tuple = Xs match {
          case Unit    => Ys
          case x *: xs => x *: Concat[xs, Ys]
        }
      #+end_src
      + In this definition, every instance of ~Concat[A, B]~, whether reducible
        or not, is known to be a /subtype/ of ~Tuple~.

      + This is necessary to _make the recursive invocation ~x *: Concat[xs, Ys]~
        type check_, since ~*:~ demands a ~Tuple~ as its right operand.

**** TODO Representation of Match Types
**** Match type reduction
**** Subtyping Rules for Match Types
**** Variance Laws for Match Types
**** Typing Rules for Match Expressions
**** Overlapping Patterns
**** Handling Termination
**** Related Work

*** DONE Dependent Function Types
    CLOSED: [2019-07-01 Mon 16:10]
    - A /dependent function type/ describes functions where the _result type_ may
      DEPEND ON the _function's parameter values_. Example:
      #+begin_src scala
        trait Entry {
          type Key
          val key: Key
        }

        def extractKey(e: Entry): e.Key = e.key          // a dependent method
        val extractor: (e: Entry) => e.Key = extractKey  // a dependent function value
        //           ||                   ||
        //           ||     Dependent     ||
        //           ||   Function Type   ||
        //           =======================
      #+end_src

      - Scala _ALREADY_ has /dependent methods/.
        BUT so far (in Scala 2) it was _NOT possible_ to turn such /methods/ into
        /function values/, so that they can be passed as /parameters/ to other
        functions, or returned as results.
        + /Dependent methods/ COULD NOT be turned into /functions/ simply because
          there was no type that could describe them.

      - In dotty the /type/ of the ~extractor~ value above is ~(e: Entry) => e.Key~

    - The /dependent function type/ above is just /syntactic sugar/ for
      #+begin_src scala
        Function1[Entry, Entry#Key] {
          def apply(e: Entry): e.Key
        }
      #+end_src

** TODO ENUMS
*** DONE Enumerations
    CLOSED: [2019-07-02 Tue 13:11]
    An /enumeration/ is used to define a /type/ consisting of _a set of NAMED values._

    - Example:
      #+begin_src scala
        enum Color {
          case Red, Green, Blue
        }
      #+end_src
      + This defined a new ~sealed~ /class/ ~Color~ with 3 values: ~Color.Red~,
        ~Color.Green~, ~Color.Blue~.

      + The _color values_ are members of ~Color~'s /companion object/.

**** DONE Parameterized enums
     CLOSED: [2019-11-10 Sun 22:12]
     /Enums/ CAN BE _parameterized_:
     #+begin_src scala
       enum Color(val rgb: Int) {
         case Red   extends Color(0xFF0000)
         case Green extends Color(0x00FF00)
         case Blue  extends Color(0x0000FF)
       }
     #+end_src
     As the example shows, you can _DEFINE_ the parameter value BY using an
     _EXPLICIT_ ~extends~ /clause/.

**** DONE Methods defined for enums
     CLOSED: [2019-11-10 Sun 22:12]
     - The values of an /enum/ correspond to _UNIQUE integers_.

     - The _integer_ associated with an /enum value/ is returned by its ~ordinal~
       /method/.

     - Example:
       #+begin_src scala
         val red = Color.Red
         // val red: Color = Red

         red.ordinal
         // val res0: Int = 0
       #+end_src

     - The /companion object/ of an /enum/ also defines *TWO* utility /methods/.
       + ~valueOf~: obtain an /enum value/ by its _name_.
       + ~values~: returns _ALL_ /enum values/ defined in an enumeration in an ~Array~.
       #+begin_src scala
         Color.valueOf("Blue")
         // val res0: Color = Blue

         Color.values
         // val res1: Array[Color] = Array(Red, Green, Blue)
       #+end_src

**** DONE User-defined members of enums
     CLOSED: [2019-11-10 Sun 22:12]
     It is _possible_ to add your own definitions to an /enum/.

     - Example:
       #+begin_src scala
         enum Planet(mass: Double, radius: Double) {
           private final val G = 6.67300E-11
           def surfaceGravity = G * mass / (radius * radius)
           def surfaceWeight(otherMass: Double) =  otherMass * surfaceGravity

           case Mercury extends Planet(3.303e+23, 2.4397e6)
           case Venus   extends Planet(4.869e+24, 6.0518e6)
           case Earth   extends Planet(5.976e+24, 6.37814e6)
           case Mars    extends Planet(6.421e+23, 3.3972e6)
           case Jupiter extends Planet(1.9e+27,   7.1492e7)
           case Saturn  extends Planet(5.688e+26, 6.0268e7)
           case Uranus  extends Planet(8.686e+25, 2.5559e7)
           case Neptune extends Planet(1.024e+26, 2.4746e7)
         }
       #+end_src

     - It is also possible to define an explicit /companion object/ for an /enum/:
       #+begin_src scala
         object Planet {
           def main(args: Array[String]) = {
             val earthWeight = args(0).toDouble
             val mass = earthWeight / Earth.surfaceGravity
             values map { p =>
               println(s"Your weight on $p is ${p.surfaceWeight(mass)}")
             }
           }
         }
       #+end_src

**** DONE Compatibility with Java Enums
     CLOSED: [2019-07-02 Tue 10:37]
     If you want to use a enum in Scala in Java, you need to extends
     ~java.lang.Enum[T]~, where ~T~ is your _enum type name_.
     - Example
       #+begin_src scala
         enum Color extends java.lang.Enum[Color] { case Red, Green, Blue }
       #+end_src

     - Example
       #+begin_src scala
         Color.Red.compareTo(Color.Green)
         // val res15: Int = -1
       #+end_src

     - For a more in-depth example of using Scala 3 /enums/ from Java, see this
       test (in GITHUB dotty project repo). In the test, the /enums/ are defined
       in the ~MainScala.scala~ file and used from a Java source, ~Test.java~.

**** DONE Implementation
     CLOSED: [2019-07-02 Tue 13:11]
     /Enums/ are represented as ~sealed~ /classes/ that extend the ~scala.Enum~
     /trait/.

     - ~scala.Enum~ defines a _SINGLE_ /public method/, ~ordinal~:
       #+begin_src scala
         package scala

         /** A base trait of all enum classes */
         trait Enum {
           /** A number uniquely identifying a case of an enum */
           def ordinal: Int
         }
       #+end_src

     - /Enum values/ *WITH* ~extends~ /clauses/ get *expanded* to /anonymous class
       instances/.
         For instance, the ~Venus~ value above (=from Jian= in Section _User-defined
       members of enums_) would be defined like this:
       #+begin_src scala
         val Venus: Planet = new Planet(4.869e24, 6.0518e6) {
           def ordinal: Int = 1
           override def toString: String = "Venus"
           // internal code to register value
         }
       #+end_src

     - /Enum values/ *WITHOUT* ~extends~ /clauses/ all share a single implementation
       that can be instantiated using a /private method/ that takes a tag and a name
       as arguments.
         For instance, ~Color.Red~ would expand to
         #+begin_src scala
           val Red: Color = $new(0, "Red")
         #+end_src

**** TODO Reference

*** DONE Algebraic Data Types
    CLOSED: [2019-07-02 Tue 13:35]
    The ~enum~ concept is general enough to ALSO support ADTs and GADTs. =TODO=

    - Example:
      #+begin_src scala
        enum Option[+T] {
          case Some(x: T)
          case None
        }
      #+end_src
      + The ~extends~ clauses can be given explicitly:
        #+begin_src scala
          enum Option[+T] {
            case Some(x: T) extends Option[T]
            case None       extends Option[Nothing]
          }
        #+end_src

      + If ~Option~ was /non-variant/, you'd need to give the ~extends~ /clause/
        of None *EXPLICITLY*.

    - Generally, for /enum classes/
      + all /covariant type parameters/  are *minimized* in a compiler-generated
        ~extends~ /clause/

      + all /contravariant type parameters/ are *maximized*.

    - If not directly ~new~ a enumeration, a type is always its parent.
      For example,
      #+begin_src scala
        Option.Some("hello")
        // val res1: t2.Option[String] = Some(hello)

        Option.None
        // val res2: t2.Option[Nothing] = None

        new Option.Some(2)
        // res3: t2.Option.Some[Int] = Some(2)
      #+end_src

    - /Enumerations/ and /ADTs/ have been presented as two *different concepts*.
      _BUT_
      since they share the same syntactic construct, they can be seen simply as
      two ends of a spectrum and it is perfectly possible to construct hybrids.
      For instance, the code below gives an implementation of Color either with
      three enum values or with a parameterized case that takes an RGB value.
      TODO TODO TODO
      TODO TODO TODO
      TODO TODO TODO
      #+begin_src scala
        enum Color(val rgb: Int) {
          case Red           extends Color(0xFF0000)
          case Green         extends Color(0x00FF00)
          case Blue          extends Color(0x0000FF)
          case Mix(mix: int) extends Color(mix)
        }
      #+end_src

**** DONE Syntax of Enums
     CLOSED: [2019-07-02 Tue 13:27]
     - TODO NOTE

**** TODO Reference

*** TODO Translation
    *Translation of Enum and ADTs*
    1.
    2.
    3.
    4.
    5.
    6.
    7.
    8.
    9.

**** Translation of Enumerations
**** Scopes for Enum Cases
**** Translation of Java-compatible enums
**** Other Rules

** TODO CONTEXTUAL ABSTRACTIONS
*** Overview
**** TODO Critique of the Status Quo
     TODO
     TODO
     TODO

**** TODO The New Design
     - The following pages introduce a *REDESIGN* of /contextual abstractions/ in
       Scala. They introduce four fundamental changes:
       1. /Delegates/:
          a new way to define basic terms that can be synthesized.
          + _They replace /implicit definitions/._

          + The core principle of the proposal:
            rather than mixing the ~implicit~ /modifier/ with a large number of
            features, we have a single way to define terms that can be
            synthesized for types.

       2. /Given Clauses/:
          a new syntax for /implicit parameters and their arguments/.
          + Both are introduced with the same keyword, ~given~.

          + TODO This unambiguously aligns parameters and arguments, solving a
            number of language warts.

          + TODO It also allows us to have _SEVERAL /implicit parameter/ sections_,
            and to have /implicit parameters/ followed by normal ones.

       3. /Delegate Imports/:
          a new class of /imports/ that _SPECIFICALLY import delegates_ and nothing
          else.
            /Delegates/ *must be* imported with ~import delegate~, a plain ~import~
          will no longer bring them into scope.

       4. /Implicit Conversions/:
          now expressed as /delegates/ of a standard ~Conversion~ class.
          All other forms of /implicit conversions/ will _be phased out_.

     - This section also contains pages describing other language features that
       are _related to_ /context abstraction/. These are: TODO TODO TODO
       + Context Bounds, which carry over unchanged.

       + Extension Methods replace implicit classes in a way that integrates better
         with typeclasses.

       + Implementing Typeclasses demonstrates how some common typeclasses can be
         implemented using the new constructs.

       + Typeclass Derivation introduces constructs to automatically derive typeclass
         delegates for ADTs.

       + Multiversal Equality introduces a special typeclass to support type safe
         equality.

       + Implicit Function Types provide a way to abstract over given clauses.

       + Implicit By-Name Parameters are an essential tool to define recursive
         synthesized values without looping.

       + Relationship with Scala 2 Implicits discusses the relationship between
         old-style implicits and new-style delegates and given clauses and how
         to migrate from one to the other.

*** Given Instances
    /Given instances/ (or, simply, "givens") define "canonical" values of certain
    types that serve for /synthesizing arguments/ to /given clauses/.
    =from Jian= /given clauses/ describes a requirement to /given instances/.

    - Example:
      #+begin_src scala
        trait Ord[T] {
          def compare(x: T, y: T): Int

          def (x: T) < (y: T) = compare(x, y) < 0
          def (x: T) > (y: T) = compare(x, y) > 0
        }

        given intOrd: Ord[Int] {
          def compare(x: Int, y: Int) =
            if (x < y) -1 else if (x > y) +1 else 0
        }

        given listOrd[T](given ord: Ord[T]): Ord[List[T]] {
          def compare(xs: List[T], ys: List[T]): Int = (xs, ys) match {
            case (Nil, Nil) => 0
            case (Nil, _)   => -1
            case (_, Nil)   => +1
            case (x :: xs1, y :: ys1) =>
              val fst = ord.compare(x, y)
              if (fst != 0) fst else xs1.compareTo(ys1)
          }
        }
      #+end_src
      + This code defines a /trait/ ~Ord~ (typeclass) with two /given instances/.

      + ~(given ord: Ord[T])~ clause in ~listOrd~ defines an /implicit parameter/.
        TODO /given clauses/ are further explained in the next section.

**** Anonymous Given Instances
     The name of a given instance can be left out.
     #+begin_src scala
       given Ord[Int] { /* ... */ }
       given [T](given Ord[T]): Ord[List[T]] { /* ... */ }
     #+end_src

**** Alias Givens
     An alias can be used to define a given instance that is equal to some expression. E.g.:
     #+begin_src scala
       given global: ExecutioinContext = new ForkJoinPool()
     #+end_src
     The _initialization rule_ is described in the next section.

     - /Alias givens/ can be anonymous, e.g.
       #+begin_src scala
         given Position = enclosingTree.position
         given (given outer: Context): Context = outer.withOwner(currentOwner)
       #+end_src

     - An /alias given/ can have /type parameters/ and /given clauses/ just like
       any other /given instance/, _but it can ONLY implement a single type._
       =from Jian= Because it is an alias -- a name or concrete thing, not a
                   general instances.

**** Given Instance Initialization - =IMPORTANT=
     A given instance without type parameters or given clause is initialized
     on-demand, the first time it is accessed.
     - It is _NOT required to ENSURE_ /safe publication/, which means that
       DIFFERENT /threads/ might create DIFFERENT /instances/ for the SAME
       /given definition/.

     - If a /given definition/ has /type parameters/ or a /given clause/, a *fresh*
       instance is created _for EACH reference_.

**** TODO Syntax - TODO
     TODO ??? TODO ??? TODO
     The identifier ~id~ can be omitted _only if_ (???)
     - some types are implemented
       OR
     - the template body defines at least one extension method.

*** TODO Given Clauses
   # Given Parameters
**** Anonymous Given Clauses
**** Inferring Complex Arguments
**** Multiple Given Clauses
**** Summoning Instances
**** Syntax

*** DONE Context Bounds
    CLOSED: [2019-11-12 Tue 02:20]
    A /context bound/ is a *SHORTHAND* for expressing the common pattern (a.k.a
    typeclass pattern) of an /implicit parameter/ that depends on a /type parameter/.

**** Context Bounds
     - The implicit parameter(s) *generated from* /context bounds/ *come last* in
       the definition of the containing /method/ or /class/. E.g.
       #+begin_src scala
         def f[T: C1 : C2, U: C3](x: T)(given y: U, z: V): R

         // would expand to

         def f[T, U](x: T)(given y: U, z: V)(given C1[T], C2[T], C3[U]): R
       #+end_src

     - /Context bounds/ can be combined with /subtype bounds/.
       If both are present, /subtype bounds/ *come first*, e.g.
       ~def g[T <: B : C](x: T):R = ...~

**** Syntax
     #+begin_src text
       TypeParamBounds ::= [SubtypeBounds] {ContextBound}
       ContextBound    ::= ':' Type
     #+end_src

*** DONE Given Imports
    CLOSED: [2019-11-13 Wed 14:44]
    A _special form_ of /import wildcard selector/ is used to IMPORT /given
    instances/.
    - Example:
      #+begin_src scala
        object A {
          class TC
          given tc: TC
          def f(given TC) = ???
        }

        object B {
          import A._
          import A.given
          // ...
        }
      #+end_src
      + In Dotty, ~import A._~ import all members of ~A~ *except* the /given instances/.

      + Merge the two import clauses: ~import A.{given, _}~

    - There are _TWO_ main benefits arising from these rules:
      + It is made clearer where /givens/ in scope are coming from.

      + Separate import not givens and givens.
        This is particularly important since /givens/ can be ANONYMOUS, so the
        usual recourse of using /named imports/ is NOT practical.

**** DONE Importing By Type
     CLOSED: [2019-11-13 Wed 14:37]
     Since /givens/ can be _anonymous_ it is _NOT always practical to import them
     by their name_, and /wildcard imports/ are typically used instead.
       /By-type imports/ provide a _MORE SPECIFIC alternative_ to /wildcard imports/,
     which makes it clearer what is imported.

     - Example:
       + ~import A.{given TC}~
       + ~import A.{given T1, given T2, ..., given Tn}~
       + ~import A.{given Ordering[?]}~
       + /By-type imports/ can be mixed with /by-name imports/.
         If BOTH are present in an import clause, *by-type imports come last*.
         ~import A.{im, given Ordering[?]}~

     - /Bounded wildcard selectors/ *also work* for _normal imports and exports_.
       For instance,
       #+begin_src scala
         enum Color {
           case Red, Green, Blue, Megenta

           def isPrimary(c: Color): Boolean = ...
         }

         // Export all four `Color` values, but leaves the `isPrimary` method alone.
         export Color.{_: Color}
       #+end_src

**** DONE Migration
     CLOSED: [2019-11-13 Wed 14:42]
     TODO NOTE
**** DONE Syntax
     CLOSED: [2019-11-13 Wed 14:44]
     TODO NOTE

*** Extension Methods
    ## 0.20.0 version #

**** Translation of Extension Methods
**** Translation of Calls to Extension Methods
**** Given Instances for Extension Methods
**** Given Instances with Collective Parameters
**** Operators
**** Generic Extensions
**** Syntax

*** DONE Implementing Typeclasses
    CLOSED: [2019-11-13 Wed 14:27]
    /Given instances/, /extension methods/ and /context bounds/ allow a concise and
    natural expression of /typeclasses/.

    - /Typeclasses/ are just /traits/ with canonical implementations defined by
      /given instances/.

    - Here are some examples of standard typeclasses:

**** Semigroups and monoids
     #+begin_src scala
       trait SemiGroup[T] {
         def (x: T) combine (y: T): T
       }

       trait Monoid[T] extends SemiGroup[T] {
         def unit: T
       }

       object Monoid {
         def apply[T](given Monoid[T]) = summon[Monoid[T]]
       }

       given Monoid[String] {
         def (x: String) combine (y: String): String = x.concat(y)
         def unit: Int = 0
       }

       def sum[T: Monoid](xs: List[T]): T =
         xs.foldLeft(Monoid[T].unit)(_.combine(_))
     #+end_src

**** Functors and monads
     #+begin_src scala
       trait Functor[F[_]] {
         def [A, B](x: F[A]) map (f: A => B): F[B]
       }

       trait Monad[F[_]] extends Functor[F] {
         def [A, B](x: F[A]) flatMap (f: A => F[B]): F[B]
         def [A, B](x: F[A]) map (f: A => B) = x.flatMap(f `andThen` pure)

         def pure[A](x: A): F[A]
       }

       given listMonad: Monad[List] {
         def [A, B](xs: List[A]) flatMap (f: A => List[B]): List[B] =
           xs.flatMap(f)

         def pure[A](x: A): List[A] =
           List(x)
       }

       given readerMonad[Ctx]: Monad[[X] =>> Ctx => X] {
         def [A, B](r: Ctx => A) flatMap (f: A => Ctx => B): Ctx => B =
           ctx => f(r(ctx))

         def pure[A](x: A): Ctx => A =
           ctx => x
       }
     #+end_src

*** Typeclass Derivation
    # Type class Derivation
**** Types supporting ~derives~ clauses
**** Type classes supporting automatic deriving
***** How to write a type class ~derived~ method using low level mechanisms

**** Deriving instances elsewhere
**** Syntax
**** Discussion

*** Multiversal Equality
**** Deriving ~Eql~ Instances
**** Precise Rules for Equality Checking
**** Predefined ~Eql~ Instances
**** Why Two Type Parameters?

*** Implicit Function Types
**** Example: Builder Pattern
**** Example: Postconditions
**** Reference

*** Implicit Conversions
**** Examples

*** Implicit By-Name Parameters
**** Reference

*** Relationship with Scala 2 Implicits
**** Simulating Contextual Abstraction with Implicits
***** Given Intances
***** Anonymous Given Intances
***** Given Clauses
***** Context Bounds
***** Extension Methods
***** Typeclass Derivation
***** Implicit Function Types
***** Implicit By-Name Parameters

**** Simulating Scala 2 Implicits in Dotty
***** Implicit Conversions
***** Implicit Classes
***** Implicit Values
***** Abstract Implicits

**** Implementation Status and Timeline

** TODO METAPROGRAMMING
*** DONE Overview
    CLOSED: [2019-06-24 Mon 02:35]
    The following fundamental facilities:
    1. /Inline/
       /inline/ is a new _modifier_ that guarantees that a definition will be
       inlined at the point of use.

       - The primary motivation:
         _reduce the overhead_ behind function calls and access to values.

       - The expansion will be performed by the Scala compiler during the /Typer/
         /compiler phase/.

       - As opposed to /inlining/ in some other ecosystems, /inlining/ in Scala
         is _not merely_ a request to the compiler but is a command.

       - The reason is that /inlining/ in Scala can drive other _compile-time
         operations_, like
         + /inline/ /pattern matching/ (enabling type-level programming)
         + /macros/ (enabling compile-time, generative, metaprogramming)
         + /runtime code generation/ (multi-stage programming)

    2. /Macros/ construct code at /compile-time/
       - /Macros/ are built on two well-known fundamental operations:
         + quotation ::
           *converts program code to data*, specifically, a (tree-like)
           representation of this code. It is expressed as
           * ~'{...}~ for /expressions/
           * ~'[...]~ for /types/

         + splicing :: *converts a program's representation to program code*
           * expressed as ~${ ... }~.

       - The /inline/ and /splicing/ abstractions allow to construct program
         code programmatically.

    3. /Staging/ construct new code at /runtime/.
       That way, code generation can depend not only on static data but also on
       data available at runtime. This splits the evaluation of the program in
       two or more phases or ... /stages/.
         Consequently, this method generative programming is called /"Multi-Stage
       Programming"/. /Staging/ is built on the _SAME_ foundations as /macros/.
       It uses /quotes/ and /splices/, but _LEAVES OUT_ /inline/.

    4. /Erased Terms/ =???= TODO
       Erased terms are used to enforce guarantees about program constraints.
       As erased terms are guaranteed not to be used in computations, they will
       not appear at the generated code.

    5. /TASTy Reflection/
       + /Quotations/ are a "black-box" representation of code.
         They can be parameterized and composed using /splices/ but their
         structure cannot be analyzed from the outside.
       + /Tasty reflection/ gives a way to analyze code structure by partly
         revealing the representation type of a piece of code in a standard API.
         TODO
         The _representation type_ is a form of /typed abstract syntax tree/,
         which gives rise to the "TASTy` moniker.

    6. /TASTy Inspection/
       /Typed abstract syntax trees/ are serialized in a custom compressed
       binary format in =.tasty= files. /TASTy inspection/ allows to _load_
       these files and _analyze_ their content's tree structure.

*** TODO Inline
**** Inline Definitions
**** Recursive Inline Methods
**** Relationship to ~@inline~
***** The definition of constant expression

**** Specializing Inline (Whitebox)
**** DONE Inline Conditionals
     CLOSED: [2019-06-24 Mon 03:05]
     #+begin_src scala
       inline def update(delta: Int) =
         inline if (delta >= 0) increaseBy(delta)
                else            decreaseBy(-delta)
     #+end_src
     + Use ~inline~ means in the call site ~delta~ _MUST be_ a /compile-time
       constant/.

     + A call ~update(22)~ would re-write to ~increaseBy(22)~.

     + A call with a value of not compile-time constant will trigger a compile
       error:
       #+begin_src text
            |  inline if (delta >= 0) ???
            |  ^
            |  cannot reduce inline if
            |   its condition
            |     delta >= 0
            |   is not a constant value
            | This location is in code that was inlined at ...
       #+end_src

**** TODO Inline Matches
     - TODO
       #+begin_src scala
         inline def g(x: Any) <: Any = inline x match {
           case x: String => (x, x)  // Tuple2[String, String](x, x)
           case x: Double => x
         }

         g(1.0d)  // Has type 1.0d which is a subtype of Double
           g("test")  // Has type (String, String)
       #+end_src

     - TODO
       #+begin_src scala
         trait Nat
         case object Zero extends Nat
         final case class Succ[N <: Nat](n: N) extends Nat

         inline def toInt(n: Nat) <: Int = inline n match {
           case Zero     => 0
           case Succ(n1) => toInt(n1) + 1
         }

         final val natTwo = toInt(Succ(Succ(Zero)))
         val intTwo: 2 = natTwo
       #+end_src

**** DONE The ~scala.compiletime~ Package
     CLOSED: [2019-06-24 Mon 16:36]
     The ~scala.compiletime~ package contains _helper definitions_ that provide
     support for /compile time/ OPERATIONS over _values_. They are described in the
     following.
***** ~constValue~, ~constValueOpt~, and the ~S~ combinator
      - ~constValue[T]~ generate a constant value of type ~T~

      -                0.200.13@25.3.1 (spacema~constValueOpt[T]~ generate a constant value of type ~Option[T]~

      - ~S~ is the type of the successor of some singleton type.
        For example, ~S[1]~ is the /singleton type/ ~2~.

***** ~erasedValue~
      - The ~erasedValue[T]~ function in ~scala.comiletime.erasedValue~ is not
        implemented -- it would always raise a ~NotImplementedError~ exception
        when called.
          _However, it can in fact never be called, since it is declared ~erased~ --
        it is only used at /compile-time/ during type checking._

      - Example:
        #+begin_src scala
          import scala.comiletime.erasedValue
          // erased def erasedValue[T]: T = ???

          inline def defaultValue[T] = inline erasedValue[T] match {
            case _: Byte    => Some(0: Byte)
            case _: Char    => Some(0: Char)
            case _: Short   => Some(0: Short)
            case _: Int     => Some(0)
            case _: Long    => Some(0L)
            case _: Float   => Some(0.0f)
            case _: Double  => Some(0.0d)
            case _: Boolean => Some(false)
            case _: Unit    => Some(())
            case _          => None
          }

          val dInt:     Some[Int]     = defaultValue[Int]
          val dDouble:  Some[Double]  = defaultValue[Double]
          val dBoolean: Some[Boolean] = defaultValue[Boolean]
          val dAny:     Any.type      = defaultValue[Any]
        #+end_src

      - Another example:
        #+begin_src scala
          inline def toIntT[N <: Nat] <: Int = inline erasedValue[N] match {
            case _: Zero.type => 0
            case _: Succ[n]   => toIntT[n] + 1
          }

          final val two = toIntT[Succ[Succ[Zero.type]]]
        #+end_src

      - TODO
        Last paragraph???

***** ~error~
      The ~error~ /method/ is used to produce _user-defined_ /compile errors/
      *DURING /inline expansion/.* It has the following signature:
      #+begin_src scala
        inline def error(inline msg: String): Nothing
      #+end_src

      - If an /inline expansion/ results in a call ~error(msgStr)~ the compiler produces
        an _error message_ containing the given ~msgStr~.
        + Example 1
          #+begin_src scala
            inline def fail() = {
              error("failed for a reason")
            }

            fail()  // error: failed for a reason
          #+end_src

          OR

        + Example 2
          #+begin_src scala
            inline def fail(p1: => Any) = {
              error(code"failed on: $p1")
            }

            fail(indentity("foo"))  // error: failed on: indentity("foo")
          #+end_src

**** DONE Summoning Implicits Selectively
     CLOSED: [2019-06-24 Mon 16:46]
     TODO NOTE
     TODO NOTE
     TODO NOTE
     #+begin_src scala
       inline def setFor[T]: Set[T] = implicit match {
         case _: Ordering[T] => new TreeSet[T]
         case _              => new HashSet[T]
       }
     #+end_src

     + The old way is full of boilterplate:
       #+begin_src scala
         trait SetFor[T, S <: Set[T]]

         class LowPriority {
           implicit def hashSetFor[T]: SetFor[T, HashSet[T]] = ...
         }

         object SetFor extends LowPriority {
           implicit def treeSetFor[T: Ordering]: SetFor[T, TreeSet[T]] = ...
         }
       #+end_src

**** DONE Reference
     CLOSED: [2019-06-24 Mon 16:55]

*** TODO Macros
**** DONE Macros: Quotes and Splices
     CLOSED: [2019-06-26 Wed 15:36]
     - Macros are built on two well-known fundamental operations:
       + quotation :: ~'{...}~ for /expressions/ (both forms are equivalent);
                      ~'[...]~ for /types/.

       + splicing :: ~${ ... }~

     - Additionally, _within_ a /quote/ or a /splice/ we can /quote/ or /splice/
       _identifiers_ directly (i.e. ~'e~ and ~$e~).

     - Readers may notice the _RESEMBLANCE_ of the two aforementioned syntactic
       schemes with the familiar /string interpolation syntax/. /Quotes/ and
       /splices/ in this section allow us to treat code in a similar way,
       effectively supporting /macros/.
       #+begin_src scala
         println(s"Hello, $name, here is the result of 1 + 1 = ${1 + 1}")
       #+end_src
       In string interpolation we /quoted/ a string and then we /spliced/ into it,
       two others.
       1. ~name~, is a reference to a value of type string,
       2. an _arithmetic expression_ that will be evaluated followed by the /splicing/
          of its string representation.

     - The entry point for /macros/ is an /inline method/ with a *top-level* /splice/.
       We call it a top-level because it is the *only occasion* where we encounter a
       /splice/ *outside* a /quote/ (consider as a /quote/ the compilation-unit at the
       call-site).

       For example, the code below presents an ~inline~ /method/ ~assert~ which
       calls at compile-time a method ~assertImpl~ with a /boolean expression
       tree/ as argument. ~assertImpl~ evaluates the expression and prints it again
       in an error message if it evaluates to ~false~.
       #+begin_src scala
         import sala.quoted._

         inline def assert(expr: => Boolean): Unit =
           ${ assertImpl('expr) }

         def assertImpl(expr: Expr[Boolean]) = '{
           if (!$expr)
             throw new AssertionError(s"failed assertion: ${${ showExpr(expr) }}")
         }

         def showExpr(expr: Expr[Boolean]): Expr[String] =
           '{ "<some source code>" }  // Better implementation later in this document
       #+end_src

     - /Quotations/ can have _spliced_ parts in them; in this case the embedded /splices/
       _are evaluated and embedded as part of_ the formation of the /quotation/.

     - /Quotes/ and /splices/ can also be applied *DIRECTLY* to _identifiers_.
       + An /identifier/ ~$x~ starting with a ~$~ that appears _INSIDE_ a /quoted
         expression or type/ is _treated as_ a /splice/ ~${x}~.

       + Analogously, an /quoted identifier/ ~'x~ that appears _INSIDE_ a /splice/
         is _treated as_ a /quote/ ~'{x}~.

     - /Quotes/ and /splices/ are *DUALS of each other*.
       For arbitrary /expressions/ ~e~ and /types/ ~T~ we have:
       #+begin_src scala
         ${'{e}} = e
         '{${e}} = e
         ${'[T]} = T
         '{$[T]} = T
       #+end_src

**** DONE Types for Quotations
     CLOSED: [2019-06-26 Wed 15:44]
     - The /type signatures/ of /quotes/ and /splices/ can be described using
       _TWO_ _FUNDAMENTAL /types/:_
       + ~Expr[T]~: /abstract syntax trees/ representing /expressions/ of /type/ ~T~

       + ~Type[T]~: /type structures/ representing /type/ ~T~.

     - /Quoting/ takes
       + /expressions/ of /type/ ~T~ to /expressions/ of /type/ ~Expr[T]~
       + /types/ ~T~ to /expressions/ of /type/ ~Type[T]~.

     - /Splicing/ takes
       + expressions of /type/ ~Expr[T]~ to /expressions/ of /type/ ~T~
       + expressions of /type/ ~Type[T]~ to /types/ ~T~.

     - The two types can be defined in package ~scala.quoted~ as follows:
       #+begin_src scala
         package scala.quoted

         sealed abstract calss Expr[+T]
         sealed abstract calss Type[T]
       #+end_src
       All constructors for these types are provided by the system, which is the
       reason why they are defined as ~sealed~.

     - One way to construct values of type ~Expr[T]~ or ~Type[T]~ is by /quoting/,
       TODO ???
       the other is by /type-specific lifting operations/ that will be discussed later on.

**** TODO The Phase Consistency Principle
     - A fundamental /phase consistency principle (PCP)/ regulates accesses to /free
       variables/ in /quoted/ and /spliced/ code:
       + For any /free variable reference/ ~x~,
         the _number_ of /quoted scopes/ and the _number_ of /spliced scopes/
         between the reference to ~x~ and the definition of ~x~ *must be equal*.

     - Here, ~this~-reference count as /free variables/.
       TODO

     - We assume all imports are fully expanded and that ~_root_~ is *NOT* a /free
       variable/. So /references/ _to global definitions_ are allowed everywhere.
       TODO

     - The /phase consistency principle/ can _be motivated as follows_:
       1. Suppose the result of a program _P_ is some /quoted text/ ~'{ ... x ... }~
          that refers to a /free variable/ ~x~ in _P_. This can be represented only
          by referring to the original variable ~x~.

       2. Hence, the result of the program will need to persist the program state
          itself as one of its parts. We don't want to do this, hence this situation
          should be made illegal.

          Dually, suppose a top-level part of a program is a /spliced text/ ~${
          ... x ... }~ that refers to a /free variable/ ~x~ in _P_. This would
          mean that we refer during construction of _P_ to a value that is
          _available ONLY during execution of P._
          *This is of course impossible and therefore needs to be ruled out.*

       Now, the small-step evaluation of a program will reduce /quotes/ and
       /splices/ in equal measure using the cancellation rules above. But it will
       neither create nor remove /quotes/ or /splices/ individually. So the PCP
       ensures that program elaboration will lead to neither of the two unwanted
       situations described above.

**** TODO From ~Expr~'s to Functions and Back
     - The ~Expr~ /companion object/ contains an _implicit ~AsFunction~ conversion_
       that TURNS a /tree describing a function/ INTO a function _mapping trees to
       trees_.
       #+begin_src scala
         object Expr {
           // ...
           implicit class AsFunction[...](...) {
             // ...
           }
         }
       #+end_src
       This decorator gives ~Expr~ the ~apply~ operation of an /applicative functor/,
       where ~Expr~'s over /function types/ can be applied to ~Expr~ _arguments_.
       The definition of ~AsFunction(f).apply(x)~ is assumed to be functionally
       the same as ~'{($f)($x)}~, however it should *optimize* this call by
       returning the result of /beta-reducing/ ~f(x)~ if ~f~ is a known lambda
       expression.

     - The ~AsFunction~ decorator distributes applications of ~Expr~ over /function
       arrows/:
       #+begin_src scala
         AsFunction(_).apply: Expr[S => T] => (Expr[S] => Expr[T])
       #+end_src
       Its _dual_, let's call it ~reflect~, can be defined as follows:
       #+begin_src scala
         def reflect[T, U](f: Expr[T] => Expr[U]): Expr[T => U] = '{
           (x: T) => ${ f('x) }
         }
       #+end_src

     - Note how the FUNDAMENTAL /phase consistency principle/ works in _two different
       directions_ here for ~f~ and ~x~.
       The reference to ~f~ is legal because it is _quoted, then spliced_,
       whereas the reference to ~x~ is legal because it is _spliced, then quoted_.

**** TODO Types and the PCP
     - In principle, The /phase consistency principle/ applies to /types/ as well
       as for /expressions/.
       This might seem too restrictive. Indeed, the definition of ~reflect~
       above is _NOT phase correct_ since there is a /quote/ but no /splice/
       between the parameter binding of ~T~ and its usage. But the code _can be
       made phase correct_ *by adding a binding of a ~Type[T]~ tag*:
       #+begin_src scala
         def reflect[T, U](f: Expr[T] => Expr[U]) given (t: Type[T]): Expr[T => U] =
           '{ (x: $t) => ${ f('x) } }
       #+end_src

     - In this version of ~reflect~, the type of ~x~ is now the result of /splicing/
       the ~Type~ value ~t~. This operation is /splice/ correct -- there is one
       /quote/ and one /splice/ between the use of ~t~ and its definition.

     - To avoid clutter, the Scala implementation tries to convert ANY
       /phase-incorrect reference/ to a type ~T~ to a /type-splice/, by
       rewriting ~T~ to ~${ the[Type[T]]}~. For instance, the user-level
       definition of ~reflect~:
       #+begin_src scala
         def reflect[T: Type, U: Type](f: Expr[T] => Expr[U]): Expr[T => U] =
           '{ (x: T) => ${ f('x) } }
       #+end_src
       would be rewritten to
       #+begin_src scala
         def reflect[T: Type, U: Type](f: Expr[T] => Expr[U]): Expr[T => U] =
           '{ (x: ${ the[Type[T]] }) => ${ f('x) } }
       #+end_src

     - The ~the~ query succeeds because there is a /delegate/ of type ~Type[T]~
       available (namely the given parameter corresponding to the /context
       bound/ ~: Type~), and the reference to that value is phase-correct.
         If that was not the case, the phase inconsistency for ~T~ would be
       reported as an error.

**** TODO Lifting Expressions
     - Consider the following implementation of a staged interpreter that implements
       a compiler through staging.
       #+begin_src scala
         import scala.quoted._

         enum Exp {
           case Num(n: Int)
           case Plus(e1: Exp, e2: Exp)
           case Var(x: String)
           case Let(x: String, e: Exp, in: Exp)
         }
       #+end_src

     - The interpreted language consists of numbers ~Num~, addition ~Plus~, and
       variables ~Var~ which are bound by ~Let~. Here are two sample expressions
       in the language:
       #+begin_src scala
         val exp    = Plus(Plus(Num(2), Var("x")), Num(4))
         val letExp = Let("x", Num(3), exp)
       #+end_src

     - Here's a compiler that maps an expression given in the interpreted language
       to /quoted/ Scala code of type ~Expr[Int]~. The compiler takes an environment
       that maps variable names to Scala ~Expr~'s.
       #+begin_src scala
         import delegate scala.quoted._

         def compile(e: Exp, env: Map[String, Expr[Int]]): Expr[Int] = e match {
           case Num(n)          => n.toExpr
           case Plus(e1, e2)    => '{ ${ compile(e1, env) } + ${ compile(e2, env) } }
           case Var(x)          => env(x)
           case Let(x, e, body) => '{ val y = ${ compile(e, env) }; ${ compile(body, env + (x -> 'y)) } }
         }
       #+end_src

     - Running compile(letExp, Map()) would yield the following Scala code:
       #+begin_src scala
         '{ val y = 3; (2 + y) + 4 }
       #+end_src

     - The body of the first clause, ~case Num(n) => n.toExpr~, looks suspicious.
       ~n~ is declared as an ~Int~, yet it is converted to an ~Expr[Int]~ with
       ~toExpr~. Shouldn't ~n~ be /quoted/? In fact this would _NOT_ work since
       replacing ~n~ by ~'n~ in the clause _would NOT be phase correct_.

     - The ~toExpr~ extension method is defined in package ~quoted~:
       #+begin_src scala
         package quoted

         delegate LiftingOps {
           def (x: T) toExpr[T] given (ev: Liftable[T]): Expr[T] = ev.toExpr(x)
         }
       #+end_src

     - The extension says that values of types implementing the ~Liftable~ /type
       class/ can be converted ("lifted") to ~Expr~ values using ~toExpr~,
       provided a /delegate import/ of ~scala.quoted._~ is in scope.

     - Dotty comes with /delegate definitions/ of ~Liftable~ for several types
       including ~Boolean~, ~String~, and /ALL primitive number types/.
         For example, ~Int~ values can be converted to ~Expr[Int]~ values by
       wrapping the value in a ~Literal~ /tree node/. This makes use of the
       underlying tree representation in the compiler for efficiency. But the
       ~Liftable~ instances are nevertheless not magic in the sense that they
       could all be defined in a user program without knowing anything about the
       representation of ~Expr~ trees. For instance, here is a possible instance
       of ~Liftable[Boolean]~:
       #+begin_src scala
         delegate for Liftable[Boolean] {
           def toExpr(b: Boolean) = if (b) '{ true } else '{ false }
         }
       #+end_src

     - Once we can lift bits, we can work our way up. For instance, here is a
       possible implementation of ~Liftable[Int]~ that does not use the
       underlying tree machinery:
       #+begin_src scala
         delegate for Liftable[Int] {
           def toExpr(n: Int): Expr[Int] = n match {
             case Int.MinValue    => '{ Int.MinValue }
             case _ if n < 0      => '{ - ${ toExpr(-n) } }
             case 0               => '{ 0 }
             case _ if n % 2 == 0 => '{ ${ toExpr(n / 2) } * 2 }
             case _               => '{ ${ toExpr(n / 2) } * 2 + 1 }
           }
         }
       #+end_src

     - Since Liftable is a type class, its instances can be conditional.
       For example, a List is liftable if its element type is:
       #+begin_src scala
         delegate [T: Liftable] for Liftable[List[T]] {
           def toExpr(xs: List[T]): Expr[List[T]] = xs match {
             case head :: tail => '{ ${ toExpr(head) } :: ${ toExpr(tail) } }
             case Nil          => '{ Nil: List[T] }
           }
         }
       #+end_src

     - In the end, Liftable resembles very much a serialization framework.
       Like the latter it can be derived systematically for all collections,
       case classes and enums. Note also that the synthesis of type-tag values
       of type Type[T] is essentially the type-level analogue of lifting.

     - Using /lifting/, we can now give the missing definition of ~showExpr~ in
       the introductory example:
       #+begin_src scala
         def showExpr[T](expr: Expr[T]): Expr[String] = {
           val code: String = expr.show
           code.toExpr
         }
       #+end_src
       That is, the ~showExpr~ /method/ _converts_ its ~Expr~ argument to a
       string (~code~), and *lifts* the result back to an ~Expr[String]~ using
       the ~toExpr~ method.

     - Note:
       the ~toExpr~ extension /method/ can be ommited by importing an /implicit
       conversion/ with ~import scala.quoted.autolift._~. The programmer is able
       to declutter slightly the code at the cost of readable phase distinction
       between stages.

**** Lifting Types
**** Relationship with Inline
**** Scope Extrusion
**** Example Expansion
**** Find implicits within a macro
**** TODO Relationship with Whitebox Inline
     ~Inline~ documents inlining.
     The code below introduces a /whitebox inline method/ that can calculate
     either a value of /type/ ~Int~ or a value of /type/ ~String~.
     #+begin_src scala
       inline def defaultOf(inline str: String) <: Any =
         ${ defaultOfImpl(str) }

       def defaultOfImpl(str: String): Expr[Any] = str match {
         case "int"    => '{1}
         case "string" => '{"a"}
       }

       // in a separate file
       val a: Int    = defaultOf("int")
       val b: String = defaultOf("string")
     #+end_src

**** TODO Defining a macro and using it in a single project

*** TODO Staging
    * Multi-Stage Programming
**** API
**** Create a new Dotty project with staging enabled
**** Example

*** TODO Erased Terms
**** Why erased terms?
**** How to define erased terms?
**** What happens with erased values at runtime?
**** State machine with erased evidence example

*** TODO TASTy Reflection
**** API: From quotes and splices to TASTy reflect trees and back
***** Sealing and Unsealing
***** Obtaining and underlying argument
***** Positions
***** Tree Utilities
****** Let

**** More Examples

*** TODO TASTy Inspection
**** Inspecting TASTy files

** OTHER NEW FEATURES
*** Trait Parameters
**** Reference

*** Creator Applications
**** Motivation
**** Discussion

*** Export Clauses
    *An ~export~ clause defines aliases for selected members of an object.*
    - Example:
      #+begin_src scala
        class BitMap
        class InkJet

        class Printer {
          type PrinterType
          def print(bits: BitMap): Unit = ???
          def status: List[String] = ???
        }

        class Scanner {
          def scan(): BitMap = ???
          def status: List[String] = ???
        }

        class Copier {
          private val printUnit = new Printer { type PrinterType = InkJet }
          private val scanUnit = new Scanner

          export scanUnit.scan
          export printUnit.{status => _, _}

          def status: List[String] = printUnit.status ++ scanUnit.status
        }
      #+end_src
      - Here the two ~export~ clauses define the following /export aliases/ in
        class ~Copier~:
        #+begin_src scala
          final def scan(): BitMap            = scanUnit.scan()
          final def print(bits: BitMap): Unit = printUnit.print(bits)
          final type PrinterType              = printUnit.PrinterType
        #+end_src

      - The exported members can be accessed inside ~Copier~ as well as from
        outside:
        #+begin_src scala
          val copier = new Copier
          copier.print(copier.scan())
        #+end_src

      - Syntax (similar to ~import~):
        TODO
        TODO
        TODO
        TODO

**** Motivation
     - It is a standard recommendation to *prefer composition over inheritance*.
       + This is really an application of /the principle of least power/:
         * Composition treats components as blackboxes
           _WHEREAS_
         * inheritance can affect the internal workings of components through overriding

       + Sometimes the close coupling implied by /inheritance/ is the best solution
         for a problem, but hwere this is not necessary the looser coupling of
         composition is better.

     - So far, OO Language including Scala made it much easier to use /inheritance/
       than /composition/, which pushing programmers to a solution that is often
       too powerful as well as complicated (=from Jian= hard to verify in the concept of math).
       + For example, in Scala,
         * /inheritance/: Use ~extends~ clause
         * /composition/: Require a verbose elaboration of a sequence of forwarders. TODO ???

       + ~export~ clauses redress the balance, and
         make /composition relationships/ *as CONCISE and EASY to* express as
         /inheritance relationships/.
         * Actually, ~export~ clauses is MORE FLEXIBLE than ~extends~ clauses --
           members can be _renamed_ or _ommited_.

     - /Export clauses/ also fill a gap opened by the shift from /package objects/
       (DEPRECATED in Scala 3) to /toplevel definitions/.
       + In Scala 2, sometimes /package objects/ is created also with ~extends~ clauses.

       + /Toplevel definitions/ doesn't reside in semantics in a user-defined object,
         so they _can't inherit anyting_. However, ~export~ can be applied in
         toplevel, and make a similar result to the /package object/ _inheritance_ way.


**** Syntax changes
**** Elaboration of Export Clauses
     TODO ???
     TODO ???
     TODO ???
     TODO ???

*** DONE Opaque Type Alias
    CLOSED: [2019-09-13 Fri 02:50]
    /Opaque types aliases/ provide type abstraction without any runtime overhead.

    - Example:
      #+begin_src scala
        object Logarithms {

          opaque type Logarithm = Double

          object Logarithm {

            // These are the ways to lift to the logarithm type
            def apply(d: Double): Logarithm = math.log(d)

            def safe(d: Double): Option[Logarithm] =
              if (d > 0.0) Some(math.log(d)) else None
          }

          // Extension methods define opaque types' public APIs
          given LogarithmOps {
            def (x: Logarithm) toDouble: Double = math.exp(x)
            def (x: Logarithm) + (y: Logarithm): Logarithm = Logarithm(math.exp(x) + math.exp(y))
            def (x: Logarithm) * (y: Logarithm): Logarithm = Logarithm(x + y)
          }
        }
      #+end_src
      + ~Logarithm~ is the same as ~Double~ is *only known in the scope where
        ~Logarithm~ is defined* which in this case is object ~Logarithms~.
        * This in scope knowledge of their equivalence is very important!
            Without this knowledge, type-check will say functions ~apply~, ~safe~,
          ~toDouble~, ~+~, and ~*~ have wrong type signature, there there will
          be no simple way to override it.

      + Outside ~Logarithms~, ~Logarithm~ is treated as a _NEW abstract type_.
        * Legal operations example:
          #+begin_src scala
            import Logarithms._
            import Predef.{any2stringadd => _, _}

            val l1 = Logarithm(1.0)
            val l2 = Logarithm(2.0)
            val l3 = l1 * l2
            val l4 = l1 + l2
          #+end_src
          - =IMPORTANT=
            The ~import Predef.{any2stringadd => _}~ is necessary!!!
              Without this import clause, the universal ~+~ in ~Predef~ would
            take precedence over the ~+~ extension method in ~LogarithmOps~.
            + Solution: eliminate ~any2stringadd~ -- this is already in DEPRECATED
                        status.

        * Illegal operations example:
          #+begin_src scala
            val d: Double = l1       // error: found: Logarithm, required: Double
            val l2: Logarithm = 1.0  // error: found: Double, required: Logarithm
            l1 * 2                   // error: found: Int(2), required: Logarithm
            l2 / l2                  // error: `/` is not a member fo Logarithm
          #+end_src

**** Bounds For Opaque Type Alias
     /Opaque type aliases/ can also come with /bounds/.
     Example:
     #+begin_src scala
       object Access {

         opaque type Permissions = Int
         opaque type PermissionChoice = Int
         opaque type Permission <: Permissions & PermissionChoice = Int

         def (x: Permissions) & (y: Permissions): Permissions = x & y
         def (x: PermissionChoice) | (y: PermissionChoice): PermissionChoice = x | y
         def (x: Permissions) is (y: Permissions): Boolean = (x & y) == y
         def (x: Permissions) isOneOf (y: PermissionChoice): Boolean = (x & y) != 0

         val NoPermission: Permission = 0
         val ReadOnly: Permission = 1
         val WriteOnly: Permission = 2
         val ReadWrite: Permissions = ReadOnly & WriteOnly
         val ReadOrWrite: PermissionChoice = ReadOnly | WriteOnly
       }
     #+end_src
     - In conepts, the ~Access~ object defines THREE /opaque types/:
       + ~Permission~,       representing a single permission,
       + ~Permissions~,      representing a conjunction (logical "and") of permissions,
       + ~PermissionChoice~, representing a disjunction (logical "or") of permissions.

     - /Type bound/ of ~Permission~ makes it known outside the ~Access~ object that
       ~Permission~ is a /subtype/ of the other two types. Hence, the following
       usage scenario type-checks:
       #+begin_src scala
         object User {
           import Access._

           case class Item(rights: Permissions)

           val x = Item(ReadOnly)  // OK, since Permission <: Permissions

           assert(!x.rights.is(ReadWrite))
           assert(x.rights.isOneOf(ReadOrWrite))
         }
       #+end_src
       + On the other hand, ~x.rights.isOneOf(ReadWrite)~ can't pass the type check.

**** TODO More details
***** Syntax
***** Type Checking
***** Realtionship to SIP 35

*** TODO Open Classes
    An ~open~ /modifier/ on a class signals that the class _is planned for
    extensions_.
    - Example:
      #+begin_src scala
        // File Writer.scala
        package p

        open class Writer[T] {
          /** Sends to stdout, can be overridden */
          def send(x: T) = println(x)

          /** Sends all arguments using `send` */
          def sendAll(xs: T*) = xs.foreach(send)
        }

        // File encryptedWriter.scala
        package p

        class EncryptedWriter[T: Encryptable] extends Writer[T] {
          override def send(x: T) = super.send(encrypt(x))
        }
      #+end_src

    - An /open class/ typically comes with
      *some documentation that describes the internal calling patterns between
      methods of the class as well as hooks that can be overridden.*
      + We call this the /extension contract/ of the /class/.
        It is DIFFERENT FROM the /external contract/ between a /class/ and its
        users.

    - /Classes/ that are _not open_ *can still be extended*, *but only if* at least
      one of two alternative conditions is met:
      + TODO
      + TODO

**** Motivation
**** Details
**** Relationship with ~sealed~
**** Migration

*** Parameter Untupling
    For data like ~val xs: List[(Int, Int)]~,
    - In Scala 2.x,
      use _EXPLICIT_ /pattern matching/ (partial function) decomposition:
      #+BEGIN_SRC scala
        xs map {
          case (x, y) => x + y
        }
      #+END_SRC

    - Dotty allows the syntax:
      #+BEGIN_SRC scala
        xs map {
          (x, y) => x + y
        }

        // OR, EQUIVALENTLY:
        xs.map(_ + _)
      #+END_SRC

    - Generally, a /function value/ with *n > 1 parameters* is _converted to_ a
      /pattern-matching closure/ using ~case~ if the expected type is a /unary
      function type/ of the form ~((T_1, ..., T_n)) => U~.

**** Reference

*** Kind Polymorphism
*** Tupled Function
**** Tupled Function
**** Examples

*** ~threadUnsafe~ Annotation
**** Examples

*** DONE New Control Syntax
    CLOSED: [2019-09-09 Mon 18:32]
    #+begin_src scala
      if x < 0 then -x else x

      while x >= 0 do x = f(x)

      for x <- xs if x > 0
      yield x * x

      for
        x <- xs
        y <- ys
      do
        println(x + y)
    #+end_src
    - The rules in details:
      TODO
      - TODO * 4

      - For ~if~ or ~while~, in their condition,
        _newline characters_ are *NOT* _statement separators_.
          So the meaning of newlines is the _SAME_ no matter whether parentheses
        are present or absent.

      - For the enumerators of ~for~-expression,
        newline characters are *potential* _statement separators_.
        TODO ??? ??? ???

**** Rewrites
     The Dotty compiler _can rewrite_ source code from old syntax and new syntax
     and back.
     - With option ~-rewrite -new-syntax~, rewrite old with new
     - With option ~-rewrite -old-syntax~, rewrite new with old

*** TODO Optional Braces
**** Spaces vs Tabs
**** Indentation and Braces
**** Special Treatment of Case Clauses
**** The End Marker
**** Example
**** Settings and Rewrites
**** Variant: Indentation Marker ~:~

** OTHER CHANGED FEATURES
*** Numeric Literals
**** Meaning of Numeric Literals
**** The FromDigits Class
**** Error Handling
**** Example
**** Compile-Time Errors

*** Structural Types
    *Programmatic Structural Types*
**** Example
**** Extensibility
**** Relation with ~scala.Dynamic~

*** Operators
    *Rules for Operators*
**** The ~@alpha~ Annotation
***** Motivation
***** Details

**** The ~@infix~ Annotation
***** Motivation
***** Details

**** Syntax Change

*** Wildcard Types
    *Wildcard Arguments in Types*
**** Motivation
**** Migration Strategy

*** Type Checking
    *Type Checking*
    - [//]:# todo: fill in

*** Type Inference
    *Changes in Type Inference*
    - [//]:# todo: fill in

*** Implicit Resolution
    *Changes in Implicit Resolution*

*** Implicit Conversions
**** Examples

*** Overload Resolution
    *Changes in Overload Resolution*
**** Looking Beyond the First Argument List
**** Parameter Types of Function Values

*** Vararg Patterns
**** Compatibility considerations

*** Pattern Bindings
**** Bindings in Pattern Definitions
**** Pattern Bindings in For Expressions
**** Syntax Changes
**** Migration

*** Pattern Matching
    *Option-less pattern matching*
**** Extractors
***** Fixed-Arity Extractors
***** Variadic Extractors

**** Boolean Match
**** Product Match
**** Single Match
**** Name-based Match
**** Sequence Match
**** Product-Sequence Match

*** Eta Expansion
    *Automatic Eta Expansion*
**** Automatic eta-expansion and nullary methods

*** Compiler Plugins
    *Changes in Compiler Plugins*
**** Using Compiler Plugins
**** Writing a Standard Compiler Plugin
**** Writing a Research Compiler Plugin

*** Lazy Vals initialization
**** Motivation
**** Implementation
**** Note on recursive lazy vals
**** Reference

*** Main Functions

** DROPPED FEATURES
*** Dropped: DelayedInit
*** Dropped: Scala 2 Macros
*** Dropped: Existential Types
*** Dropped: General Type Projection
*** Dropped: Do-While
*** Dropped: Procedure Syntax
*** Dropped: Package Objects
*** Dropped: Early Initializers
*** Dropped: Class Shadowing
*** TODO Dropped: Limit 22
*** Dropped: XML Literals
*** TODO Dropped: Symbol Literals
*** Dropped: Auto-Application
**** Migrating code
**** Reference

*** Dropped: Weak Conformance
*** Dropped: Nonlocal Returns
*** Dropped: ~private[this]~ and ~protected[this]~ Quanlifier

* CONTRIBUTING
** Contribute Knowledge
*** Contribute Internals-related Knowledge

** Getting Started
*** Requirements
*** Compiling and Running
*** Starting a REPL
*** Generating Documentation

** Workflow
*** Compiling files with dotc
*** Inspecting Trees with Type Stealer
*** Pretty-printing
*** SBT Commands Cheat Sheet

** Testing
*** Unit tests
**** Testing with checkfiles

*** Integration tests
**** Bootstrapped-only tests
**** From TASTy tests

** Debugging
*** Setting up the playground
*** Show for human readable output
*** How to disable color
*** Reporting as a non-intrusive println
*** Printing out trees after phases
*** Printing out stack traces of compile time errors
*** Configuring the printer output
*** Figuring out an object creation site
**** Via ID
**** Via tracer

*** Built-in Logging Architecture
**** Printers
**** Tracing
**** Reporter

** IDEs and Tools
*** Mill
*** Scalafix

** Procedures
*** Release Model
**** Model
**** Example
***** At the Dotty Repo
***** At the CI
****** Canceling CI builds

***** Documentation
****** Release Procedure Checklist
****** GitHub Releases and Blog Post

***** Ecosystem

**** Procedure in Bash Scripts

*** Modifying the Test framework
    *Test Vulpix Framework*

* INTERNALS
** Backend
*** Data Flow
*** Architecture
**** (a) The queue subsystem
**** (b) Bytecode-level types, ~BType~
**** (c) Utilities offering a more "high-level" API to bytecode emission
**** (d) Mapping between type-checker types and ~BType~'s
**** (e) More "high-level" utilities for bytecode emission
**** (f) Building an ASM ~ClassNode~ given an AST ~TypeDef~

** Classpaths
** Core Data Structrues
*** Symbols and SymDenotations
*** Why is this important?
*** Are We Done Yet?
*** What Are the Next Steps?

** Contexts
*** Contexts in the typer
*** In other phases
*** Using contexts

** Dotc vs Scalac
   # Differences between Dotc and Scalac
*** Denotation
**** Denotation vs. SymDenotation
**** Implicit Conversion

*** Symbol
*** Flags
*** Tree
*** Type

** Higher-Kinded Types
   *This page is out of date and preserved for posterity. Please see
   Implementing Higher-Kinded Types in Dotty for a more up to date version*

*** Higher-Kinded Types in Dotty V2
**** The duality
**** Named type parameters
**** Wildcards
**** Type parameters in the encodings
**** Partial applications
**** Modelling polymorphic type declarations
**** Modelling polymorphic type aliases: simple case
**** Modelling polymorphic type aliases: general case
**** Modelling higher-kinded types
**** Full example
**** Status of ~#~

** Overall Structure
   # Dotty Overall Structure
*** Package Structure
*** Contexts
*** Compiler Phases

** Periods
   # Dotc's concept of time*

** Syntax
   # Scala Syntax Summary
*** Lexical Syntax
*** Keywords
**** Regular keywords
**** Soft keywords

*** Context-free Syntax
**** Literals and Paths
**** Types
**** Expressions
**** Type and Value Parameters
**** Bindings and Imports
**** Declarations and Definitions

** Type System
*** Class diagram
*** Proxy types and ground types
*** Representations of types
**** Representation of methods

*** Subtyping checks
**** Type rebasing

*** Type caching
    # TODO

*** Type inference via constraint solving
    # TODO

** Dotty Internals 1: Trees & Symbols (Meeting Notes)
*** Entry point
*** Phases
*** Trees
**** Untyped trees
**** Typed trees
**** Notes on some tree types
***** ThisTree

**** Creating trees
**** Meaning of trees
**** Errors
**** Assignment

*** Symbols
**** ClassSymbol
**** SymDenotation

** Debug Macros
*** position not set
*** unresolved symbols in pickling

* RESOURCES
*** Talks
**** Talks on Dotty
**** Deep Dive with Dotty
